{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Want to know who we are? Read up on our website.</p>"},{"location":"#what-is-this-site-about","title":"What is this site about?","text":"<p>This site is a public documentation area for our product and services. It is continously updated by the respective product teams.</p>"},{"location":"Bytt.Email/","title":"Bytt.Email","text":"<p>Bytt.Email is our service for allowing end users to change their own email address and UPN, both in Entra ID and Active Directory.</p> <p></p> <p>The service is payed for through Azure Marketplace (Coming soon).</p>"},{"location":"Bytt.Email/#consenting-access","title":"Consenting access","text":"<p>Note</p> <p>The following operations must be done as one of the following roles:</p> <ul> <li>Global Administrator</li> <li>Cloud Application Administrator</li> <li>Application Administrator</li> </ul> <ol> <li> <p>Consent to Fortytwo Universe, our API hub:</p> <p>https://login.microsoftonline.com/common/adminconsent?client_id=2808f963-7bba-4e66-9eee-82d0b178f408 </p> </li> <li> <p>Consent to the Bytt.Email application:</p> <p>https://login.microsoftonline.com/common/adminconsent?client_id=34ee8edb-d2ff-4ee9-bac3-73b53303e00f </p> </li> </ol>"},{"location":"Bytt.Email/#required-graph-permissions","title":"Required graph permissions","text":"Required permission Why? User.Read.All The solution needs to get the details of the user account that signs in, such as firstname, lastname, userPrincipalName and proxyAddresses GroupMember.Read.All Because we need to find email pattern groups as documented below"},{"location":"Bytt.Email/#grant-users-access","title":"Grant users access","text":"<p>Locate the Fortytwo Universe app under Entra ID and Enterprise Apps:</p> <p></p> <p>Under Users and groups, click Add user/group.</p> <p></p> <p>Assign any relevant user or group of users. These will be allowed to use the Bytt.Email service to change their email.</p> <p></p> <p>The assignments should now look like this. Notice that if you utilize other Fortytwo services, these role assignments are also managed here.</p> <p></p>"},{"location":"Bytt.Email/#configure-write-permissions-fulfillment","title":"Configure write permissions / fulfillment","text":"<p>Note: It is possible to test the service without granting write permissions, in that case simply skip this section</p> <p>If you have users in Active Directory synced to Entra ID, you need to configure the AD agent.</p> <p>If you have cloud users, you need to create an Administrative Unit and assign Bytt.Email permissions.</p>"},{"location":"Bytt.Email/#configure-email-patterns","title":"Configure email patterns","text":"<p>Note</p> <p>The default configuration for Bytt.Email is that the values of the first example is available to your users (if the user is assigned the Bytt.Email - user role, but not assigned a group with patterns), with the domain being the current UPN suffix of the user. This works for many of our customers.</p> <p>By consenting to Bytt.Email, you now have a new multivalued string attribute named <code>extension_34ee8edbd2ff4ee9bac373b53303e00f_patterns</code> available for groups in your tenant. In order to override the default email patterns available to your users, you can add users as member of group with this attribute set.</p> <p>This attribute can be set by using Graph Explorer and sending a PATCH request to https://graph.microsoft.com/v1.0/groups/OBJECTID-OF-GROUP</p> <pre><code>{\n    \"extension_34ee8edbd2ff4ee9bac373b53303e00f_patterns\": [\n        \"{firstname1}.{lastname-1}@yourdomain.com\",\n        \"{firstname1}.{firstname2}.{lastname-1}@yourdomain.com\",\n        \"{firstname1}.{lastname-2}.{lastname-1}@yourdomain.com\",\n        \"{firstnamewd1}.{lastnamewd-1}@yourdomain.com\",\n        \"{firstnamewd1}.{firstnamewd2}.{lastnamewd-1}@yourdomain.com\",\n        \"{firstnamewd1}.{lastnamewd-2}.{lastnamewd-1}@yourdomain.com\",\n        \"{firstname1}.{firstname2,1}.{lastname-1}@yourdomain.com\",\n        \"{firstname1}.{lastname-1}2@yourdomain.com\"\n    ]\n}\n</code></pre>"},{"location":"Bytt.Email/#create-email-pattern-group-using-powershell","title":"Create email pattern group using PowerShell","text":"<pre><code>connect-mggraph -scopes group.readwrite.all\n$domain = \"yourdomain.com\"\nNew-MgGroup -DisplayName \"Email patterns - $domain\" -MailEnabled:$false -SecurityEnabled:$true -MailNickname \"$(new-guid)\".Substring(0,8) -AdditionalProperties @{\n    \"extension_34ee8edbd2ff4ee9bac373b53303e00f_patterns\" = @(\n        \"{firstname1}.{lastname-1}@$domain\"\n        \"{firstname1}.{firstname2}.{lastname-1}@$domain\"\n        \"{firstname1}.{lastname-2}.{lastname-1}@$domain\"\n        \"{firstnamewd1}.{lastnamewd-1}@$domain\"\n        \"{firstnamewd1}.{firstnamewd2}.{lastnamewd-1}@$domain\"\n        \"{firstnamewd1}.{lastnamewd-2}.{lastnamewd-1}@$domain\"\n        \"{firstname1}.{firstname2,1}.{lastname-1}@$domain\"\n        \"{firstname1}.{lastname-1}2@$domain\"\n    )\n}\n</code></pre>"},{"location":"Bytt.Email/#placeholders","title":"Placeholders","text":"Placeholder Replaced with {firstname1} First firstname {firstname2} Second firstname {firstname3} Third firstname {firstname-1} Last firstname {firstname-2} Second last firstname {firstname-3} Third last firstname {lastname1} First lastname {lastname2} Second lastname {lastname3} Third lastname {lastname-1} Last lastname {lastname-2} Second last lastname {lastname-3} Third last lastname {firstnamewd1} First firstname, with dashes included {firstnamewd2} Second firstname, with dashes included {firstnamewd3} Third firstname, with dashes included {firstnamewd-1} Last firstname, with dashes included {firstnamewd-2} Second last firstname, with dashes included {firstnamewd-3} Third last firstname, with dashes included {lastnamewd1} First lastname, with dashes included {lastnamewd2} Second lastname, with dashes included {lastnamewd3} Third lastname, with dashes included {lastnamewd-1} Last lastname, with dashes included {lastnamewd-2} Second last lastname {lastnamewd-3} Third last lastname {onpremisessamaccountname} The onpremisessamaccountname attribute of the user {mailnickname} The mailNickname attribute of the user <p>We also allow for extracing the first n characters of the placeholders:</p> Placeholder Replaced with {firstname1,1} First character of first firstname {lastnamewd-1,3} First three characters of the last lastname, with dashes included"},{"location":"Bytt.Email/#example-usage","title":"Example usage","text":"<p>A user that is a member of both of these groups, will get the following options available to them:</p> <ul> <li>{firstname1}.{lastname-1}@contoso.com</li> <li>{firstname1}.{firstname2,1}.{lastname-1}@contoso.com</li> <li>{firstname1}.{lastname-1}@nwtraders.com</li> <li>{firstname1}.{firstname2,1}.{lastname-1}@nwtraders.com</li> </ul> <p>A user that is a member of only Example Group 1 will get these options:</p> <ul> <li>{firstname1}.{lastname-1}@contoso.com</li> <li>{firstname1}.{firstname2,1}.{lastname-1}@contoso.com</li> </ul> <p>While a user that is member of only Example Group 2 will get these options:</p> <ul> <li>{firstname1}.{lastname-1}@nwtraders.com</li> <li>{firstname1}.{firstname2,1}.{lastname-1}@nwtraders.com</li> </ul>"},{"location":"Bytt.Email/#example-group-1","title":"Example Group 1","text":"<pre><code>{\n    \"extension_34ee8edbd2ff4ee9bac373b53303e00f_patterns\": [\n        \"{firstname1}.{lastname-1}@contoso.com\",\n        \"{firstname1}.{firstname2,1}.{lastname-1}@contoso.com\"\n    ]\n}\n</code></pre>"},{"location":"Bytt.Email/#example-group-2","title":"Example Group 2","text":"<pre><code>{\n    \"extension_34ee8edbd2ff4ee9bac373b53303e00f_patterns\": [\n        \"{firstname1}.{lastname-1}@nwtraders.com\",\n        \"{firstname1}.{firstname2,1}.{lastname-1}@nwtraders.com\"\n    ]\n}\n</code></pre>"},{"location":"Bytt.Email/ad-agent/","title":"AD agent installation guide","text":"<p>The ChangeEmail agent module is a simple module made for listening to change requests from Bytt.Email / ChangeEmail by Fortytwo, updating the user account in Active Directory and reporting back the status of the change. There are a few steps required to install the module and run it:</p>"},{"location":"Bytt.Email/ad-agent/#requirements","title":"Requirements","text":"<ul> <li>The agent must be running on a domain joined windows server</li> <li>PowerShell 7.5 or newer installed</li> <li>AD PowerShell installed (<code>Install-WindowsFeature -Name RSAT-AD-Tools -IncludeAllSubFeature</code>)</li> </ul>"},{"location":"Bytt.Email/ad-agent/#step-1-install-powershell-modules","title":"Step 1 - Install PowerShell modules","text":"<p>Run the below as administrator in order to install the required modules from PowerShell Gallery:</p> <pre><code>Install-Module Fortytwo.ChangeEmail.Agent -Scope AllUsers\nInstall-Module EntraIDAccessToken -Scope AllUsers\n</code></pre>"},{"location":"Bytt.Email/ad-agent/#step-2-configure-changeemailagent-requirements","title":"Step 2 - Configure ChangeEmailAgent requirements","text":"<p>Run the following as administrator:</p> <pre><code>New-EventLog -LogName \"Application\" -Source \"ChangeEmailAgent\"\n$Certificate = New-SelfSignedCertificate -Subject \"ChangeEmailAgent\" -NotAfter (Get-Date).AddYears(100)\n[System.Convert]::ToBase64String($Certificate.Export([System.Security.Cryptography.X509Certificates.X509ContentType]::Cert), \"InsertLineBreaks\") | Set-Content -Path \"ChangeEmailAgent-$($env:COMPUTERNAME).cer\"\n\"\",\"Thumbprint:       $($Certificate.ThumbPrint)\", \"Certificate file: ChangeEmailAgent-$($env:COMPUTERNAME).cer\"\",\"\" | Write-Host\n</code></pre>"},{"location":"Bytt.Email/ad-agent/#step-3-consent-to-fortytwo-universe-our-api-and-create-app-registration-for-agent","title":"Step 3 - Consent to Fortytwo Universe (Our API) and create app registration for agent","text":"<ol> <li> <p>As a global administrator, go to: https://login.microsoftonline.com/common/adminconsent?client_id=2808f963-7bba-4e66-9eee-82d0b178f408</p> </li> <li> <p>In Entra ID, go to App registrations and click New registration</p> </li> <li> <p>Give it a name and create Register</p> </li> <li> <p>Note down the Client ID and Tenant ID:</p> </li> </ol> <p></p> <ol> <li>Under Certificates &amp; secrets upload the certificate file created in Step 2</li> </ol> <p></p> <ol> <li>Under API permissions, click Add a permission, select APIs my organization uses and locate Fortytwo Universe</li> </ol> <p></p> <ol> <li> <p>Under Application permissions check changeemail.changerequest.readwrite.all and click Add permissions*.</p> </li> <li> <p>Click Grant admin consent</p> </li> </ol>"},{"location":"Bytt.Email/ad-agent/#step-4-create-the-run-file-for-the-changeemail-agent","title":"Step 4 - Create the run file for the ChangeEmail Agent","text":"<p>Create <code>C:\\changeemail\\run.ps1</code> with the following contents:</p> <pre><code>Import-Module EntraIDAccessToken -force\nImport-Module Fortytwo.ChangeEmail.Agent -force\n\nAdd-EntraIDClientCertificateAccessTokenProfile `\n    -Scope \"https://api.fortytwo.io/.default\" `\n    -Thumbprint \"THUMBPRINT_FROM_STEP2\" `\n    -ClientId \"CLIENT_ID_FROM_STEP3\" `\n    -TenantId \"TENANT_ID_FROM_STEP3\" `\n    -V2Token:$true\n\nStart-ChangeEmailAgentListener -Sleep 5 -Verbose -Debug\n</code></pre>"},{"location":"Bytt.Email/ad-agent/#step-5-try-to-run-the-changeemail-agent-manually","title":"Step 5 - Try to run the ChangeEmail agent manually","text":"<ol> <li>Open a PowerShell and run <code>cd c:\\changeemail ; . c:\\changeemail\\run.ps1</code></li> </ol> <p>At this point, you can test out ChangeEmail and see that requests are received and processed by the agent.</p>"},{"location":"Bytt.Email/ad-agent/#step-6-run-the-changeemail-agent-as-a-scheduled-task","title":"Step 6 - Run the ChangeEmail agent as a scheduled task","text":""},{"location":"Bytt.Email/ad-agent/#create-a-gmsa-for-the-scheduled-task","title":"Create a gMSA for the scheduled task","text":"<p>Run the below PowerShell in order to create a gMSA:</p> <pre><code>New-ADServiceAccount -Name \"changeemailagent\" -PrincipalsAllowedToRetrieveManagedPassword \"SERVERNAME$\" -DNSHostname \"bytt.email\"\n</code></pre>"},{"location":"Bytt.Email/ad-agent/#delegate-the-gmsa-the-reset-password-permission-in-ad","title":"Delegate the gMSA the reset password permission in AD","text":"<p>For each OU where the agent should be able to reset passwords, run the following three PowerShell lines (with the correct OU path and domain name):</p> <pre><code>dsacls \"OU=Users,DC=contoso,DC=com\" /I:S /G '\"contoso.com\\changeemailagent$:CA;Reset Password\";user'\ndsacls \"OU=Users,DC=contoso,DC=com\" /I:S /G '\"contoso.com\\changeemailagent$:rpwp;PwdlastSet\";user'\ndsacls \"OU=Users,DC=contoso,DC=com\" /I:S /G '\"contoso.com\\changeemailagent$:rpwp;lockoutTime\";user'\n</code></pre>"},{"location":"Bytt.Email/ad-agent/#grant-permission-to-certificate","title":"Grant permission to certificate","text":"<p>Run certlm.msc, locate the changeemailagent certificate under Personal certificates, and Manage private keys</p> <p></p> <p>Locate the gMSA you created, and grant Full control</p> <p></p>"},{"location":"Bytt.Email/ad-agent/#grant-permission-to-log-on-as-a-batch-job","title":"Grant permission to Log on as a batch job","text":""},{"location":"Bytt.Email/ad-agent/#create-scheduled-task","title":"Create scheduled task","text":"<ol> <li>Create a scheduled task running as the gMSA that:<ul> <li>Runs the action <code>pwsh</code> with the arguments <code>-file c:\\changeemail\\run.ps1</code></li> <li>Run daily, repeat every 2 minutes (Just in order to restart the task if it fails)</li> <li>Do not run multiple instances</li> </ul> </li> </ol>"},{"location":"Bytt.Email/au/","title":"Administrative unit (AU)","text":"<p>In order to minimize the permissions required by Bytt.Email, we are not requesting permissions like user.readwrite.all. This method minimizes the required permissions for Bytt.Email into your tenant. It is only needed if you have cloud only users that should be able to use the Bytt.Email service.</p> <ol> <li>Sign into the Azure Portal as a Global Administrator, locate Entra ID, find Administrative units in the left meny and click + Add.</li> </ol> <p></p> <ol> <li>Name the AU something that makes sense in your environment and click Review + create</li> </ol> <p></p> <ol> <li>Find the AU you created, go to Roles and administrators and click on User Administrator</li> </ol> <p></p> <ol> <li>Add an assignment for the Bytt.Email Enterprise application:</li> </ol> <p></p> <ol> <li>Finally, on the properties of the AU, change the Memebership type to Dynamic User and define a criteria:</li> </ol> <p></p> <p>Example criteria:</p> Who Criteria All enabled users (user.accountEnabled -eq true) All enabled users with of different company values (user.companyName -in [\"Company 1\", \"Company 2\"]) All users with a certain UPN suffix (user.userPrincipalName -endsWith \"@customer.com\") All members of group X user.memberof -any (group.objectId -in ['group-x-object-id']) All members in any of group X or Y user.memberof -any (group.objectId -in ['group-x-object-id', 'group-y-object-id'])"},{"location":"Entra%20Reference%20Architecture/","title":"Microsoft Entra Solution Patterns","text":"<p>This section contains our Fortytwo reference solutions for utilizing Microsoft Entra as the your Identity Governance and Access (IGA) solution. The reference architecture is under continuous development, and more content will be added.</p>"},{"location":"Entra%20Reference%20Architecture/Customer%20Identity%20and%20Access%20Management/","title":"Customer Identity and Access Management","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/","title":"Norske kommuner og fylkeskommuner","text":"<p>Content in Norwegian</p> <p>The content in this subsection is in Norwegian, as it is targeted to Norwegian municipalities</p> <p>Ikke ferdig</p> <p>Denne dokumentasjonen er ikke ferdig, og b\u00f8r ansees som work in progress</p> <p>Velkommen til Fortytwo's referansearkitektur for Identity and Access Management (IAM) / Identity Governance and Administration (IGA) for norske kommuner og fylkeskommuner. Denne siden er utformet som en veiledning og en blueprint som kan benyttes for \u00e5 styrke og sikre digitale identiteter og tilgang til informasjonssystemer i offentlige enheter og baserer seg p\u00e5 bruk av Microsoft Entra ID som kjernekomponent.</p> <p>Helt overordnet og oppsummert er arkitekturen lagt opp til \u00e5 benytte Entra ID fullt ut, med valgfritt Active Directory med brukere og grupper provisjonert via Entra ID. Det er ingen andre IAM-produkter involvert i designet.</p> <p></p> <p>I dagens digitale landskap st\u00e5r kommuner og fylkeskommuner overfor stadig \u00f8kende kompleksitet n\u00e5r det gjelder administrasjon av identiteter og tilgangsstyring. \u00c5 balansere behovet for \u00e5 gi ansatte, elever og innbyggere effektiv tilgang til n\u00f8dvendige ressurser, samtidig som sikkerheten opprettholdes og uten \u00e5 bygge opp en enorm teknisk gjeld i form av forskjellige tekniske l\u00f8sninger, er en utfordrende oppgave. Denne referansearkitekturen tar sikte p\u00e5 \u00e5 adressere nettopp dette, ved \u00e5 tilby en strukturert tiln\u00e6rming til design, implementering og forvaltning av IAM.</p> <p>Vi inviterer deg til \u00e5 utforske denne arkitekturen og ta det i bruk som en ressurs i arbeidet med \u00e5 styrke og forbedre IAM-praksisen for offentlige enheter i Norge.</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/FEIDE/","title":"FEIDE + Microsoft Entra ID","text":"<p>FEIDE-katalog som en tjeneste</p> <p>Fortytwo tilbyr FEIDE-katalog som en tjeneste, enten kj\u00f8rende i Azure hos oss eller i Azure hos deg. Vi s\u00f8rger da for at katalogen alltid er operativ og populert med korrekte data. Ta kontakt med hello@fortytwo.io for mer informasjon og pris.</p> <p>Alle kommuner og fylkeskommuner m\u00e5 tilby sine ansatte og elever en m\u00e5te \u00e5 logge p\u00e5 FEIDE p\u00e5, for \u00e5 kunne f\u00e5 tilgang til l\u00f8sninger som kun har integrasjon mot nettopp FEIDE for p\u00e5logging. FEIDE best\u00e5r i hovedsak av f\u00f8lgende komponenter, hvor begrepet Vertsorganisasjon benyttes om kommunen / fylkeskommunen:</p> Komponent Beskrivelse Forvaltes av FEIDE-plattformen Sentral l\u00f8sning som h\u00e5ndterer autentisering SIKT LDAP-katalog En LDAP katalog som benyttes av FEIDE for oppslag av informasjon om brukere, som GREP-koder, undervisningsgrupper, personnummer og liknende Vertsorganisasjon Tjenester Tjenester som benytter FEIDE som p\u00e5loggingstjeneste Tjenestetilbyder <p>For \u00e5 kunne tilby FEIDE for sine brukere, m\u00e5 en kommune/fylkeskommune etablere en eller flere LDAP-servere med et standardisert skjema, som inneholder data i et bestemt format. Disse serverene inneholder store mengder personlig identifiserbar informasjon (PII), og b\u00f8r sikres p\u00e5 en god m\u00e5te, ved at den isoleres fra milj\u00f8et og etableres som en helt separat l\u00f8sning i eksempelvis Azure.</p> <p></p> <p>Designvalg FEIDE.01</p> <p>Serverene som inneholder FEIDE-katalogen etableres i Azure, i et separat virtuelt nettverk med kun \u00e5pning fra FEIDE-tjenesten og l\u00f8sningen for provisjonering av innhold.</p> <ul> <li>S\u00f8rger for best mulig isolering av tjenesten, for \u00e5 begrense risiko for angrep</li> </ul>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/FEIDE/#ldap","title":"LDAP","text":"<p>LDAPv3 som protokoll er veldefinert, og med FEIDE st\u00e5r man fritt til \u00e5 velge hvilken LDAP-l\u00f8sning man m\u00e5tte \u00f8nske, s\u00e5 lenge man benyttes de p\u00e5krevde skjemaene. Gode valg av LDAP-servere er Microsoft sin AD LDS og OpenLDAP.</p> <p>Designvalg FEIDE.02</p> <p>LDAP-katalogen etableres som en instans av AD LDS.</p> <ul> <li>Trivielt \u00e5 drifte for windows-administratorer</li> </ul> <p>LDAP-katalogen m\u00e5 v\u00e6re tilgjengelig for at FEIDE-p\u00e5logging skal virke, og det b\u00f8r derfor etableres flere servere med lastbalansering og failover.</p> <p>Designvalg FEIDE.03</p> <p>LDAP-katalogen kj\u00f8res fordelt p\u00e5 to windows-baserte virtuelle maskiner, i Azure, i et Availability Set, med lastbalansering.</p> <ul> <li>Tilgjengelig hvis en VM skulle g\u00e5 ned (99.95% Azure SLA)</li> </ul>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/FEIDE/#provisjonering-av-innhold","title":"Provisjonering av innhold","text":"<p>Innholdet i FEIDE-katalogen inneholder en del attributter som kun b\u00f8r eksistere i det skoleadministrative systemet og ikke i eksempelvis Active Directory eller Entra ID. Det etableres derfor en l\u00f8sning som leser tildelte brukere fra en Enterprise App i Entra ID (for scoping av hvilke brukere som skal ha FEIDE-bruker) og sl\u00e5r dette sammen med data fra det skoleadministrative systemet og populerer FEIDE-katalogen med de riktige dataene.</p> <p>Designvalg FEIDE.04</p> <p>Innholdet i LDAP-katalogen provisjoneres ved hjelp av en Azure DevOps Pipeline kj\u00f8rende med self hosted agent med fast IP.</p> <ul> <li>Enkel feils\u00f8king og overv\u00e5kning</li> <li>Direkte integrert mot versjonert kode</li> <li>Muliggj\u00f8r \u00e5 begrense hvem som kan koble til FEIDE-katalog p\u00e5 IP</li> </ul> <p>Designet legger opp til at det ikke settes noe passord p\u00e5 brukerne i FEIDE, og at Single Sign-On mot Entra ID benyttes for p\u00e5logging.</p> <p>Designvalg FEIDE.05</p> <p>Brukere i FEIDE-katalogen etableres som disablede brukere uten passord.</p> <ul> <li>Krever bruk av Single Sign-On via Entra ID</li> <li>Bedrer sikkerheten ved p\u00e5logging</li> <li>Fjerner potensielt behov for synk av passord fra on-premises AD, og dermed ogs\u00e5 behovet for on-premises AD</li> </ul>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/FEIDE/#feide-som-en-tjeneste","title":"FEIDE som en tjeneste","text":"<p>Vi i Fortytwo tilbyr FEIDE-katalog som en tjeneste, som inneb\u00e6rer av vi s\u00f8rger for at:</p> <ul> <li>Katalogen synkroniseres med skoleadministrativt system</li> <li>Katalogen alltid er operativ, sikret og monitorert</li> <li>Alt av sertifikater, skjema-oppdatering og liknende h\u00e5ndteres</li> <li>Migrering fra eksisterende katalog til ny Fortytwo managed FEIDE-katalog</li> </ul> <p></p> <p>Ta kontakt med hello@fortytwo.io for mer informasjon og pris.</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Gjester%20og%20eksterne/","title":"Gjestetilganger","text":"<p>Work in progress</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/","title":"Integrasjon av tjenester","text":"<p>Designet legger opp til at alle applikasjoner og tjenester integreres mot Entra ID, b\u00e5de for Single Sign-On, autorisasjon og brukerprovisjonering der det er behov for det.</p> <p>Brukerprovisjonering?</p> <p>Brukerprovisjonering vil si at IAM-plattformen populerer en brukerdatabase i applikasjonen direkte, p\u00e5 forh\u00e5nd, f\u00f8r brukeren logger inn i applikasjonen.</p> <p></p> <p>Det er ofte mulig \u00e5 integrere en applikasjon p\u00e5 flere m\u00e5ter, og for \u00e5 s\u00f8rge for at man alltid velger den \"beste\" m\u00e5ten, er det etablert en del faste integrasjonsm\u00f8nstre, som alltid skal benyttes, og man velger alltid den f\u00f8rste p\u00e5 listen som lar seg benytte:</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/#brukerprovisjonering","title":"Brukerprovisjonering","text":"<ol> <li>SCIM-basert integrasjon</li> <li>Populering av applikasjon via API-basert integrasjon</li> <li>Filuttrekk</li> <li>Applikasjon leser selv via Microsoft Graph</li> </ol>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/#single-sign-on","title":"Single Sign-On","text":"<ol> <li>Multi-tenant app for SaaS applikasjoner</li> <li>OpenID Connect integrasjon</li> <li>SAML federering</li> </ol>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/#autorisasjon","title":"Autorisasjon","text":"<ol> <li>App-roller og tildelinger</li> <li>Assigned groups as claim</li> <li>SCIM-transferred groups</li> <li>Pipeline transferring app roles to app via API integration</li> <li>Application reading groups from Microsoft Graph</li> </ol>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Autorisasjon%20og%20grupper/01-App-roller%20og%20tildelinger/","title":"App-roller og tildelinger","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Autorisasjon%20og%20grupper/02-Assigned%20groups%20as%20claim/","title":"Etablere grupper i Claims","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Autorisasjon%20og%20grupper/02-Assigned%20groups%20as%20claim/#assigned-groups-som-claim","title":"Assigned groups som claim","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Autorisasjon%20og%20grupper/03-SCIM-transferred%20groups/","title":"SCIM overf\u00f8ring av Grupper","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Autorisasjon%20og%20grupper/04-Pipeline%20transferring%20app%20roles%20/","title":"Pipeline overf\u00f8ring av grupper","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Autorisasjon%20og%20grupper/04-Pipeline%20transferring%20app%20roles%20/#pipeline-transferring-app-roles-to-app-via-api-integration","title":"Pipeline transferring app roles to app via API integration","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Autorisasjon%20og%20grupper/05-Application%20reading%20groups/","title":"Applikasjon initiert overf\u00f8ring av grupper","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Autorisasjon%20og%20grupper/05-Application%20reading%20groups/#application-reading-groups-from-microsoft-graph","title":"Application reading groups from Microsoft Graph","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Brukerprovisjonering/01-SCIM-basert%20integrasjon/","title":"SCIM-basert Integrasjon","text":"<p>System for Cross-domain Identity Management (SCIM) er en standard protokoll innen identitetsadministrasjon, som lar organiasjoner enkelt h\u00e5ndtere identiteter og tilgang p\u00e5 tvers av ulike plattformer og applikasjoner. Entra ID har muligheter for integrasjon av applikasjoner med SCIM-st\u00f8tte, uten bruk av eksterne verkt\u00f8y, hvor man kan konfigurere hvilke brukere og hvilke data om disse brukerene som skal populeres i applikasjonen. Det er ogs\u00e5 mulighet for \u00e5 populere grupper i eksterne applikasjoner.</p> <p></p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Brukerprovisjonering/02-API-basert%20integrasjon/","title":"API-Basert Integrasjon","text":"<p>Populering av applikasjon via API-basert integrasjon</p> <p>Det finnes mange applikasjoner som har API-baserte grensesnitt for \u00e5 populere brukere, eller andre objekttyper (organisasjonshierarki, stillinger, osv.), men hvor APIet ikke er basert p\u00e5 SCIM-standarden. Entra ID har ingen native integrasjonsmulighet mot denne typen APIer, men i stedet benyttes en Azure-basert automasjonsl\u00f8sning som leser fra Microsoft Graph og skriver til applikasjons-APIet.</p> <p>For \u00e5 s\u00f8rge for at Entra ID fortsatt styrer hvilke brukerkontoer som er en del av integrasjonen, benyttes en enterprise app med app role assignments. P\u00e5 denne m\u00e5ten kan de forskjellige metodene for \u00e5 styre tildeling av applikasjonsroller, bla. access packages, benyttes. </p> <p>Fortytwo har god erfaring med \u00e5 kj\u00f8re automasjonsl\u00f8sninger i alle f\u00f8lgende systemer:</p> <ul> <li>Azure DevOps Pipelines</li> <li>GitHub Actions</li> <li>Azure Automation Accounts</li> <li>Azure Functions</li> </ul> <p></p> <p>I noen tilfeller vil det v\u00e6re behov for provisjonering av data som av ulike \u00e5rsaker ikke befinner seg i Entra ID. Dette kan for eksempel v\u00e6re mer sensitive personopplysninger, organisasjonshierarki eller stillingsinformasjon. I disse tilfellene benytte automasjonsl\u00f8snigen data fra HR- og Skoleadministrattivt system direkte, og sammenkobler dataene med brukerinformasjon fra Entra ID.</p> <p>Som en tjeneste</p> <p>Vi i Fortytwo tilbyr applikasjonsprovisjonering som en tjeneste, som inneb\u00e6rer av vi s\u00f8rger for at:</p> <ul> <li>Brukerinformasjon blir synkronisert til applikasjonen kontinuerlig</li> <li>Monitorering av l\u00f8sningen</li> <li>Alt av sertifikater, skjema-oppdatering, API-versjoner og liknende h\u00e5ndteres</li> </ul> <p>Ta kontakt med hello@fortytwo.io for mer informasjon og pris.</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Brukerprovisjonering/03-Fil-basert%20integrasjon/","title":"Fil-basert Integrasjon","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Brukerprovisjonering/04-App-read%20integrasjon/","title":"Applikasjon inititert integrasjon","text":"<p>Applikasjon leser selv via Microsoft Graph</p> <p></p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Brukerprovisjonering/05-On-prem-AD-integrasjon/","title":"On-Prem AD integrasjon","text":"<p>Work in progress</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Ferdige%20integrasjoner/01-intro/","title":"V\u00e5re ferdige integrasjon","text":"<p>Work in progress</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Single%20Sign-On/1/","title":"Multi-tenant app for SaaS applikasjoner","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Single%20Sign-On/2/","title":"OpenID Connect integrasjon","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Integrasjon%20av%20tjenester/Single%20Sign-On/3/","title":"SAML federering","text":""},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Priviligert%20tilgang/","title":"Priviligert tilgang","text":"<p>Work in progress</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Selvbetjening/Avansert%20gruppeh%C3%A5ndtering/01-intro/","title":"Selvbetjeningsfunksjon for avansert gruppemedlemskap","text":"<p>Work in progress</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Selvbetjening/Delegert%20administrasjon/01-intro/","title":"Selvbetjeningsfunksjon for delegert administrasjon/lederportal","text":"<p>Work in progress</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Selvbetjening/F%C3%B8rstegangspassord/01-intro/","title":"Selvbetjeningsfunksjon for h\u00e5ndtering av elevpassord","text":"<p>Work in progress</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Selvbetjening/Internett%20styring/01-intro/","title":"Selvbetjeningsfunksjon for styring av internettilgang","text":"<p>Work in progress</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Sikkerhet%20og%20Conditional%20Access/01-intro/","title":"Sikkerhet og Conditional Access","text":"<p>Work in progress</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Sikkerhet%20og%20Conditional%20Access/02-Autentiseringsmekanismer/","title":"Autentiseringsmekanismer","text":"<p>Work in progress</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Sikkerhet%20og%20Conditional%20Access/03-N%C3%B8dtilgang/","title":"N\u00f8dtilgang","text":"<p>N\u00f8dtilgangskontoer (Ogs\u00e5 kalt Break Glass Account) i Entra ID gir et ekstra sikkerhetslag ved \u00e5 tillate autoriserte personer \u00e5 f\u00e5 tilgang til kritiske Entra ID-ressurser i tilfelle en uventet hendelse, for eksempel n\u00e5r alle normale administratorer er utilgjengelige. Dette kan v\u00e6re sv\u00e6rt nyttig i n\u00f8dstilfeller eller hvis det oppst\u00e5r problemer med \u00e5 f\u00e5 tilgang til Entra ID og Microsoft 365. Erfaring tilsier at det kan ta flere dager \u00e5 re-etablere tilgang til en tenant hvis man mister all ting og har behov for hjelp av Microsoft for \u00e5 f\u00e5 tilbake tilgang.</p> <p>Designvalg SEC.01</p> <p>En brukerkonto etableres med hensikt \u00e5 v\u00e6re brukt kun ved n\u00f8dstilfeller.</p> <p>For \u00e5 sikre en robust og p\u00e5litelig n\u00f8dtilgangsl\u00f8sning, etableres n\u00f8dtilgangskontoen med et ekstremt sterkt, tilfeldig generert passord som ikke lagres i noen databaser eller systemer. Denne tiln\u00e6rmingen minimerer potensielle sikkerhetsrisikoer knyttet til passordets lagring og reduserer risikoen for uautorisert tilgang. Videre blir \u00e9n eller flere device-bound passkeys, som for eksempel FIDO2 USB- eller NFC-enheter, registrert p\u00e5 kontoen som den eneste gyldige p\u00e5loggingsmetoden. Dette sikrer at tilgangen kun er tilgjengelig via disse fysiske enhetene og legger til et ekstra lag av autentisering for \u00e5 sikre at bare autoriserte personer kan bruke n\u00f8dtilgangskontoen i kritiske situasjoner.</p> <p>Designvalg SEC.02</p> <p>N\u00f8dtilgangskontoen etableres med et tilfeldig satt langt passord som ikke lagres noe sted. \u00c9n eller flere device-bound passkeys (Feks. FIDO2 USB/NFC-enhet) registeres p\u00e5 kontoen som eneste gyldige p\u00e5logging.</p> <p>For \u00e5 opprettholde kontroll og overv\u00e5king av n\u00f8dtilgangssituasjoner, implementeres det en automatisert varslingssystem n\u00e5r n\u00f8dtilgangskontoen benyttes. Dette systemet gir umiddelbar og kontinuerlig informasjon til definerte ansvarlige personer eller grupper hver gang n\u00f8dtilgangskontoen tas i bruk. Denne varslingen sikrer \u00f8yeblikkelig respons og tilsyn ved n\u00f8dtilfeller, og tillater rask identifisering og h\u00e5ndtering av situasjonen, samtidig som det gir transparens og dokumentasjon om bruk av n\u00f8dtilgang for fremtidig gjennomgang og evaluering.</p> <p>Designvalg SEC.03</p> <p>Det etableres automatisk varsling n\u00e5r n\u00f8dtilgangskontoen benyttes.</p> <p>For \u00e5 sikre tilgjengelighet og effektivitet i n\u00f8dssituasjoner, tildeles n\u00f8dtilgangskontoen en permanent Global Administrator-rolle. Dette valget sikrer at i tilfelle en feil konfigurasjon eller utilgjengelighet av Priviliged Identity Management (PIM), forblir n\u00f8dtilgangsl\u00f8sningen intakt og tilgjengelig. Ved \u00e5 ha permanent Global Administrator-tilgang sikres det at n\u00f8dtilgangskontoen alltid har de n\u00f8dvendige tillatelsene til \u00e5 h\u00e5ndtere kritiske situasjoner uavhengig av eventuelle endringer eller begrensninger i PIM-systemet.</p> <p>Designvalg SEC.04</p> <p>N\u00f8dtilgangskontoen legges som permanent Global Administrator</p> <ul> <li>Unng\u00e5r at eksempelvis feilkonfigurasjon av Priviliged Identity Management (PIM) \u00f8delegger n\u00f8dtilgangsl\u00f8sningen</li> </ul> <p>For \u00e5 sikre at n\u00f8dtilgangskontoen alltid er tilgjengelig i kritiske situasjoner, blir den eksplisitt ekskludert fra alle Conditional Access-regler. Dette designvalget sikrer at feilkonfigurasjoner eller endringer i Conditional Access policies ikke p\u00e5virker n\u00f8dtilgangsl\u00f8sningen. Ved \u00e5 unnta n\u00f8dtilgangskontoen fra slike regler reduseres risikoen for utilsiktet blokkering av tilgangen til n\u00f8dtilgangsmekanismen, og sikrer at den forblir tilgjengelig n\u00e5r den trengs mest.</p> <p>Designvalg SEC.05</p> <p>N\u00f8dtilgangskontoen legges som unntak fra alle Conditional Access-regler.</p> <ul> <li>Reduserer sjansen for at feilkonfigurasjon av Conditional Access policies \u00f8delegger n\u00f8dtilgangsl\u00f8sningen</li> </ul> <p>For \u00e5 ytterligere sikre Conditional Access-milj\u00f8et og minimere risikoen for utilsiktet blokkering av tilgang, gir man samtykke til Fortytwo sin n\u00f8dtilgangsapp. Denne appen f\u00e5r kun tilgang til \u00e5 endre Conditional Access policies, og dens rolle begrenses til kun \u00e5 h\u00e5ndtere disse spesifikke policyendringene. Dette gir et ekstra sikkerhetslag ved \u00e5 tillate rask tilgang i tilfelle utilsiktet selvforskyldt utestengelse fra systemet p\u00e5 grunn av feilkonfigurasjon av Conditional Access. Appen sikrer at kun n\u00f8dvendige endringer kan utf\u00f8res, og at de gj\u00f8res p\u00e5 en kontrollert m\u00e5te for \u00e5 gjenopprette n\u00f8dvendig tilgang uten \u00e5 kompromittere systemets sikkerhet.</p> <p>Designvalg SEC.06</p> <p>Som ekstra tiltak for \u00e5 unng\u00e5 uhell med Conditional Access gj\u00f8res et consent av Fortytwo sin n\u00f8dtilgangsapp.</p> <ul> <li>Har kun tilgang til \u00e5 endre p\u00e5 Conditional Access policies</li> <li>Kan benyttes for rask tilgang om man skulle stenge seg selv ute grunnet feilkonfigurasjon av Conditional Access</li> </ul>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Sikkerhet%20og%20Conditional%20Access/04-Overv%C3%A5kning/","title":"Overv\u00e5kning","text":"<p>Work in progress</p>"},{"location":"Entra%20Reference%20Architecture/Norske%20kommuner%20og%20fylkeskommuner/Sikkerhet%20og%20Conditional%20Access/05-Persona%20Based%20Conditional%20Access/","title":"Persona Based Conditional Access","text":"<p>Work in progress</p>"},{"location":"Entra%20Reference%20Architecture/Outbound%20Provisioning/","title":"Outbound Provisioning","text":""},{"location":"Generic/","title":"Generic","text":"<p>This is currently a work in progress and more will come here...</p>"},{"location":"Generic/Fortytwo%20information%20labelling/","title":"Document labelling","text":""},{"location":"Generic/Fortytwo%20information%20labelling/#background","title":"Background","text":"<p>Fortytwo Technologies principles in regards to information protection and document labelling</p> <p>This section only focus on classification of information based on the informations sensitivity and the intended audience. We will not handle protection of the infomation in this section, protection will build on the label definition, usage guidelines and the systems Fortytwo use. </p>"},{"location":"Generic/Fortytwo%20information%20labelling/#public","title":"Public","text":"<p>Information available to all audience, with no specific access restrictions. Information labelled with this classification present no risk if information is shared outside Fortytwo Technologies organisation.</p> <p>Examples of information</p> <ul> <li>Information published to docs.fortytwo.io</li> <li>Product and services datas sheets</li> <li>Security</li> <li>General security briefings and heads-up to customers</li> <li>How-tos and guides with no customer specific information</li> </ul>"},{"location":"Generic/Fortytwo%20information%20labelling/#standard","title":"Standard","text":"<p>Information intended for members of Fortytwo Technologies organization only. Information in this category should not be shared outside of Fortytwo information domain, however - the information in this class would not present financial or legal risk if shared outside of Fortytwo information domain.</p> <p>Examples of information</p> <ul> <li>Product documentation</li> <li>Internal guidelines, code of conduct or employee benefits</li> </ul>"},{"location":"Generic/Fortytwo%20information%20labelling/#restricted","title":"Restricted","text":"<p>Information limited to named recipients, which can be both internal or external to Fortywo Technologies. Restricted is to be used when the information needs to be secured as instructed in laws or regulations, or if its content could be damaging Fortytwo technologies, either financially or through loss of reputation.</p> <p>Examples of information</p> <ul> <li>Business strategic information </li> <li>Security incident handling with customers</li> <li>Customers system documentation</li> </ul> <p>## GDPR ##   </p> <p>Data and information which is subject to protection under GDPR, this includes both basic basic information like names and addresses, but also more sensitive categories, such as special categories of personal data which reveal racial or ethnic origin, political or religious beliefs, trade union membership, genetic or biometric data, and data concerning health, sex life, or sexual orientation</p> <ul> <li>Information containing PII for employees<ul> <li>Name, address, date of birth, and telephone number</li> <li> <ul> <li>Identification numbers like Social Security Numbers or passport numbers</li> </ul> </li> <li>IP adresses, online cookies, and other online identifiers</li> <li>Location data</li> <li>Images and videos</li> <li>Financial information</li> <li>School or employment records</li> </ul> </li> </ul>"},{"location":"Generic/shared_teams_channel/","title":"Shared Teams channel","text":"<p>Hello there! If you have gotten the link to this guide shared with you, it means that Fortytwo have already agreed to set up a shared channel between our organizations, and we've prepared the setup on our side.</p> <p>This guide is for you to set up and verify the needed configuration in your tenant to be able to join the shared channel.</p>"},{"location":"Generic/shared_teams_channel/#configure-cross-tenant-access-settings-in-entra-id","title":"Configure cross-tenant access settings in Entra ID","text":"RBAC roles needed <p>User with Security Administrator or Global Administrator role is needed to make these changes in Entra ID.</p> Time to effect <p>Changes to cross-tenant access settings may take up to six hours to take effect.</p> <p>Sign in to Entra admin center using your account with the required access. Under \"Identity\" in the menu, select \"External Identities\", and then select \"Cross-tenant access settings\".</p> <p></p> <p>Select the tab \"Organizational settings\", and then click \"Add organization\". On the \"Add organization\" pane, type the full domain name for our organization \"fortytwo.io\" and press \"Enter\". It should populate the field \"Name\" with \"Fortytwo\", and then click the button for \"Add\".</p> <p></p> <p>Our organization should appear in the organizations list. At this point, all access settings for this organization are inherited from your default settings.</p>"},{"location":"Generic/shared_teams_channel/#configure-outbound-settings","title":"Configure outbound settings","text":"<p>Select the \"Outbound access\" link for our organization.</p> <p></p> <p>On the \"B2B direct connect\" tab, click the button for \"Customize settings\". On the \"External users and groups\" tab, choose \"Allow access\" and set \"Applies to\" to a group or spesific users, or to \"All &lt;org.name&gt; users\" if you allow all users in your organization to be invited to shared channels.</p> <p></p> <p>On the \"External applications\" tab, choose \"Allow access\" and \"Select external applications\". Click \"Add Microsoft applications\".</p> <p></p> <p>Select the \"Office 365\" application, and then click the button \"Select\".</p> <p></p> <p>Click the button \"Save\", choose \"Yes\" to confirm, and close the \"Outbound access settings\" blade.</p>"},{"location":"Generic/shared_teams_channel/#verify-teams-configuration","title":"Verify Teams configuration","text":"RBAC roles needed <p>User with Teams Administrator role is needed to make these changes in Teams.</p> <p>Shared channels is enabled by default in Teams. Follow this procedure to confirm the settings.</p>"},{"location":"Generic/shared_teams_channel/#verify-teams-policy","title":"Verify Teams policy","text":"<p>In the Teams admin center, expand \"Teams\", and then select \"Teams policies\".</p> <p></p> <p>Select the policy that applies to the user(s) that should be allowed to be invited to external channels. If you've previously done no customization, only \"Global (org wide default)\" will be listed. Select \"Edit\" on the policy.</p> <p></p> <p>Make sure that \"Join external shared channels\" is set to \"On\". If it is \"Off\", click the toggle to turn it on, and then click \"Apply\".</p>"},{"location":"Generic/shared_teams_channel/#completion","title":"Completion","text":"<p>You have now completed the configuration needed to join the shared channel. Please give us feedback that is done. Your users will get invited to the shared channel by our team.</p>"},{"location":"Generic/shared_teams_channel/#references","title":"References","text":"<ul> <li>Collaborate with external participants in a shared channel (IT Admins)</li> <li>Video demonstration</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/","title":"Getting started","text":""},{"location":"Managed%20Azure%20AD%20B2C/#table-of-contents","title":"Table of contents","text":"<ul> <li>Getting started</li> <li>Table of contents</li> <li>Introduction</li> <li>Quickstart</li> <li>The intent</li> <li>Modern authentication</li> <li>The pieces of the puzzle</li> <li>The magic is in the making</li> <li>Templates</li> <li>What are you waiting for?</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/#introduction","title":"Introduction","text":"<p>Here lies the documentation for the Managed Azure AD B2C solution that is available in the Azure Marketplace.</p>"},{"location":"Managed%20Azure%20AD%20B2C/#quickstart","title":"Quickstart","text":"<p>Go to Customer Identity Access Management and the Identity Experience Framework to go through the B2C Identity Platform documentation.</p>"},{"location":"Managed%20Azure%20AD%20B2C/#the-intent","title":"The intent","text":"<p>The intention is to improve the understanding of the Microsoft Identity Platform and the Identity Experience Framework, which we use as our building blocks for the Fortytwo Managed AD B2C Azure Marketplace offering.</p>"},{"location":"Managed%20Azure%20AD%20B2C/#modern-authentication","title":"Modern authentication","text":"<p>The section on modern authentication protocols, OpenID Connect (preferred) and SAML, will provide insight into how these protocols work and how to leverage them when integrating your application with the Microsoft Identity Platform.</p>"},{"location":"Managed%20Azure%20AD%20B2C/#the-pieces-of-the-puzzle","title":"The pieces of the puzzle","text":"<p>For a complete integration there are various parts that must be in place:</p> <ul> <li>App registrations</li> <li>With necessary configuration</li> <li>User Journeys</li> <li>Sign Up Sign In User Journey is included (_v2_)</li> <li>Authentication libraries for the app integration code (MSAL, MSAL.x)</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/#the-magic-is-in-the-making","title":"The magic is in the making","text":"<p>Putting all of this together usually takes some time and past experience always helps. So, in order to speed up this process we have here gathered and organized the essential information in one place. This tells the complete integration story, from start to finish. However, the tenant specific details such as User Journeys, app registration identifiers, secrets, and more, is found in the tenant of the Identity Platform.</p> <p>Remember, for a successful integration, the tenant specific settings must be used, which should be safely stored in your environment. The integration documentation is recommended to keep close to the Identity platform code, preferably in the same repository. This ensures that all relevant information is easy to find and that it (hopefully) gets continously updated.</p>"},{"location":"Managed%20Azure%20AD%20B2C/#templates","title":"Templates","text":"<p>To make it easy to find the necessary information for performing an app integration we use templates to store the parameters.</p> <p>For every environment there will be a unique set of parameters and configuration.</p> <p>There are templates for app registrations, User Journeys and custom policy files.</p> <p>Fill in the templates and store the documents with the code (best practice). This documentation is a vital part of each Identity Platform.</p> <p>The tenant specific configuration is required for users that are about to integrate an application with the Identity Platform.</p>"},{"location":"Managed%20Azure%20AD%20B2C/#what-are-you-waiting-for","title":"What are you waiting for?","text":"<p>Go to Customer Identity Access Management and the Identity Experience Framework and start the Journey of making your application a part of the new Identity Platform.</p> <p>If you do not already have a B2C tenant or simply wish to try out our offering, go to Azure Marketplace, select Get It Now, configure delegation details and send us an email at helloATfortytwo.io and we will provision you a complete B2C environment using our pipelines.</p>"},{"location":"Managed%20Azure%20AD%20B2C/a-CIAM-IEF-introduction/","title":"Microsoft B2C and the Identity Experience Framework","text":""},{"location":"Managed%20Azure%20AD%20B2C/a-CIAM-IEF-introduction/#table-of-contents","title":"Table of contents","text":"<ul> <li>Microsoft B2C and the Identity Experience Framework</li> <li>Table of contents</li> <li>Identity Framework Experience, customizable and scalable</li> <li>Secure identity management</li> <li>Integrating</li> <li>Microsoft Graph API</li> <li>Going forward<ul> <li>Find the app type for your app registration</li> <li>Authorization and authentication protocols</li> </ul> </li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/a-CIAM-IEF-introduction/#identity-framework-experience-customizable-and-scalable","title":"Identity Framework Experience, customizable and scalable","text":"<p>The Microsoft Identity Experience Framework (IEF) is allows for full flexibility of the Microsoft Identity B2C platform. The IEF provides you applications secure and reliable identity management and can craft fully customizable User Journeys. The service is highly available, it spans globally and is built to scale to millions of identities. With a fully operational Identity Platform, application developers can focus on creating core functionality and easily integrate their applications with the B2C platform for secure authentication, while not having to worry about identity management.</p>"},{"location":"Managed%20Azure%20AD%20B2C/a-CIAM-IEF-introduction/#secure-identity-management","title":"Secure identity management","text":"<p>The user directory of the B2C tenant, in tandem with the IEF, provide secure and scalable identity management. The Identity Experience Framework platform supports modern protocols for integration, full claims management flexibility, user tracking and the possibility of extension attributes for extending identity objects.</p> <p>Single sign-on (SSO) is readily available and delivered out of the box.</p>"},{"location":"Managed%20Azure%20AD%20B2C/a-CIAM-IEF-introduction/#integrating","title":"Integrating","text":"<p>There are two types of accounts; local accounts and external (federated) accounts.</p> <p>Local accounts authenticate with the B2C directory, external accounts authenticate with their respective identity providers (IDPs) allowing users to sign in with an existing account. When configured, users can select to sign in using an account from a public IDP like Google, LinkedIn and / or a commercial IdP, for example Vipps and ID-porten (Norway only). The only requirement is that the IdP supports either OpenID Connect or Security Assertion Markup Language 2.0 (SAML). Using SAML is a fully supported alternative, however OpenID Connect is preferred, for both flexibility and ease of use.</p>"},{"location":"Managed%20Azure%20AD%20B2C/a-CIAM-IEF-introduction/#microsoft-graph-api","title":"Microsoft Graph API","text":"<p>If an app already has an existing user database and we want to migrate the user accounts, we can use REST API queries. Using an App Service or Function App, we can extend the User Journey capability and expand the data exchange flexibility. This way we can add custom code and configure Just-In-Time (JIT) user migration scenarios, and we can pre-provision users in the B2C directory using the Microsoft Graph API.</p>"},{"location":"Managed%20Azure%20AD%20B2C/a-CIAM-IEF-introduction/#going-forward","title":"Going forward","text":"<p>To integrate an application with the Identity Experience Framework it may be useful to dive into Authorization and authentication protocols to better understand the technical requirements.</p> <p>Integrating an application with the Identity platform requires an app registration, see find the app type for your app registration</p>"},{"location":"Managed%20Azure%20AD%20B2C/a-CIAM-IEF-introduction/#find-the-app-type-for-your-app-registration","title":"Find the app type for your app registration","text":"<p>The first step to getting started with the application and Identity platform integration is to create an app registration (though it may prove useful to read through this documentation first). The app registration will be created based on the type of application that you will be integrating. Creating an app registration can be done by anyone holding the Application Developer or Application Administrator (or more privileged) role.</p> <p>What type is your app goes into detail on the mandatory and optional settings needed to be configured for an app integration to function.</p> <p>Requesting an application registration explains the app registration process. Based on the provided information you will be able create a new app registration, or make a request for an app registration to created on your behalf.</p> <p>Using an app registration allows your application to integrate with the Identity platform, enabling it to request, manage and validate issued tokens for either user or app authentication and authorization.</p>"},{"location":"Managed%20Azure%20AD%20B2C/a-CIAM-IEF-introduction/#authorization-and-authentication-protocols","title":"Authorization and authentication protocols","text":"<p>Once an app registration has been created it is important to decide on authentication protocols and authorization used by the application.</p> <p>Understanding OAuth 2.0 and OpenID Connect protocols will provide information on the preferred protocols using a flow chart and explaining and illustrating the available OAuth 2.0 grant types and when they are applicable.</p>"},{"location":"Managed%20Azure%20AD%20B2C/b-Application-integration/","title":"Application integration","text":""},{"location":"Managed%20Azure%20AD%20B2C/b-Application-integration/#table-of-contents","title":"Table of contents","text":"<ul> <li>Application integration</li> <li>Table of contents</li> <li>Introduction</li> <li>Getting started with application integration</li> <li>App registrations</li> <li>Identity Experience Framework - custom policies</li> <li>Authentication and authorization</li> <li>Application integration examples</li> <li>Other</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/b-Application-integration/#introduction","title":"Introduction","text":"<p>A good place to start is the Microsoft Learn page Technical and feature overview of Azure Active Directory B2C.</p> <p>When reading the section Identity experiences: user flow or custom policies know that in the current implementation we are leveraging custom policies for the User Journeys.</p> <p>In Protocols and tokens the you will find the supported modern authentication protocols.</p>"},{"location":"Managed%20Azure%20AD%20B2C/b-Application-integration/#getting-started-with-application-integration","title":"Getting started with application integration","text":"<p>As a developer it is beneficial to understand the Identity platform, how to perform integration with your application, and what is to be expected from a successful integration.</p> <p>First step; register a new app registration.</p> <p>Create an app registration or request one to be provisioned, if that is the process. The app registration details, including secret (if applicable), are required for the application to be able to communicate with the Identity platform.</p> <p>See Creating or requesting an app registration to find out what information you must provide.</p> <p>App registrations must be created by a privileged user (Application Developer, Application Administrator or more privileged role admin). Usually, an app is either created in the Azure Portal or declared in infrastructure as code (IaC), using Terraform or Bicep, as a couple of examples.</p> <p>NOTE!</p> <p>The recommended way to manage app registrations is through infrastructure as code. The IaC approach reduces the chance of configuration drift across environments. Additionally, it may serve as an added backup as any manual change can be reverted back by running the pipeline again. When using Terraform, for DEV environments, consider allowing manual changes (lifecycle -&gt; ignore_changes) for redirect_uri, api and required_resource_access</p>"},{"location":"Managed%20Azure%20AD%20B2C/b-Application-integration/#app-registrations","title":"App registrations","text":"<p>These pages contain lists of the available application registrations for the various environments:</p> <ul> <li>DEV app registrations</li> <li>TEST app registrations</li> <li>PROD app registrations</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/b-Application-integration/#identity-experience-framework-custom-policies","title":"Identity Experience Framework - custom policies","text":"<p>NOTE!</p> <p>The Microsoft Identity platform introduces the policy parameter. With the policy parameter, you can use OAuth 2.0 to add policies to your app, such as sign-up, sign-in, and profile management user flows.</p> <p>Source: Single-page application sign-in using the OAuth 2.0 implicit flow in Azure Active Directory B2C</p> <p>When integrating an application with the B2C environment the policy parameter (SignUpSignInPolicyId) must be provided. This is a parameter that enables a user flow / custom policy (often called User Journey) to be executed by an application depending on the user initiated scenario.</p> <p>For each environment these are the available custom policies:</p> <ul> <li>DEV custom polices</li> <li>TEST custom policies</li> <li>PROD custom policies</li> </ul> <p>Built-in policies (as opposed to custom policies) are also referred to as User flows, these are not used.</p> <p>Custom policies are what the Identity Experience Framework use to define User Journeys. Custom policies support everything from easy to the most complex authentication and migration scenarios.</p> <p>Here are some templates, one per environment, as an example of how to list the available User Journeys:</p> <ul> <li>User Journeys in DEV</li> <li>User Journeys in TEST</li> <li>User Journeys in PROD</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/b-Application-integration/#authentication-and-authorization","title":"Authentication and authorization","text":"<p>With a policy in place and ready to be tested it is time to integrate your application with the Identity platform. To update yourself, read through Identity platform: Authentication and Authorization. This section describes the supported authentication protocols and also goes into the available OAuth2 grant flows that can be used.</p> <p>In the sub-pages of this section, among other things, token validation is mentioned. This is important to read and understand as security is always important to consider, and paramount for integrations like these.</p>"},{"location":"Managed%20Azure%20AD%20B2C/b-Application-integration/#application-integration-examples","title":"Application integration examples","text":"<p>A quite common scenario, is to integrate (JavaScript) Single-Page architecture (SPA) applications.</p> <p>These Microsoft Learn articles explain how to configure and integrate a web app and a web API:</p> <ul> <li>Configure authentication in a sample single-page application by using Azure AD B2C</li> <li>Configure authentication in a sample Node.js web API by using Azure Active Directory B2C</li> </ul> <p>There are also tutorials for integrating using other languages like Python and C# (ASP.NET / WPF app):</p> <ul> <li>Configure authentication in a sample web app by using Azure AD B2C</li> <li>Configure authentication in a sample Python web app by using Azure AD B2C</li> <li>Configure authentication in a sample WPF desktop app by using Azure AD B2C</li> </ul> <p>A common prerequisite, all samples must have an app registration. This is a re-occurring theme early on in the mentioned articles.</p> <p>When using web APIs an application registration is also required for these. The APIs must be configured to expose one or more scopes and the web application must be granted appropriate delegated permissions (OAuth delegation).</p>"},{"location":"Managed%20Azure%20AD%20B2C/b-Application-integration/#other","title":"Other","text":"<p>Be aware of unsupported application types.</p> <p>Finally, Recommendations and best practices for Azure Active Directory B2C.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/","title":"Creating or requesting an app registration","text":""},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#table-of-contents","title":"Table of contents","text":"<ul> <li>Creating or requesting an app registration</li> <li>Table of contents</li> <li>Introduction</li> <li>Platform app registrations<ul> <li>What type of application are you integrating / developing</li> <li>If the application is a Web app the following information must be provided</li> <li>If the app is a single-page application please provide the following</li> <li>If is is a Web API this information is required</li> <li>And if it is a Native client this information is required</li> </ul> </li> <li>Application registration form<ul> <li>Create / request app registration form</li> <li>App registration answer form with information to configured in the application</li> <li>Example with two sample apps - create / request app registration</li> <li>Example with two sample apps - response after app registrations have been created</li> </ul> </li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#introduction","title":"Introduction","text":"<p>To create an app registration some information about the app must be provided.</p> <p>This information is essential to configure the app registration and provide it with API permissions (OAuth delegation), if necessary.</p> <p>As a rule of thumb, all environments should have the same app registrations, with the exception of DEV where applications that are under development may have their own development-only app registrations.</p> <ul> <li>DEV app registrations</li> <li>TEST app registrations</li> <li>PROD app registrations</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#platform-app-registrations","title":"Platform app registrations","text":"<p>Below are the four main application types and what properties they need configured:</p>"},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#what-type-of-application-are-you-integrating-developing","title":"What type of application are you integrating / developing","text":"<ul> <li>Web app</li> <li>Single-page app</li> <li>Web API</li> <li>Native client (mobile app / desktop app)</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#if-the-application-is-a-web-app-the-following-information-must-be-provided","title":"If the application is a Web app the following information must be provided","text":"<ul> <li>What is the name of your application</li> <li>What environment will the application be integrated with (DEV / TEST / PROD)</li> <li>Is it an OpenID Connect integration</li> <li>What redirect_uri (reply URL) should be allowed for returning tokens</li> <li>What API permissions (resources), if any, and scopes does the application need access to</li> </ul> <p>Once an app registration is created a secret (client_secret) will be provisioned, which must be provided by the application when calling the Microsoft Identity Platform /authorize endpoint.</p> <p>IMPORTANT!</p> <p>If using Infrastructure-as-Code (IaC) principles the app registration client_secret can be put into an Azure Key Vault for safe keeping. App registration secrets can only be viewed (once) and must be copied immediately after resource creation.</p> <p>The implementation of Proof Key for Code Exchange (PKCE) is supported (and recommended to use) for single-page apps (SPA), which are often JavaScript-based. However, mobile, desktop and now also web apps (confidential clients), as described in Application types for Microsoft identity platform are recommended to implement PKCE.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#if-the-app-is-a-single-page-application-please-provide-the-following","title":"If the app is a single-page application please provide the following","text":"<ul> <li>What is the name of your application</li> <li>What environment will the application be integrated with (DEV / TEST / PROD)</li> <li>What redirect_uri (reply URL) should be allowed for returning tokens</li> <li>What API permissions (resources), if any, and scopes does the application need access to</li> </ul> <p>IMPORTANT!</p> <p>For single-page apps, avoid using Implicit flow. This authentication method should not be used in production (nor any) environments. It's highly recommended to also avoid enabling it in DEV as authorization code flow with PKCE is the secure and recommended approach.</p> <p>When developing in JavaScript, make sure to use MSAL.js 2.x (at a minimum) package as versions prior to 2.x ONLY support the implicit code flow.</p> <p>The quote below is from the Microsoft Docs article Tutorial: Sign in users and call the Microsoft Graph API from a JavaScript SPA using auth code flow:</p> <p>MSAL.js 2.x improves on MSAL.js 1.0 by supporting the authorization code flow in the browser instead of the implicit grant flow. MSAL.js 2.x does NOT support the implicit flow.</p> <p>See here for detailed information on the Proof Key for Code Exchange by OAuth Public Clients standard.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#if-is-is-a-web-api-this-information-is-required","title":"If is is a Web API this information is required","text":"<ul> <li>What is the name of your application</li> <li>What environment will the application be integrated with (DEV / TEST / PROD)</li> <li>The name of scopes the API exposes / publishes for consumption by other applications (e.g. read, write, user_impersonation)</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#and-if-it-is-a-native-client-this-information-is-required","title":"And if it is a Native client this information is required","text":"<ul> <li>What is the name of your application</li> <li>What environment will the application be integrated with (DEV / TEST / PROD)</li> <li>What API permissions (resource) and scopes does the application need access to</li> <li>What redirect_uri (reply URL) should be allowed for returning tokens</li> </ul> <p>A redirect_uri for native apps using Microsoft Authentication Library may look like</p> <ul> <li>msalAPPID://auth</li> <li>urn:ieft:wg.oauth:2.0:oob</li> <li>https://{tenantName}.b2clogin.com/oauth2/nativeclient</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#application-registration-form","title":"Application registration form","text":""},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#create-request-app-registration-form","title":"Create / request app registration form","text":"<p>This is a template that can be used when creating or requesting an app registration:</p> Name Type Reply URLs Allow implicit flow Scope API Permissions Environment"},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#app-registration-answer-form-with-information-to-configured-in-the-application","title":"App registration answer form with information to configured in the application","text":"<p>This is a template that can be used once an app registration has been created:</p> Name Type Reply URLs Allow implicit flow Scope API Permissions Client ID Client Secret Environment"},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#example-with-two-sample-apps-create-request-app-registration","title":"Example with two sample apps - create / request app registration","text":"Name Type Reply URLs Allow implicit flow Scope API Permissions Environment Mirage Web Web App https://localhost/web/auth https://mydev.environment.net/auth false N/A Mirage API (user_impersonation) Dev Mirage API API https://localhost/api/auth false user_impersonation N/A Dev"},{"location":"Managed%20Azure%20AD%20B2C/c1-Creating-an-app-registration/#example-with-two-sample-apps-response-after-app-registrations-have-been-created","title":"Example with two sample apps - response after app registrations have been created","text":"Name Type Reply URLs Allow implicit flow Scope API Permissions Client ID Client Secret Environment Mirage Web Web App https://localhost/web/auth https://mydev.environment.net/auth false N/A Mirage API (user_impersonation) &lt;appId&gt; &lt;appSecret&gt; Dev Mirage API API https://localhost/api/auth false user_impersonation N/A &lt;appId&gt; N/A Dev"},{"location":"Managed%20Azure%20AD%20B2C/c2-DEV-App-registrations/","title":"DEV - tenant.onmicrosoft.com - app registrations","text":""},{"location":"Managed%20Azure%20AD%20B2C/c2-DEV-App-registrations/#table-of-contents","title":"Table of contents","text":"<ul> <li>DEV - tenant.onmicrosoft.com - app registrations</li> <li>Table of contents</li> <li>Introduction</li> <li>Management<ul> <li>Developers and operators</li> <li>Infrastructure as Code</li> <li>App registrations owned by company IaC</li> <li>Allow changes to app registrations outside of IaC</li> <li>App registrations with secrets</li> </ul> </li> <li>App registrations matrix</li> <li>App registration secrets</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/c2-DEV-App-registrations/#introduction","title":"Introduction","text":"<p>Every tenant will have a list of app registrations that are used in application integrations. Even though the app registration names and permissions are set up identically across environments, app id (client_id) and app secret (client_secret) will NOT be identical.</p> <p>Using the below matrix it is possible to see what app registrations exist in an environment at a given time.</p> <p>A development environment may have app registrations that TEST and PROD does not have, namely as it is an environment used for ongoing development.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c2-DEV-App-registrations/#management","title":"Management","text":"<p>A development environment should be a safe place for developers and operators both, where ideas and creativity can unfold, functionality can be tested.</p> <p>For resources deployed in DEV there are various options, including the opposites of defining everything in code and not using infrastructure as code (IaC) at all.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c2-DEV-App-registrations/#developers-and-operators","title":"Developers and operators","text":"<p>Developers may need rapid changes and should be self-sufficient when it comes to application development, application integration, application permissions and identity management.</p> <p>As a pre-requisite; developers must be assigned sufficient permissions, and with this in place they should be able to actively interact with all connected parts of the development environment.</p> <p>Operators and developers can both hold top permissions in any CIAM tenant, especially if it's a development environment. This will allow for the most agile development process where changes may occur often and come about quickly. Our goal should be to enable developers, rather build guard rails than motes.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c2-DEV-App-registrations/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>App registration creation and maintenance can be divided into these categories:</p> <ul> <li>Defined and owned by company IaC</li> <li>Defined and owned by Fortytwo (managed service provider) IaC</li> <li>Manually created and / or maintained by company or Fortytwo</li> </ul> <p>In a development environment it is not uncommon to find app registrations fitting all these categories.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c2-DEV-App-registrations/#app-registrations-owned-by-company-iac","title":"App registrations owned by company IaC","text":"<p>This list of app registrations will include applications developed (or implemented) by the company:</p> <ul> <li>companyApp - web app - dev</li> <li>JWT.ms (owned by Fortytwo IaC, for User Journey testing and token issuance)</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/c2-DEV-App-registrations/#allow-changes-to-app-registrations-outside-of-iac","title":"Allow changes to app registrations outside of IaC","text":"<p>In the development environment app registrations must be flexible to changes, also those that do not originate in IaC. When using IaC tool Terraform (TF), which uses a state file to monitor deployed resources, changes made outside of TF are usually reversed (because state if owned by TF). Terraform supports the setting lifecycle which tells the terraform resource provider to ignore changes.</p> <p>Example for app registrations, to allow manual changes to redirect_uris as they are configured as part of the web block in the Terraform app registration resource definition:</p> <pre><code>lifecycle {\n\u00a0\u00a0\u00a0 ignore_changes [\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 web\n\u00a0\u00a0\u00a0 ]\n}\n</code></pre> <p>Changes in an app registration that may need to be changed include (but are not limited to):</p> <ul> <li>redirect_uris</li> <li>implicit flow settings</li> <li>secrets</li> <li>API permissions</li> <li>exposed APIs</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/c2-DEV-App-registrations/#app-registrations-with-secrets","title":"App registrations with secrets","text":"<p>A confidential client (web application), requires a client_secret to securely integrate with the Identity platform. A public client (single-page application, mobile application) can't be trusted with a client_secret (any secret used would be exposed in the client browser / app).</p> <p>Applications needing a client_secret:</p> <ul> <li>companyApp - web app - dev</li> </ul> <p>Look to app registration secrets for details on application secret management.</p> <p>Secret management is imperative as secrets need to be cycled regularly to minimize the risk of credential compromise. A functioning regular secret change strategy is important because applications must have access to a valid secret at run-time to start the application.</p> <p>The most common placement for secrets is Azure Key Vault, where access policies and managed identities can be used to restrict and grant access to sensitive data.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c2-DEV-App-registrations/#app-registrations-matrix","title":"App registrations matrix","text":"Name Type Reply URLs Allow implicit flow Scope API Permissions Client ID Client Secret Environment Comments JWT.ms Web App https://jwt.ms/ access_token id_token N/A Graph: openid+offline_access &lt;appId&gt; N/A Dev Any IDP - AzureADandPersonalMicrosoftAccount - User Journey test app companyApp - web app - dev Web App &lt;replyUrl&gt; N/A N/A Graph openid+offline_access &lt;appId&gt; &lt;appSecret&gt; Dev Any IDP"},{"location":"Managed%20Azure%20AD%20B2C/c2-DEV-App-registrations/#app-registration-secrets","title":"App registration secrets","text":"<p>Creating a streamlined process for the handling of sensitive app registration information both adds security and accessibility.</p> <p>There will be Azure Key Vaults for applications that require client secrets for interaction.</p> Name Type Azure Key Vault Client ID Environment Comments companyApp - web app - dev Web App URIx &lt;appId&gt; Dev company - iac - identity N/A URIx &lt;appId&gt; Dev Owned by company, service principal for running IaC (may be stored in Key Vault / DevOps library variable group)"},{"location":"Managed%20Azure%20AD%20B2C/c3-TEST-App-registrations/","title":"TEST - tenant.onmicrosoft.com - app registrations","text":""},{"location":"Managed%20Azure%20AD%20B2C/c3-TEST-App-registrations/#table-of-contents","title":"Table of contents","text":"<ul> <li>TEST - tenant.onmicrosoft.com - app registrations</li> <li>Table of contents</li> <li>Introduction</li> <li>Management<ul> <li>Developers and operators</li> <li>Infrastructure as Code</li> <li>App registrations owned by company IaC</li> <li>App registrations with secrets</li> </ul> </li> <li>App registrations matrix</li> <li>App registration secrets</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/c3-TEST-App-registrations/#introduction","title":"Introduction","text":"<p>Every tenant will have a list of app registrations that are used in application integrations. Even though the app registration names and permissions are set up identically across environments, app id (client_id) and app secret (client_secret) will NOT be identical.</p> <p>Using the below matrix it is possible to see what app registrations exist in an environment at a given time.</p> <p>A test environment (often referred to as pre-prod) has the exact same app registrations, and app registration configuration, as production. It is a staging environment where all changes are deployed and tested thoroughly before they are released to PROD.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c3-TEST-App-registrations/#management","title":"Management","text":"<p>The B2C TEST environment should have reasonably strict change management. Changes should go through an approval gate where at least one person, not including the author, must approve deployment of changes.</p> <p>Developers should not need to interact much with this environment, with the exception of approving changes or perform system testing.</p> <p>Operators should make sure that the TEST environment is primarily changed via infrastructure as code (Iac). This will ensure the highest probability of functionality remaining operational in TEST, while also working when released to PROD.</p> <p>Resources in a TEST environment should preferably be deployed using IaC. Situations may occur where it is sensible to perform temporary, manual, changes to the environment. For example when a test fails and a quick fix can be manually implemented to try to (bug)fix the issue.</p> <p>The primary reason for avoiding manual configuration is the increased risk of configuration drift between environments, especially TEST and PROD.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c3-TEST-App-registrations/#developers-and-operators","title":"Developers and operators","text":"<p>Unlike in the development environment, developers will usually not need to hold high privilege permissions in TEST (pre-prod). App registrations should be configured with fully qualified domain name redirect uris (reply urls) to mimic the production environment.</p> <p>Changes made to TEST environment should be discussed before deployment, to avoid temporary-permanent changes being made.</p> <p>Operators hold top permissions in all environments, and for a test environment, where (ideally) all resources are defined in code, developers should not need to be highly privileged.</p> <p>However, all parties in a Platform team should be able to participate in the approval process for code being committed and changes being rolled out in the environment. To maintain a flowing process, multiple approvers must be appointed to quickly get changes introduced to the TEST environment, to avoid bottleneck approval gates.</p> <p>How many approvals a change requires before being merged, or the number of approvals to deploy a change, needs to be decided.</p> <p>Also worth noting, in some situations the ideal flow is for all changes that pass approvals in the development environment, to be automatically deployed to TEST, to adhere to the idea of small, incremental changes being introduced continuously.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c3-TEST-App-registrations/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>App registration creation and maintenance can be divided into these categories:</p> <ul> <li>Defined and owned by company IaC</li> <li>Defined and owned by Fortytwo (managed service provider) IaC</li> <li>Manually created and / or maintained by company or Fortytwo</li> </ul> <p>App registrations should only be defined by IaC in a test environment (exceptions should be few).</p>"},{"location":"Managed%20Azure%20AD%20B2C/c3-TEST-App-registrations/#app-registrations-owned-by-company-iac","title":"App registrations owned by company IaC","text":"<p>This list of app registrations will include applications developed (or implemented) by the company:</p> <ul> <li>companyApp - web app - test</li> <li>JWT.ms (owned by Fortytwo IaC, for User Journey testing and token issuance)</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/c3-TEST-App-registrations/#app-registrations-with-secrets","title":"App registrations with secrets","text":"<p>A confidential client (web application), requires a client_secret to securely integrate with the Identity platform. A public client (single-page application, mobile application) can't be trusted with a client_secret (any secret used would be exposed in the client browser / app).</p> <p>Applications needing a client_secret:</p> <ul> <li>companyApp - web app - test</li> </ul> <p>Look to app registration secrets for details on application secret management.</p> <p>Secret management is imperative as secrets need to be cycled regularly to minimize the risk of credential compromise. A functioning regular secret change strategy is important because applications must have access to a valid secret at run-time to start the application.</p> <p>The most common placement for secrets is Azure Key Vault, where access policies and managed identities can be used to restrict and grant access to sensitive data.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c3-TEST-App-registrations/#app-registrations-matrix","title":"App registrations matrix","text":"Name Type Reply URLs Allow implicit flow Scope API Permissions Client ID Client Secret Environment Comments JWT.ms Web App https://jwt.ms/ access_token id_token N/A Graph: openid+offline_access &lt;appId&gt; N/A Test Any IDP - AzureADandPersonalMicrosoftAccount - User Journey test app companyApp - web app - test Web App &lt;replyUrl&gt; N/A N/A Graph: openid+offline_access &lt;appId&gt; &lt;appSecret&gt; Test Any IDP"},{"location":"Managed%20Azure%20AD%20B2C/c3-TEST-App-registrations/#app-registration-secrets","title":"App registration secrets","text":"<p>Creating a streamlined process for the handling of sensitive app registration information both adds security and accessibility.</p> <p>There will be Azure Key Vaults for applications that require client secrets for interaction.</p> Name Type Azure Key Vault Client ID Environment Comments companyApp - web app - test Web App URIx &lt;appId&gt; Test company - iac - identity N/A URIx &lt;appId&gt; Test Owned by company, service principal for running IaC (may be stored in Key Vault / DevOps library variable group)"},{"location":"Managed%20Azure%20AD%20B2C/c4-PROD-App-registrations/","title":"PROD - tenant.onmicrosoft.com - app registrations","text":""},{"location":"Managed%20Azure%20AD%20B2C/c4-PROD-App-registrations/#table-of-contents","title":"Table of contents","text":"<ul> <li>PROD - tenant.onmicrosoft.com - app registrations</li> <li>Table of contents</li> <li>Introduction</li> <li>Management<ul> <li>Developers and operators</li> <li>Infrastructure as Code</li> <li>App registrations owned by company IaC</li> <li>App registrations with secrets</li> </ul> </li> <li>App registrations matrix</li> <li>App registration secrets</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/c4-PROD-App-registrations/#introduction","title":"Introduction","text":"<p>Every tenant will have a list of app registrations that are used in application integrations. Even though the app registration names and permissions are set up identically across environments, app id (client_id) and app secret (client_secret) will NOT be identical.</p> <p>Using the below matrix it is possible to see what app registrations exist in an environment at a given time.</p> <p>A production environment will have the exact same app registrations, and app registration configuration, as test. All processes related to the production environment should be automated, as far as possible, to reduce the chance of errors being introduced due to manual processes.</p> <p>The goal is for TEST and PROD environments to be identically configured, this way changes can flow from one environment to the other without requiring any additional changes or manual customization.</p> <p>Adequate testing should be made before releasing changes to production. It is important to build an efficient, but solid, testing regime. This trust can then be leveraged to enable and ensure that changes, and new features, can quickly flow from TEST to PROD.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c4-PROD-App-registrations/#management","title":"Management","text":"<p>The B2C PROD environment should have strict change management. Changes should go through an approval gate where at least one person, not including the author, must approve deployment of changes.</p> <p>If new features will be released, all involved parties, including support, should to be informed, because information sharing is key in a successful organization.</p> <p>Changes coming to PROD will have been verified in the TEST environment, and as for TEST, (if possible) all changes in PROD will be made using infrastructure as code (IaC).  </p> <p>Even though making changes and adding features in PROD has the most risk attached to it, it's important to build a trust system where changes are welcome, and not feared. Ideally, changes will come quickly and often, and during normal work hours.</p> <p>Amounts of releases and release schedule is something that each Platform team, and organization, must figure out for themselves, depending on their situation.</p> <p>The goal should be to not become risk-averse and rather welcome changes!</p>"},{"location":"Managed%20Azure%20AD%20B2C/c4-PROD-App-registrations/#developers-and-operators","title":"Developers and operators","text":"<p>Any change being made to PROD environment must be discussed in the Platform team.</p> <p>Operators hold top permissions in all environments, and more often than not, developers only need read permissions in a production environment.</p> <p>However, all parties in a Platform team should be able to participate in the approval process for code being committed to PROD as well as any changes being rolled out in PROD.  </p> <p>Changes to PROD environment must either be done on a schedule, or be well-informed in advance, to maintain the highest level of confidence of a successful deployment.  </p> <p>The number of approvals to deploy changes to PROD must be decided.</p> <p>As for TEST environment, it may be possible to reach a state where all changes that pass approvals in the test environment, are automatically deployed to PROD, to adhere to the idea of small, incremental changes being introduced continuously.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c4-PROD-App-registrations/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>App registration creation and maintenance should only fit this category:</p> <ul> <li>Defined and owned by company IaC</li> </ul> <p>App registrations must be defined by IaC in a production environment (except on very rare occasions).</p>"},{"location":"Managed%20Azure%20AD%20B2C/c4-PROD-App-registrations/#app-registrations-owned-by-company-iac","title":"App registrations owned by company IaC","text":"<p>This list of app registrations will include applications developed (or implemented) by the company:</p> <ul> <li>companyApp - web app - prod</li> <li>JWT.ms (owned by Fortytwo IaC, for User Journey testing and token issuance)</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/c4-PROD-App-registrations/#app-registrations-with-secrets","title":"App registrations with secrets","text":"<p>A confidential client (web application), requires a client_secret to securely integrate with the Identity platform. A public client (single-page application, mobile application) can't be trusted with a client_secret (any secret used would be exposed in the client browser / app).</p> <p>Applications needing a client_secret:</p> <ul> <li>companyApp - web app - prod</li> </ul> <p>Look to app registration secrets for details on application secret management.</p> <p>Secret management is imperative as secrets need to be cycled regularly to minimize the risk of credential compromise. A functioning regular secret change strategy is important because applications must have access to a valid secret at run-time to start the application.</p> <p>The most common placement for secrets is Azure Key Vault, where access policies and managed identities can be used to restrict and grant access to sensitive data.</p>"},{"location":"Managed%20Azure%20AD%20B2C/c4-PROD-App-registrations/#app-registrations-matrix","title":"App registrations matrix","text":"Name Type Reply URLs Allow implicit flow Scope API Permissions Client ID Client Secret Environment Comments JWT.ms Web App https://jwt.ms/ access_token id_token N/A Graph: openid+offline_access &lt;appId&gt; N/A Prod Any IDP - AzureADandPersonalMicrosoftAccount - User Journey test app companyApp - web app - prod Web App &lt;replyUrl&gt; N/A N/A Graph: openid+offline_access &lt;appId&gt; &lt;appSecret&gt; Prod Any IDP"},{"location":"Managed%20Azure%20AD%20B2C/c4-PROD-App-registrations/#app-registration-secrets","title":"App registration secrets","text":"<p>Creating a streamlined process for the handling of sensitive app registration information both adds security and accessibility.</p> <p>There will be Azure Key Vaults for applications that require client secrets for interaction.</p> Name Type Azure Key Vault Client ID Environment Comments companyApp - web app - prod Web App URIx &lt;appId&gt; Prod company - iac - identity N/A URIx &lt;appId&gt; Prod Owned by company, service principal for running IaC (may be stored in Key Vault / DevOps library variable group)"},{"location":"Managed%20Azure%20AD%20B2C/d2-IEF/","title":"The Identity Experience Framework","text":""},{"location":"Managed%20Azure%20AD%20B2C/d2-IEF/#table-of-contents","title":"Table of contents","text":"<ul> <li>The Identity Experience Framework</li> <li>Table of contents</li> <li>Introduction</li> <li>Custom policies</li> <li>Environments</li> <li>User Journey testing</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/d2-IEF/#introduction","title":"Introduction","text":"<p>The Identity Experience Framework supports custom policies.</p> <p>User flows are getting a new home in Microsoft Entra External ID for customers and are well-suited for getting started quickly, custom policies provide a far greater flexibility.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d2-IEF/#custom-policies","title":"Custom policies","text":"<p>Identity Experience Framework custom policies are developed using Extensible Markup Language (XML). The custom policies are constructed from a hierarchical chain contained within the TrustFrameworkPolicy element.</p> <p>The XML code is usually split into (at least) three files, a base policy file, an extension policy file and a relying party (execution policy) file. If there is a requirement to support other languages than English, all the LocalizedResources references would be organized in a dedicated language file that extends the chain by one member, base, language, extension and execution policy.</p> <p>When a User Journey is triggered, the code from all chained XML-formatted files are merged according to the inheritance model.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d2-IEF/#environments","title":"Environments","text":"<p>Each environment make out it's own Identity Platform and are configured using CI/CD (continous integration/deployment).</p> <ul> <li>DEV - \\.onmicrosoft.com (placeholder for DEV template) <li>TEST - \\.onmicrosoft.com (placeholder for TEST template) <li>PROD - \\.onmicrosoft.com (placeholder for PROD template) <p>For each environment there are a number of User Journeys. The policy files behind the User Journeys are identical in name and functionality but contain tenant-specific application identifiers, different keys and other references.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d2-IEF/#user-journey-testing","title":"User Journey testing","text":"<p>Links to trigger the policies in each of B2C tenants can be found in the corresponding environment's document.</p> <p>The links provided triggers the User Journeys based on the Microsoft JWT.ms web application. This is the URL where the token and user is redirected after completing the User Journey.</p> <p>The JWT.ms app is very helpful to get an idea of how User Journeys look visually, test and verify the functionality and see what claims are emitted in the id_token once the session successfully concludes.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/","title":"Custom branding - sign-in pages","text":""},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#table-of-contents","title":"Table of contents","text":"<ul> <li>Custom branding - sign-in pages</li> <li>Table of contents</li> <li>Introduction</li> <li>Custom branding<ul> <li>Custom branding files</li> <li>Maintaining custom branding files</li> <li>Azure portal</li> <li>Azure Storage Explorer</li> <li>Azure CLI (Command-Line Interface)</li> <li>PowerShell script B2C-BlobManagement.ps1<ul> <li>Script pre-requisites</li> <li>Script availability</li> </ul> </li> <li>Script updates - public repository<ul> <li>Script execution</li> <li>Script variables - manually configured section</li> <li>Script variables - tips and notes</li> </ul> </li> </ul> </li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#introduction","title":"Introduction","text":"<p>The sign-in pages are made of up html, css and javascript (js) files. Left un-configured they are rendered using the Microsoft classic theme.</p> <p>The better and more modern alternative themes, Slate Gray and Ocean Blue, are available. These can quite easily be put to use, see the Microsoft Learn article branding with custom policies.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#custom-branding","title":"Custom branding","text":"<p>In most cases the Microsoft pre-built themes are used for initial setups. Even though design and user interface may be part of the early design, usually this work is not prioritized. As the User Journeys are fully developed the focus turns to user experience. The user experience is important both in terms of functionality and visualization, the latter inferring custom branding.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#custom-branding-files","title":"Custom branding files","text":"<p>The custom branding files are often stored in an Azure storage account in the container branding. The container is protected (the default) authentication method Access key. It is possible to configure authentication method Azure AD User Account for the container.</p> <p></p> <p>The container is configured with access level Blob (anonymous read access for blobs only).</p> <p></p> <p>Each theme folder has html, css and js content divided into separate folders.</p> <p></p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#maintaining-custom-branding-files","title":"Maintaining custom branding files","text":"<p>There are at least four ways of interacting with an Azure storage account container. Depending on what operation to be taken, they all vary in their effectiveness.</p> <p>These four ways are sorted based on accessibility and user interaction vs automation:</p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#azure-portal","title":"Azure portal","text":"<p>Using the Azure Portal is the easiest way to access the branding container through the storage account. User accessing must have requisite privileges based on the configured authentication method. Using the Azure Portal the container can be access through either the Container or the Storage browser blade. The Storage browser is the online version of the Azure Storage Explorer.</p> <p></p> <p>This works reliably but is not very effective for uploading or downloading many files or a folder structure.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#azure-storage-explorer","title":"Azure Storage Explorer","text":"<p>Azure Storage Explorer is free for download and use. Can also be downloaded directly from the Azure Portal.</p> <p>Using this tool maintaining a container (or any storage account content) is made very easy. The tool is required to be installed locally. Once installed, resources from any tenant can be accessed through selected method of authentication. The Azure Storage Explorer is user-friendly but like any user-driven interactive tool, is potentially error prone.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#azure-cli-command-line-interface","title":"Azure CLI (Command-Line Interface)","text":"<p>Azure CLI can be downloaded and installed freely. It has a lot smaller footprint than Azure Storage Explorer and is more suitable for automation.</p> <p>Azure CLI is powered by Python. Once installed the light-weight command az (which is a .cmd file calling python.exe) provides a wide variety of possibilities.</p> <p> (This is only the first third of the base commands az can interact with)</p> <p>This tools is great for automation and even supports a sync functionality (in preview at the time of writing). This method (az storage blob sync functionality) provides the easiest way to keep files in parity between folders. Using az for automation is also the most straight-forward as the Azure CLI package is pre-installed on Azure Devops-based hosted agents.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#powershell-script-b2c-blobmanagementps1","title":"PowerShell script B2C-BlobManagement.ps1","text":"<p>The Powershell script B2C-BlobManagement was developed for bridging the gap between the various different tools.</p> <p>The advantage of this script is that it does not need installation, granted PowerShell script execution is enabled. The pre-requisite PowerShell modules are checked for at runtime and installed in user context if found missing (REMEMBER to check out the $NoTestPreReqsOverride) TIP!</p> <p>Using this script it is easy to both implement it in a pipeline as well as running it in authenticated user context. It's primary function is to upload files, set content type and set cache control on .js files (because they are prone to frequent updates).</p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#script-pre-requisites","title":"Script pre-requisites","text":"<p>The script does require the Powershell modules Az.Accounts and Az.Storage, which is checked at runtime.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#script-availability","title":"Script availability","text":"<p>The script is available on GitHub.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#script-updates-public-repository","title":"Script updates - public repository","text":"<p>If later updated, this version will be publicly available from this GitHub repository.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#script-execution","title":"Script execution","text":"<p>To run the script in a pipeline, the following input parameters must be provided:</p> <pre><code>B2C-BlobManagement.ps1 -TenantId tid -Subscription sub -ClientId id -ClientSecret secret -Subscription sub -ResourceGroup rg -StorageAccountName sa -ContainerName container -SourceFolder pathToFolder\n</code></pre> <p>This is a snippet from the script documentation, first .EXAMPLE, where more information can be found.</p> <p>For use on the command line, locally, the script requires a lot fewer parameters:</p> <pre><code>B2C-BlobManagement.ps1 -EnvPrefix d/t/p -Username myUser@myDomain.com -Upload:$true -Download:$false -SourceFolder C:\\GIT\\Source\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#script-variables-manually-configured-section","title":"Script variables - manually configured section","text":"<p><code>-EnvPrefix</code> must be provided as an input parameter when running the script locally. This parameter will fetch the environment variables for either development, test or production.</p> <p>TIP!</p> <p>When the script is executed locally the <code>-EnvPrefix</code> parameter MUST be included. This is regardless of all other parameters being passed as input parameters on the command line. Only when the script is run as part of an automated process and in the context of an app, can this be left out.</p> <p>This is for uploading files from a local folder to a storage account container (.EXAMPLE number four). Subscription, resource group and storage accounts must be provided in the script section Manually configured variables (see below).</p> <pre><code>#region Manually configured variables\n# Overrides for default values from param block\n$ContainerOverride #= \"branding\"\n$UploadOverride #= $true\n$DownloadOverride #= $false\n$NoTestPreReqsOverride #= $true\n\n## Container name, folder names and storage account names for various B2C environments\n$DestinationFolderD = \"C:\\GIT\\ProjectX\\branding dev\"\n$SourceFolderD = \"C:\\GIT\\ProjectX\\branding dev\"\n$StorageAccountNameD = \"storageAccountDev\"\n$ResourceGroupD = \"resourceGroupTest\"\n$SubscriptionD = \"d\"\n\n$DestinationFolderT = \"C:\\GIT\\ProjectX\\branding test\"\n$SourceFolderT = \"C:\\GIT\\ProjectX\\branding test\"\n$StorageAccountNameT = \"storageAccountTest\"\n$ResourceGroupT = \"resourceGroupTest\"\n$SubscriptionT = \"t\"\n\n$DestinationFolderP = \"C:\\GIT\\ProjectX\\branding prod\"\n$SourceFolderP = \"C:\\GIT\\ProjectX\\branding prod\"\n$StorageAccountNameP = \"storageAccountProd\"\n$ResourceGroupP = \"resourceGroupProd\"\n$SubscriptionP = \"p\"\n</code></pre> <p>All parameters can be provided on the command line. However, when running the script locally (frequently) it can be convenient to set persistent environment values. Values and names for the respective parameters can be provided by an Azure Administrator.</p> <p>It is a common practice to have three environments, development, test and production (names may vary). For consistency across environments the same name is used for the Azure Blob Container, <code>branding</code>. This can be overridden using in-script parameter <code>ContainerOverride</code> or by providing <code>-ContainerName</code> as input an parameter.</p> <ul> <li><code>DestinationFolderD</code> and <code>SourceFolderD</code> are used depending on the operation, download or upload.  </li> <li><code>StorageACcountNameD</code> is the name of the Azure Storage Account where the branding container is deployed.  </li> <li><code>ResourceGroupNameD</code> is the Azure Resource Group where the Storage Account is deployed.  </li> <li><code>SubscriptionNameD</code> is the Azure Subscription where the Resource Group is deployed.</li> </ul> <p>All these parameters can be provided as input parameters when executing the script.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d3-Custom-branding/#script-variables-tips-and-notes","title":"Script variables - tips and notes","text":"<p>TIP!</p> <p>When running the script multiple times on the same client the <code>$NoTestPreReqsOverride</code> can be set to <code>$true</code>. Alternatively, provide the <code>-NoTestPreReqs:$true</code> parameter as an input parameter. It is unnecessary to wait for the script to check for installed modules on every execution.</p> <p><code>-Upload:$false</code> and <code>-Download:$true</code> can be provided as input parameters when running the script. However, they can be omitted when uploading files as this is the scripts default behaviour.</p> <p>As for <code>-NoTestPreReqs</code>, the <code>-Upload</code> and <code>-Download</code> parameters can be set (overridden) in the BlobManagement script. The default behaviour can be changed by providing input parameters or by using in-script overrides <code>UploadOverride =</code> and <code>DownloadOverride =</code>.</p> <p>NOTE!</p> <p>Be aware that when using any of the in-script overrides, these settings take precedence over input parameters.</p> <p>The script implements SupportsShouldProcess and can be run with <code>-WhatIf</code> to verify the operation to be triggered.</p> <p>The script also supports deleting files from a container, using the <code>-Delete</code> input parameter. Its primary use is to delete all content in a storage container, useful for testing of file upload and download.</p> <p>By additionally providing parameter <code>-DeleteExtensions</code>, <code>-DeleteFolders</code> or <code>-DeleteFiles</code>, some granularity is possible.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d4-Custom-policies/","title":"Identity Experience Framework custom policies","text":""},{"location":"Managed%20Azure%20AD%20B2C/d4-Custom-policies/#table-of-contents","title":"Table of contents","text":"<ul> <li>Identity Experience Framework custom policies</li> <li>Table of contents</li> <li>Introduction</li> <li>Custom policy files</li> <li>Uploading policies to the Identity Experience Framework<ul> <li>B2C-PolicyManagement.ps1</li> <li>Script pre-requisites</li> <li>Script availability<ul> <li>Script execution</li> <li>Script variables</li> </ul> </li> </ul> </li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/d4-Custom-policies/#introduction","title":"Introduction","text":"<p>Custom policies builds on top of the Identity Experience Framework (IEF) and enables the creation of User Journeys tailor-made for any organizational need.</p> <p>Custom policies leverage XML syntax. The advantage is the flexibility this brings, to be able to craft totally custom User Journeys within the rules of the schema and the framework. The Identity Experience Framework xml files that make out User Journeys are frequently referred to as (custom) policy files.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d4-Custom-policies/#custom-policy-files","title":"Custom policy files","text":"<p>One or more custom policy files make out a User Journey. Custom policy files for a User Journey are usually split into a few separate files, based on configuration. This makes them easier to handle and read and simplifies the search for content split into separate files.</p> <p>When a User Journey is triggered, all custom policy files required will be fetched and parsed as one file. But as this happens under the hood, it is easier for the developer to store the code (configuration) in separate files.</p> <p>A custom policy configuration must have the following sections / files:</p> <ul> <li>a base file - where all the definitions and references are kept</li> <li>a base extensions file - where all User Journeys are stored</li> <li>multiple execution policy (relying party) files - where token definitions and logging is defined</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/d4-Custom-policies/#uploading-policies-to-the-identity-experience-framework","title":"Uploading policies to the Identity Experience Framework","text":"<p>There are several ways of uploading policy files to the IEF. The simplest (and most intuitive) is to use the Azure Portal, open the Azure AD B2C resource then the Identity Experience Framework blade and select Upload custom policy.</p> <p></p> <p>The same can be achieved programmatically using PowerShell or the REST API calls to Microsoft Graph, where download, list and delete operations also can be triggered.</p> <p>In the Azure AD Preview PowerShell module there are cmdlets for managing the Trust Framework Policy, referring to the framework that custom policies are built on.</p> <p>By calling the Microsoft Graph API it is also possible to upload and manage custom policies, but at the time of writing, only the <code>/beta</code> endpoint supports these actions.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d4-Custom-policies/#b2c-policymanagementps1","title":"B2C-PolicyManagement.ps1","text":"<p>The reason for the Powershell script B2C-PolicyManagement is to be able to easily upload custom policy files from a local client and get the same result as when uploading policy files through an automated pipeline.</p> <p>This script requires the Azure AD Preview PowerShell module to be installed.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d4-Custom-policies/#script-pre-requisites","title":"Script pre-requisites","text":"<p>An authenticated session with the B2C tenant using an account with requisite privileges. Both Connect-AzAccount (recommended, but requires Az.Account PowerShell module) and Connect-AzureAD can be used to establish a session.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d4-Custom-policies/#script-availability","title":"Script availability","text":"<p>The script is available on GitHub.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d4-Custom-policies/#script-execution","title":"Script execution","text":"<p>The script can be executed without any input parameters, but the in-script variable Placeholders must be configured, or else the script will throw '... - not a valid placeholder ...'.</p> <pre><code>B2C-PolicyManagement\n</code></pre> <p>This is a snippet from the script documentation, second .EXAMPLE. One or multiple policy files can be added as input parameters.</p> <p>Use <code>-DeployFolder</code> to override the creation of a default Deploy folder in the current working directory.</p> <pre><code>B2C-PolicyManagement -PolicyFiles .\\3-b2c_1a_v2_signupsignin.xml, .\\4-b2c_1a_v2_passwordreset.xml -DeployFolder MinDeploy\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/d4-Custom-policies/#script-variables","title":"Script variables","text":"<p>The <code>$Placeholders</code> list variable must be filled out for the script to run successfully.</p> <pre><code>$Placeholders = @{\n    \"PLACEHOLDER_TENANTNAME\"                  = \"\"\n    \"PLACEHOLDER_TENANTID\"                    = \"\"\n    \"PLACEHOLDER_BRANDINGBASEURL\"             = \"\"\n    \"PLACEHOLDER_INSTRUMENTATIONKEY\"          = \"\"\n    \"PLACEHOLDER_IEF_CLIENTID\"                = \"\"\n    \"PLACEHOLDER_IEFPROXY_CLIENTID\"           = \"\"\n    \"PLACEHOLDER_B2C_EXTENSIONS_APP_CLIENTID\" = \"\"\n    \"PLACEHOLDER_B2C_EXTENSIONS_APP_OBJECTID\" = \"\"\n    \"PLACEHOLDER_AAD_COMMON_APP_CLIENTID\"     = \"\"\n    \"PLACEHOLDER_IDPORTEN_CLIENTID\"           = \"\"\n    \"PLACEHOLDER_HELPERAPI_URL\"               = \"\"\n}\n</code></pre> <p>Values and names for the respective parameters can be provided by a tenant administrator.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d5-Pipeline-branding-policies/","title":"Automating upload of custom branding and policy files","text":""},{"location":"Managed%20Azure%20AD%20B2C/d5-Pipeline-branding-policies/#table-of-contents","title":"Table of contents","text":"<ul> <li>Automating upload of custom branding and policy files</li> <li>Table of contents</li> <li>Introduction</li> <li>Custom branding<ul> <li>Custom branding files</li> <li>Uploading custom branding files</li> </ul> </li> <li>Custom policies<ul> <li>Custom policy files</li> <li>Uploading custom policies</li> </ul> </li> <li>Establishing a DevOps pipeline<ul> <li>Azure DevOps pipeline introduction</li> <li>Building an Azure DevOps pipeline</li> </ul> </li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/d5-Pipeline-branding-policies/#introduction","title":"Introduction","text":"<p>Custom branding files and policy files, respectively, make out the user interface and the backend logic. While it's easy to develop and manage these files in a source control repository, it quickly becomes significantly more complex when building an automated system for uploading them across multiple environments.</p> <p>This article will explain the moving pieces that need to go together to build the aforementioned pipeline.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d5-Pipeline-branding-policies/#custom-branding","title":"Custom branding","text":"<p>Custom branding is used to shape a visual representation of the sign-in pages to match other company pages. This is usually preferred because it gives the user the best possible (and most consistent) experience when signing in. For more information on custom branding Custom branding files.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d5-Pipeline-branding-policies/#custom-branding-files","title":"Custom branding files","text":"<p>The custom branding files are usually stored in an Azure storage account in a container named branding. Here there will be two Microsoft provided themes, OceanBlue and StaleGray, and at least one company project folder.</p> <p>Each theme consists of a html, css and js folder, where the respective content can be found in each folder.</p> <p></p>"},{"location":"Managed%20Azure%20AD%20B2C/d5-Pipeline-branding-policies/#uploading-custom-branding-files","title":"Uploading custom branding files","text":"<p>Uploading and downloading custom branding files to an Azure blob container (the most frequent use-case) can be in several ways. Guidance to four different ways can be found at Custom branding.</p> <p>Downloading files from a blob container is usually done in the context of a user. This process is close to risk free and can therefore be performed manually. Also, downloading custom branding files using a pipeline doesn't make much sense.</p> <p>For uploading files in an automated pipeline there are two options, both are good:</p> <ul> <li>The Python-based command line tool az.</li> <li>The PowerShell script B2C-BlobManagement.ps1.</li> </ul> <p>The PowerShell script was created for this specific task and is well-suited for use in both an automated process, as well as run directly in the context of a user (from where the need originated).</p> <p>How to configure, and utilize, the power of an Azure DevOps pipeline for uploading files to a Azure blob container, see DevOps pipeline.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d5-Pipeline-branding-policies/#custom-policies","title":"Custom policies","text":"<p>Custom policies can be found in the Identity Experience Framework blade inside the Azure AD B2C service. Custom policies are used to build User Journeys. See User experience for more detail.</p> <p>Custom policies consists of xml files that define the logic that runs in the Identity Experience Framework, see here for links to code samples, training material and more.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d5-Pipeline-branding-policies/#custom-policy-files","title":"Custom policy files","text":"<p>Read more on custom policies and the custom policy files in the Identity Experience Framework.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d5-Pipeline-branding-policies/#uploading-custom-policies","title":"Uploading custom policies","text":"<p>The section Upload policies to the IEF explains possible ways to manage custom policies.</p> <p>How to configure and utilize the power of an Azure DevOps pipeline for uploading custom policies to the Identity Experience Framework, see DevOps pipeline.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d5-Pipeline-branding-policies/#establishing-a-devops-pipeline","title":"Establishing a DevOps pipeline","text":""},{"location":"Managed%20Azure%20AD%20B2C/d5-Pipeline-branding-policies/#azure-devops-pipeline-introduction","title":"Azure DevOps pipeline introduction","text":"<p>To build a fully automated process using Azure DevOps it is possible to to create and configure a release pipeline. As pipelines are written in YAML-formatted files it's simple to move a pipeline, and files, and quickly establish it in a different DevOps project.</p> <p>To ease support for deployment to multiple environments a YAML template describes all pipeline stages and the host type. This template is extended (using extends action) by YAML files for each environment. This setup contains environment specific variables to each of their own files. Depending on the variables and their sensitivity, (usually) all environment specific parameters can be written in the YAML, the exception being deployment principals. Common settings, such as tenant name, can be stored in the variable group(s) when all environments are deployed to subscriptions in the same tenant.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d5-Pipeline-branding-policies/#building-an-azure-devops-pipeline","title":"Building an Azure DevOps pipeline","text":"<p>Establish a DevOps pipeline (must be performed once for every environment):</p> <ol> <li>Clone, copy, commit and push pipeline files to repository</li> <li>Create a new pipeline and browse to repository</li> <li>Configure a pipeline using an existing YAML file</li> <li>Save pipeline (don't select Run)</li> <li>Create a variable group (Library -&gt; + Variable group)</li> <li>Add service principal app id (content_deployment_app_registration_clientid), secret (content_deployment_app_registration_clientsecret) and match script names (make sure secret variable is padlocked, variable type set to secret)</li> <li>Configure Pipeline permissions to limit access to the new pipeline(s)</li> <li>For Prod environments, consider configuring Approvals and checks</li> <li>Return to Pipelines and if necessary, create folder(s) and move pipeline(s)</li> <li>Open the pipeline and select Edit to configure variables</li> <li>Match (variable) group name and configure environment specific values</li> <li>(Test) Run pipeline and watch the results</li> </ol>"},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/","title":"Pipeline deployment custom branding","text":""},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/#table-of-contents","title":"Table of contents","text":"<ul> <li>Pipeline deployment custom branding</li> <li>Table of contents</li> <li>Introduction</li> <li>Upload files using Azure DevOps pipeline<ul> <li>Pipeline execution</li> <li>Development pipeline</li> <li>Test and Production pipelines</li> </ul> </li> <li>How to work with an Azure DevOps repository</li> <li>Recommended procedure<ul> <li>Checking in files to git repository with Visual Studio Code</li> <li>Branch out from the main branch</li> <li>Branching - graphical user interface</li> <li>Branching - terminal / shell</li> </ul> </li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/#introduction","title":"Introduction","text":"<p>Identity platform published pages can be fully customized. Customization enables companies to brand their sign-in pages so they share the look and feel of other company pages.</p> <p>Custom branding explains sign-in page styling.</p> <p>Management of custom branding files, primarily uploading of files, can be done in two ways:</p> <ul> <li>The manual way leverages a PowerShell script. This will be the fastest way to work with custom branding files in the development environment.</li> <li>The automated way when working with Azure DevOps repositories and pipelines.</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/#upload-files-using-azure-devops-pipeline","title":"Upload files using Azure DevOps pipeline","text":"<p>There are pipelines created for uploading / publishing of branding files to all environments.</p> <ul> <li>Branding - Development</li> <li>Branding - Test</li> <li>Branding - Production</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/#pipeline-execution","title":"Pipeline execution","text":"<p>The configuration of pipelines triggers can be split into two categories:</p> <ul> <li>Automatically triggered</li> <li>Manually triggered</li> </ul> <p>NOTE!</p> <p>All pipelines are configured to require approval before running. Members of project group Contributors can all approve runs, including their own.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/#development-pipeline","title":"Development pipeline","text":"<p>Automatic pipeline triggering is configured deployment of branding in the development environment. When the pipeline discovers changes committed to the branding folder, regardless of branch, the pipeline starts running.</p> <p>This means that every for pull request (PR) merged, that makes modifications to files in the include path, triggers the pipeline to run, in the same goes for any branch making changes to these files.</p> <p>This is the (current) configuration for the development environment:</p> <pre><code>trigger:\n  batch: true\n  paths:\n    include:\n      - Pipelines/Dev-branding.yml\n      - Pipelines/Templates/Template-branding.yml\n      - Environments/Development/branding\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/#test-and-production-pipelines","title":"Test and Production pipelines","text":"<p>For test and production, a manual action is required to trigger pipeline for deployment of branding files to respective environments. There are no \"Environments/&lt;Test/Production&gt;/branding\" folders, the Development files are generalized so that they can be promoted to other environments using environment specific parameters.</p> <p>This is the (current) configuration for the test and production environment (replace Test with Prod):</p> <pre><code>trigger:\n  paths:\n    include:\n      - Pipelines/Test-branding.yml\n      - Pipelines/Templates/Template-branding.yml\n</code></pre> <p>Pipelines in all environments are configured with includes to their own yaml pipeline configuration files. With pipeline configuration changes, the pipelines will trigger and start (but will require approval to run).</p>"},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/#how-to-work-with-an-azure-devops-repository","title":"How to work with an Azure DevOps repository","text":"<p>Pushing changes to a central source controlled repository usually involves Git and an editor. Microsoft's Visual Studio Code is a good and lightweight alternative, albeit some extensions may improve the user experience.</p> <p>The procedure for working with online repositories is very similar regardless of vendor.</p> <p>The following (recommended) procedure uses an Azure DevOps repository (other popular alternatives are GitHub and Bitbucket).</p>"},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/#recommended-procedure","title":"Recommended procedure","text":"<ol> <li>Branch out from the main branch (using graphical user interface or shell / terminal)</li> <li>Make code changes in the new branch<ol> <li>If environment is Development, it is convenient to manually upload files</li> <li>Eventually, manual upload files will only be possible in Development as all changes to Test and Production should be fully automated</li> </ol> </li> <li>Upload changes and test Azure AD B2C pages to verify that modifications were successful</li> <li>Now the working branch are ready to be merged to the main branch, so everyone with a copy of the repository can get the latest version</li> <li>Create a pull request that pushes changes from the working branch into main</li> <li>Double-check the proposed changes (Files), assign (one or more) Required reviewer and select Create</li> <li>When the PR is created, make sure that there are *no* Merge conflicts</li> <li>Inform reviewer(s) of PR (copy and share the web site link in the browser address field)</li> <li>Configure Auto-complete (Merge type Merge - Delete &lt;working branch&gt; after merging) for automatic merge or wait for PR to be approved, then select Complete</li> <li>Switch back to main branch, pull newly applied changes, delete working branch</li> </ol>"},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/#checking-in-files-to-git-repository-with-visual-studio-code","title":"Checking in files to git repository with Visual Studio Code","text":"<p>The following procedure is based on Visual Studio Code.</p> <p>Any other editor of choice (often referred to as ISE - integrated scripting environment) can be used as git is installed and works independently.</p> <p>How to Install Git (and / or download).</p>"},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/#branch-out-from-the-main-branch","title":"Branch out from the main branch","text":"<p>In Visual Studio Code create a new branch by following these steps:</p> <p>TIP!</p> <p>First clone the project repository (this will create a local folder)</p>"},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/#branching-graphical-user-interface","title":"Branching - graphical user interface","text":"<ol> <li>Press \"F1\" and type \"create branch\"<ol> <li>Select \"Git: Create Branch...\"</li> <li>Enter the \"working name\" of the new branch</li> </ol> </li> <li>Make changes</li> <li>Test changes by uploading files (for the development environment)</li> <li>Commit changes</li> <li>Push changes</li> <li>Create pull request (PR) in Azure DevOps, either yourself or have someone else create one</li> <li>Approve and merge PR</li> <li>Switch to main branch, pull changes, delete branch (optional, but recommended)</li> </ol>"},{"location":"Managed%20Azure%20AD%20B2C/d6-Pipeline-push-branding/#branching-terminal-shell","title":"Branching - terminal / shell","text":"<p>By supplying the -c parameter the git switch command creates and switches to the branch:</p> <ol> <li>git switch -c &lt;new branch name&gt;</li> <li>Make changes</li> <li>git add . (or git add *) (adds all changes, single files can be select instead)</li> <li>git commit -m \"&lt;commit message&gt;\"</li> <li>git status (see which files are committed)</li> <li>git push -u origin &lt;branch name&gt; (The -u == --set-upstream and is a one-time operation to create the new branch in Azure DevOps, new commits only need git push)</li> <li>Create pull request (PR) in Azure DevOps</li> <li>Approve and merge PR</li> <li>git checkout main</li> <li>git pull</li> <li>git branch -d &lt;new branch name&gt; (deletes local branch, optional, but recommended)</li> </ol>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/","title":"Branding policies pipeline configuration","text":""},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#table-of-contents","title":"Table of contents","text":"<ul> <li>Branding policies pipeline configuration</li> <li>Table of contents</li> <li>Introduction</li> <li>Pipelines<ul> <li>Pipeline execution</li> <li>The automated way</li> <li>The manual way</li> <li>Azure DevOps Pipelines Environments</li> <li>Azure DevOps Pipelines Library</li> <li>Azure DevOps Pipelines variable group - content deployment</li> <li>Branding</li> <li>Upload branding files via Azure DevOps pipeline</li> <li>Development pipeline - branding</li> <li>Test and Production pipelines - branding</li> <li>Policies</li> <li>Polices - Dev</li> <li>Polices - Test</li> <li>Polices - Prod</li> <li>Upload policy files via Azure DevOps pipeline</li> <li>Development pipelines - policies</li> <li>Test and Production pipelines - policies</li> </ul> </li> <li>How to work with an Azure DevOps repository</li> <li>Recommended procedure<ul> <li>Checking in files to git repository with Visual Studio Code</li> <li>Branch out from the main branch</li> <li>Branching - graphical user interface</li> <li>Branching - terminal / shell</li> </ul> </li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#introduction","title":"Introduction","text":"<p>Azure DevOps pipelines are used for deploying the B2C user interface (branding) and policy files (User Journeys). This increases the trust level for having a controlled and successful deployment across all environments.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#pipelines","title":"Pipelines","text":"<p>There are two different types of pipelines for handling deployment:</p> <ul> <li>branding</li> <li>polices</li> </ul> <p>For each of these deployment types there are three pipelines to support the various environments:</p> <ul> <li>dev (development)</li> <li>test</li> <li>prod (production)</li> </ul> <p>At minimum, there are six pipelines (2x3) registered for deployments dev, test and prod environments (plus for any additional set of policy files).</p> <p>All these pipelines must use service principals to perform necessary configuration changes. The service principals have been created by automation elsewhere, with credentials stored in DevOps Pipelines Library variable groups.</p> <p>The variable group (which provides access to, and safe-keeps, credentials):</p> <ul> <li>Customer b2c content deployment</li> </ul> <p>Content refers to management of the branding and policy files. Policy file management happens within the Identity Experience Framework blade, branding files are hosted on an Azure storage account (resource tenant).</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#pipeline-execution","title":"Pipeline execution","text":"<p>The project repository is the place for all Identity Experience Framework files, User Journey code and configuration.</p> <p>The configuration of pipelines triggers can be split into two categories:</p> <ul> <li>Automatically triggered</li> <li>Manually triggered</li> </ul> <p>NOTE!</p> <p>All pipelines are configured to require approval before running. Members of project group Contributors can all approve runs, including their own.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#the-automated-way","title":"The automated way","text":"<p>Using triggers enables automatic execution when working with Azure DevOps repositories and pipelines.</p> <p>For pipelines used in development they will automatically trigger when uploaded changes are detected. The pipelines are triggered but must be approved in order to start churning through steps and tasks.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#the-manual-way","title":"The manual way","text":"<p>For pipelines in test and production they must be triggered manually.</p> <p>This is a security measure, but also a necessary configuration as test and prod don't have their own files. The policy and branding files from Environment\\Development\\policies\\v1 are promoted and deployed to test and prod.</p> <p>All pipelines must be approved to start running through steps and tasks.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#azure-devops-pipelines-environments","title":"Azure DevOps Pipelines Environments","text":"<p>There are three environments configured:</p> <ul> <li>dev</li> <li>test</li> <li>prod</li> </ul> <p>Each of these are referenced when pipelines are triggered. Run history is saved to the respective environments, dev, test, prod.</p> <p>The environments have Approvals and checks configured as follows:</p> <ul> <li>All approvers must approve</li> <li>Approvers: [IdentityPlatform]\\Contributors</li> <li>Allow approvers to approve their own runs</li> </ul> <p>NOTE!</p> <p>All approvers must approve does not mean that every member of the group must approve. This can be confusing, but when using groups for approval, a single approval is sufficient.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#azure-devops-pipelines-library","title":"Azure DevOps Pipelines Library","text":"<p>There are three variable groups defined in the library. These credentials are used for b2c policies and branding (content):</p> <ul> <li>Customer b2c content deployment - Dev</li> <li>Customer b2c content deployment - Test</li> <li>Customer b2c content deployment - Prod</li> </ul> <p>These credentials are loaded during pipeline execution and are necessary to perform the configured pipeline tasks.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#azure-devops-pipelines-variable-group-content-deployment","title":"Azure DevOps Pipelines variable group - content deployment","text":"<p>Customer b2c content deployment - &lt;env&gt; is used for deploying custom policies and custom styling (UI) files.</p> <p>The content variable group holds credentials for the app registration used for content deployment for the specified environment.</p> <p>IMPORTANT!</p> <p>Using an app registration client_id and client_secret means that if the secret expires the pipeline will stop working. It is important that secret management (key rotation) is established to avoid deployment disruption. The app registration resides in the resource tenant and it is granted permission in the B2C tenant using admin consent.</p> <p>Variable CONTENT_DEPLOYMENT_APP_REGISTRATION_CLIENTID refers to an app registration in the resource tenant. Variable CONTENT_DEPLOYMENT_APP_REGISTRATION_CLIENTSECRET must be provided with the client_id for the pipeline to successfully authenticate with the Graph API and issue a token that must be presented when uploading files.</p> <p>The app registration must be granted the following Graph API application permissions in the B2C tenant:</p> <ul> <li>Policy.Read.All</li> <li>Policy.ReadWrite.TrustFramework</li> </ul> <p>The app registration service principal must also be granted requisite permissions on the blob container in the resource tenant, for uploading styling files. The blob container branding is where the styling files used by the sign-in pages are stored and published.</p> <p>The minimum requirement for managing files in the container is Reader and Data Access.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#branding","title":"Branding","text":"<p>The branding pipelines are named &lt;Environment&gt; - branding and uses the variable group Customer b2c content deployment - &lt;Environment&gt;.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#upload-branding-files-via-azure-devops-pipeline","title":"Upload branding files via Azure DevOps pipeline","text":"<p>Azure DevOps pipelines have been configured for uploading and publishing of branding files to the environments:</p> <ul> <li>Dev - branding</li> <li>Test - branding</li> <li>Prod - branding</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#development-pipeline-branding","title":"Development pipeline - branding","text":"<p>Automatic pipeline triggering is configured for deployment of branding in the development environment. When the pipeline discovers changes committed to the branding folder, regardless of branch, the pipeline starts running.</p> <p>This means that every for pull request (PR) merged, that makes modifications to files in the include path, triggers the pipeline to run, in the same goes for any branch making changes to these files.</p> <p>This is the (current) configuration for the development environment:</p> <pre><code>trigger:\n  batch: true\n  paths:\n    include:\n      - Pipelines/Dev-branding.yml\n      - Pipelines/Templates/Template-branding.yml\n      - Environments/Development/branding\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#test-and-production-pipelines-branding","title":"Test and Production pipelines - branding","text":"<p>For test and production, a manual action is required to trigger pipeline for deployment of branding files to respective environments. There are no Environments/&lt;Test/Production&gt;/branding folders, the Development files are generalized so that they can be promoted to other environments using environment specific parameters.</p> <p>This is the (current) configuration for the test and production environment (replace Test with Prod):</p> <pre><code>trigger:\n  paths:\n    include:\n      - Pipelines/Test-branding.yml\n      - Pipelines/Templates/Template-branding.yml\n</code></pre> <p>Pipelines in all environments are configured with includes to their own yaml pipeline configuration files. With pipeline configuration changes, the pipelines will trigger and start (but will require approval to run).</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#policies","title":"Policies","text":"<p>The policies pipelines are named &lt;Environment&gt; - policies - vX and uses the variable group Customer b2c content deployment - &lt;Environment&gt;.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#polices-dev","title":"Polices - Dev","text":"<p>Two (sometimes three) sets of policy files are uploaded to the Development environment.</p> <ul> <li>* - v1</li> <li>* - v2</li> <li>(* - v3)</li> </ul> <p>Having multiple sets of policy files allows parallel development of custom policies without the risk of breaking the sign-in experience.</p> <p>When working on different User Journeys working within a single set of policy files can be sufficient. When updating a User Journey it is beneficial to be able to test the outcome to avoid disrupting authentication flows. Breaking a User Journey can cause developers to get unexpected results and waste time troubleshooting errors that are not theirs.</p> <p>Only a development environment will invariably have a need for more than two sets of policies.</p> <p>Any v3 policies are totally experimental and usually only know to Identity Experience developers. If present, v3 polices only live in the development environment and will not be promoted to neither Test nor Prod.</p> <p>The v1 and v2 polices may both be used actively by integrated applications that are under development. Usually only v1 policies are used, but when testing new User Journey functionality, v2 policies may be useful for developers. Only Identity developers will know what v2 (and v3) polices are available, and so these policies will be used more sparsely.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#polices-test","title":"Polices - Test","text":"<p>NOTE!</p> <p>Policy files in Test and Prod environments are promoted from the repository Development\\Policies - vX folder.</p> <p>Two DevOps pipelines are configured for uploading two sets of policy files to the Test environment.</p> <ul> <li>* - v1</li> <li>* - v2</li> </ul> <p>Policies v1 hold definitions and User Journeys that will be promoted to the Prod environment. This is the stable set of policy files with User Journeys where developers, testers and end users will mostly interact.</p> <p>Policies v2 may be useful to allow testing of new features or quick bugfix testing (without interrupting the existing flows).</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#polices-prod","title":"Polices - Prod","text":"<p>NOTE!</p> <p>Policy files in Test and Prod environments are promoted from the repository Development\\Policies - vX folder.</p> <p>One DevOps pipeline is configured for uploading policy files to the Prod environment.</p> <ul> <li>* - v1</li> </ul> <p>Policies deployed in production should have been thoroughly tested in other environments before being released here.</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#upload-policy-files-via-azure-devops-pipeline","title":"Upload policy files via Azure DevOps pipeline","text":"<p>Azure DevOps pipelines have been configured for uploading custom policy files to environments:</p> <ul> <li>Dev - policies - v1</li> <li>Dev - policies - v2</li> <li>(Dev - policies - v3)</li> <li>Test - policies - v1</li> <li>Test - policies - v2</li> <li>Prod - policies - v1</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#development-pipelines-policies","title":"Development pipelines - policies","text":"<p>Automatic pipeline triggering is configured for deployment of custom policy files in the development environment. When the pipeline discovers changes committed to the respective policy folder, regardless of branch, the pipeline starts running.</p> <p>This means that every for pull request (PR) merged, that makes modifications to files in the include path, triggers the pipeline to run, in the same goes for any branch making changes to these files.</p> <p>Pipelines in all environments are configured with includes to their own yaml pipeline configuration files.  </p> <p>This is the (current) configuration for the v1 (for v2 and v3, replace versions, and dev with test)  policies in the development environment:</p> <pre><code>trigger:\n  batch: true\n  paths:\n    include:\n      - Pipelines/Policies dev v1.yml\n      - Pipelines/Templates/Template-policies.yml\n      - Environments/Development/policies/v1\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#test-and-production-pipelines-policies","title":"Test and Production pipelines - policies","text":"<p>For test and production environments, a manual action is required to trigger pipeline for deployment of custom policy files. There are no Environments/&lt;Test/Production&gt;/policies folders, the Development files are generalized so that they can be promoted to other environments using environment specific parameters.</p> <p>This is the (current) configuration for the production environment:</p> <pre><code>trigger:\n  paths:\n    include:\n      - Pipelines/Policies v1.yml\n      - Pipelines/Templates/Template-policies.yml\n</code></pre> <p>Pipelines in all environments are configured with includes to their own yaml pipeline configuration files. With pipeline configuration changes, the pipelines will trigger and start (but will require approval to run).</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#how-to-work-with-an-azure-devops-repository","title":"How to work with an Azure DevOps repository","text":"<p>Pushing changes to an central source controlled repository usually involves Git and an editor. Microsoft's Visual Studio Code is a good and lightweight alternative, albeit some extensions may improve the user experience.</p> <p>The procedure for working with online repositories is very similar regardless of vendor.</p> <p>The following (recommended) procedure uses an Azure DevOps repository (other popular alternatives are GitHub and Bitbucket).</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#recommended-procedure","title":"Recommended procedure","text":"<ol> <li>Branch out from the main branch (using graphical user interface or shell / terminal)</li> <li>Make code changes in the new branch<ol> <li>If environment is Development, it is convenient to manually upload files</li> <li>Eventually, manual upload files will only be possible in Development as all changes to Test and Production should be fully automated</li> </ol> </li> <li>Upload changes and test Azure AD B2C pages to verify that modifications were successful</li> <li>Now the working branch are ready to be merged to the main branch, so everyone with a copy of the repository can get the latest version</li> <li>Create a pull request that pushes changes from the working branch into main</li> <li>Double-check the proposed changes (Files), assign (one or more) Required reviewer and select Create</li> <li>When the PR is created, make sure that there are *no* Merge conflicts</li> <li>Inform reviewer(s) of PR (copy and share the web site link in the browser address field)</li> <li>Configure Auto-complete (Merge type Merge - Delete &lt;working branch&gt; after merging) for automatic merge or wait for PR to be approved, then select Complete</li> <li>Switch back to main branch, pull newly applied changes, delete working branch</li> </ol>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#checking-in-files-to-git-repository-with-visual-studio-code","title":"Checking in files to git repository with Visual Studio Code","text":"<p>The following procedure is based on Visual Studio Code.</p> <p>Any other editor of choice (often referred to as ISE - integrated scripting environment) can be used as git is installed and works independently.</p> <p>How to Install Git (and / or download).</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#branch-out-from-the-main-branch","title":"Branch out from the main branch","text":"<p>In Visual Studio Code create a new branch by following these steps:</p> <p>TIP!</p> <p>First clone the project repository (this will create a local folder).</p>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#branching-graphical-user-interface","title":"Branching - graphical user interface","text":"<ol> <li>Press \"F1\" and type \"create branch\"<ol> <li>Select \"Git: Create Branch...\"</li> <li>Enter the \"working name\" of the new branch</li> </ol> </li> <li>Make changes</li> <li>Test changes by uploading files (for the Development environment)</li> <li>Commit changes</li> <li>Push changes</li> <li>Create pull request (PR) in Azure DevOps, either yourself or have someone else create one</li> <li>Approve and merge PR</li> <li>Switch to main branch, pull changes, delete branch (optional, but recommended)</li> </ol>"},{"location":"Managed%20Azure%20AD%20B2C/d9-Pipeline-branding-pipeline-config/#branching-terminal-shell","title":"Branching - terminal / shell","text":"<p>By supplying the -c parameter the git switch command creates and switches to the branch:</p> <ol> <li>git switch -c &lt;new branch name&gt;</li> <li>Make changes</li> <li>git add . (or git add *) (adds all changes, single files can be select instead)</li> <li>git commit -m \"&lt;commit message&gt;\"</li> <li>git status (see which files are committed)</li> <li>git push --set-upstream origin &lt;branch name&gt; (The -u == --set-upstream and is a one-time operation to create the new branch in Azure DevOps, new commits only need git push)</li> <li>Create pull request (PR) in Azure DevOps</li> <li>Approve and merge PR</li> <li>git checkout main</li> <li>git pull</li> <li>git branch -d &lt;new branch name&gt; (deletes local branch, optional, but recommended)</li> </ol>"},{"location":"Managed%20Azure%20AD%20B2C/e1-AuthN-and-AuthZ/","title":"Authentication and Authorization","text":""},{"location":"Managed%20Azure%20AD%20B2C/e1-AuthN-and-AuthZ/#table-of-contents","title":"Table of contents","text":"<ul> <li>Authentication and Authorization</li> <li>Table of contents</li> <li>Introduction</li> <li>The basics</li> <li>OAuth 2.0 and OpenID Connect flows</li> <li>OpenID Connect</li> <li>Policies</li> <li>Tokens</li> <li>OAuth 2.0 Grants</li> <li>Which OAuth 2.0 flow should I use</li> <li>Debugging OpenID Connect and OAuth 2.0</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e1-AuthN-and-AuthZ/#introduction","title":"Introduction","text":"<p>The Microsoft Identity platform supports the authentication protocol standard OAuth 2.0 and the added identity layer OpenID Connect. OpenID Connect is the modern authentication protocol most commonly used in application integrations, though SAML2 is also supported.</p> <p>This reference guide will elaborate on authentication methods used in OpenID Connect integrations and provide useful examples on how to authenticate end-users and provide tokens for your consumer (and business) applications.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e1-AuthN-and-AuthZ/#the-basics","title":"The basics","text":"<p>Every application that integrates with the Identity platform must be registered with an app registration. The application registration process yields a couple of values for the application to be used when initiating an authentication request:</p> <ul> <li>An application ID or client ID that uniquely identifies the application</li> <li>A redirect URI or package identifier in which the response of the authentication is returned</li> </ul> <p>The application communicates with the Microsoft Identity platform by sending requests to the v2.0 endpoint:</p> <pre><code>https://{tenantName}.b2clogin.com/{tenantName}.onmicrosoft.com/oauth2/v2.0/authorize\nhttps://{tenantName}.b2clogin.com/{tenantName}.onmicrosoft.com/oauth2/v2.0/token\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e1-AuthN-and-AuthZ/#oauth-20-and-openid-connect-flows","title":"OAuth 2.0 and OpenID Connect flows","text":"<p>In nearly all OAuth and OpenID Connect flows, four parties are involved in the exchange:</p> <p></p> <ul> <li> <p>The authorization server is the Microsoft Identity platform v2.0 endpoint. It handles anything related to user information and access. It also handles the trust relationships between the parties in a flow. It is responsible for verifying the user's identity, granting and revoking access to resources, and issuing tokens. It is also known as the identity provider.</p> </li> <li> <p>The resource owner is typically the end user. It is the party that owns the data, and it has the power to allow third parties to access that data store or resource.</p> </li> <li> <p>The OAuth client is your app. It is identified by its application ID. It is usually the party that end users interact with. It also requests tokens from the authorization server. The resource owner must grant the client permission to access the resource.</p> </li> <li> <p>The resource server is where the resource or data resides. It trusts the authorization server to securely authenticate and authorize the OAuth client. It also uses bearer access tokens to ensure that access to a resource can be granted.</p> </li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e1-AuthN-and-AuthZ/#openid-connect","title":"OpenID Connect","text":"<p>OpenID Connect is an authentication protocol, built on top of OAuth 2.0, that can be used to securely sign users into web applications. Using Microsoft's B2C implementation of OpenID Connect, you can outsource sign-up, sign-in, and other identity management experiences in your web applications to User Journeys created in the Identity Experience Framework (IEF).</p> <p>OpenID Connect extends the OAuth 2.0 authorization protocol for use as an authentication protocol. This allows you to perform single sign-on by using OAuth. It introduces the concept of an id_token, which is a security token that allows the client to verify the identity of the user and obtain basic profile information about the user.</p> <p>The Microsoft Identity platform, in its B2C implementation, extends the standard OpenID Connect protocol to do more than simple authentication and authorization. It introduces the policy parameter, which enables you to use OpenID Connect to add user experiences to your app - such as sign-up, sign-in, and profile management. Here we'll show you how to use OpenID Connect and policies to implement each of these experiences in your web applications. We'll also show you how to get access_tokens for accessing web APIs.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e1-AuthN-and-AuthZ/#policies","title":"Policies","text":"<p>Custom policies are the most important feature of the service Identity Experience Framework, which extend the standard OAuth 2.0 and OpenID Connect (and SAML) protocols. These policies (User Journeys) enables full customization, providing a lot more functionality than simple authentication and authorization.</p> <p>Policies fully describe the consumer identity experiences, including sign-up, sign-in and profile editing. They can be executed by using a special query parameter in the HTTP authentication requests.</p> <p>Multiple policy files create a User Journey, but are not a feature of OAuth 2.0, OpenID Connect, nor SAML protocols, they are exclusive to the Microsoft Identity platform B2C implementation.</p> <p>User Journeys are defined by configuring custom policies</p>"},{"location":"Managed%20Azure%20AD%20B2C/e1-AuthN-and-AuthZ/#tokens","title":"Tokens","text":"<p>The Microsoft Identity platform implementation of OAuth 2.0 and OpenID Connect makes extensive use of bearer tokens, including bearer tokens that are represented as JSON web tokens (JWTs).</p> <p>A bearer token is a lightweight security token that grants the Bearer access to a protected resource. The bearer is any party that can present the token. The Identity platform must first authenticate the party before it can receive a bearer token.</p> <p>A JWT is a compact, URL-safe means of transferring information between two parties. Information transferred in JWTs are known as claims. These are assertions of information about the bearer and the subject of the token. The claims in JWTs are JSON objects that are encoded and serialized for transmission. JWTs issued are signed but NOT encrypted, so you can debug them using various tools, including https://jwt.ms.</p> <p>Bearer tokens must be transported in a secure channel, such as transport layer security (HTTPS) to be protected from unauthorized parties because they don't have a built-in mechanism for such. If a bearer token is transmitted outside a secure channel, a malicious party can use a man-in-the-middle attack to acquire the token and use it to gain unauthorized access to a protected resource. The same security principles apply when bearer tokens are stored or cached for later use. Always ensure that your app transmits and stores bearer tokens in a secure manner.</p> <p>For additional bearer token security considerations, see RFC 6750 Section 5.</p> <p>Further details on the different types of tokens and some of the claims used are available in this Microsoft Learn article.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e1-AuthN-and-AuthZ/#oauth-20-grants","title":"OAuth 2.0 Grants","text":"<p>The OAuth 2.0 specification describes a number of grants, or methods, for a client application to acquire an access token, which can be used to authenticate a request to an API endpoint.</p> <p>The specification describes five grants for acquiring an access token:</p> <ul> <li>Authorization Code Grant</li> <li>Client Credential Grant</li> <li>Implicit Grant (rather see OAuth 2.0 Authorization Code Grant which supports Proof Key for Code Exchange for native apps and single-page apps, for JavaScript SPAs use MSAL.js 2.x)</li> <li>Refresh Token Grant (mostly handled by the authentication library without need for further configuration)</li> <li>Resource Owner Credential Grant - ROPC (doesn't support external identities and is rarely used)</li> </ul> <p>This guide focuses on Authorization Code Grant, Implicit Grant and Client Credentials Grant, as these are the most applicable grants for Identity platform integration scenarios.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e1-AuthN-and-AuthZ/#which-oauth-20-flow-should-i-use","title":"Which OAuth 2.0 flow should I use","text":"<p>The below figure serves as a map for selecting the applicable grant type for the given scenario.</p> <p>NOTE!</p> <p>Remember that Implicit Grant is replaced by the Authorization Code Grant extension Proof Key for Code Exchange (PKCE) to prevent certain attacks and securely perform OAuth exchanges.</p> <p></p> <p>Read more detailed information on the different grant flows:</p> <ul> <li>OAuth 2.0 Authorization Code Grant</li> <li>OAuth 2.0 Implicit Grant</li> <li>OAuth 2.0 Client Credentials Grant</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e1-AuthN-and-AuthZ/#debugging-openid-connect-and-oauth-20","title":"Debugging OpenID Connect and OAuth 2.0","text":"<p>OAuth 2.0 and OpenID Connect can be troublesome to get working right away. This is something most people experience.</p> <p>Debugging OpenID Connect lists, and explains how to use, a couple of community tools that may prove useful for debugging purposes.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e2-OAuth-AuthZ-code-grant/","title":"OAuth 2.0 authorization code grant","text":"<ul> <li>OAuth 2.0 authorization code grant</li> <li>Introduction</li> <li>1. Get an authorization code<ul> <li>Use a policy</li> </ul> </li> <li>2. Get a token<ul> <li>Validating the id_token</li> </ul> </li> <li>3. Use the access_token</li> <li>4. Refresh the token</li> <li>5. Authorization code grant extension Proof Key for Code Exchange (PKCE)</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e2-OAuth-AuthZ-code-grant/#introduction","title":"Introduction","text":"<p>The OAuth 2.0 authorization code grant is described in section 4.1 of the OAuth 2.0 specification. You can use it to perform authentication and authorization in the majority of app types, including web apps and native (mobile / desktop) apps.</p> <p>The authorization code grant enables apps to securely acquire access_tokens, which can be used to access resources that are secured by an authorization server.</p> <p>This article will focus on a particular flavour of the OAuth 2.0 authorization code grant (also referred to as code flow) where the OAuth client is a web app.</p> <p>This is a high level illustration of the flow:</p> <p></p>"},{"location":"Managed%20Azure%20AD%20B2C/e2-OAuth-AuthZ-code-grant/#1-get-an-authorization-code","title":"1. Get an authorization code","text":"<p>The authorization code flow begins with the client directing the user to the endpoint. This is the interactive part of the flow, where the user is required to take action. In this request, the client indicates the permissions that it needs to acquire from the user in the scope parameter and the policy to execute in the p parameter.</p> <p>NOTE!</p> <p>Microsoft recommends using Proof Key for Code Exchange (PKCE) for the authorization code grant also.</p> <p>The code_challenge and code_challenge_method parameters are displayed and explain in section Get an authorization code.</p> <p>The example uses policy p=b2c_1a_v1_signupsignin (line breaks for legibility).</p>"},{"location":"Managed%20Azure%20AD%20B2C/e2-OAuth-AuthZ-code-grant/#use-a-policy","title":"Use a policy","text":"<pre><code>GET:\nhttps://{tenantName}.b2clogin.com/{tenantName}.onmicrosoft.com/oauth2/v2.0/authorize\n?client_id={clientId}\n&amp;response_type=code\n&amp;redirect_uri={redirectUri}\n&amp;response_mode=query\n&amp;scope={scope}\n&amp;state={state}\n&amp;nonce= {nonce}\n&amp;p=b2c_1a_v1_signupsignin\n</code></pre> Parameter Required Description client_id Yes The application ID that the Azure portal assigned to your application. response_type Yes The response type, which must include code for the authorization grant flow. redirect_uri Yes The redirect_uri of your app, where authentication responses can be sent and received by your app. It must exactly match one of the redirect_uris that you registered in the portal, except that it must be URL encoded. scope Yes A space-separated (URL encoded) list of scopes. You must always specify openid as one of the scope values as this will initiate a OpenID Connect authentication process. If you only specify openid, you will only get an id_token when the returned code is exchanged at server side (see further down in this article). If you in addition to openid specify a resource URL or AppID, then you will also get an access_token (Note! You can only specify 1 resource in the scope list. Multiple resources can only be attained by performing separate authorization grant flows). If you also include the offline_access scope then your app will also get a refresh_token for long-lived access to resources. Example shown below grid. response_mode Recommended The method that should be used to send the resulting authorization_code back to your app. It can be one of query, form_post, or fragment. state Recommended A value included in the request that will also be returned in the token response. It can be a string of any content that you want. A randomly generated unique value is typically used for preventing cross-site request forgery attacks. The state is also used to encode information about the user's state in the app before the authentication request occurred, such as the page they were on or the policy being executed. p Yes The policy that will be executed. It is the name of a policy that is developed in the AAD B2C tenant. The policy name value begins with b2c_1a_. prompt Optional The type of user interaction that is required. The standard value is login, which forces the user to enter their credentials on that request. Single sign-on will not take effect. However, if prompt=none is used SSO will take effect, given that a session already exists. nonce Yes A value included in the request (generated by the app) that will be included in the resulting id_token as a claim. The app can then verify this value to mitigate token replay attacks. The value is typically a randomized, unique string that can be used to identify the origin of the request. Read the following article on how to generate the nonce. <p>TIP!</p> <p>How to ask for an id_token, refresh_token and access_token to an API in the B2C tenant (the scope parameter MUST be URL encoded) with appID  9993ca2f-6cc4-4d47-b0ac-c10811ad43e3 and permissions (scopes) read and write:</p> <p>openid+offline_access+https%3a%2f%2f87{tenantName}.onmicrosoft.com%2f9993ca2f-6cc4-4d47-b0ac-c10811ad43e330%2Fread+https%3a%2f%2f87{tenantName}.onmicrosoft.com%2f9993ca2f-6cc4-4d47-b0ac-c10811ad43e330%2Fwrite</p> <p>At this point, the user will be asked to complete the policy's workflow. This may involve the user entering their user name and password in addition to any other number of steps, depending on how the policy is defined.</p> <p>After the user completes the policy, the Identity platform will return a response to your app at the indicated redirect_uri, by using the method specified in the response_mode parameter. The response will be exactly the same regardless of which policy that is executed.</p> <p>A successful response that uses response_mode=query looks like:</p> <pre><code>Name                           Value\n----                           -----\nstate                          myState\ncode                           eyJraWQiOiJIUTB6ZERpTlhmWHZyTWJ5cVpJQy10ZUZpbEV6ZVd5TUxHTUFIVTBmVVd3IiwidmVyIjoiMS4wIiwiemlwIjoiRGVmbGF0ZSIsInNlciI6IjEuMCJ916HgvyoBl4SSnOGud7YKPt0BUIo......\n</code></pre> <p>This preview is generated from PowerShell for better legibility. The actual values are appended as parameters in the redirection URL from B2C. The code format differs from the v1.0 endpoint, and should only be redeemed from the v2.0 /token endpoint.</p> Parameter Description code The authorization_code that the app requested. The app can use the authorization code to request an access_token for a target resource. Authorization codes are very short lived. Typically, they expire after 5-10 minutes. state See the full description in the previous table. If a state parameter is included in the request, the same value should appear in the response. The app should verify that the state values in the request and the response are identical. <p>Error responses will look like:</p> <pre><code>{\n  \"error\": \"access_denied\",\n  \"error_description\": \"The user revoked access to the app.\"\n}\n</code></pre> Parameter Description error An error code string that can be used to classify the types of errors that occur, and can be used to react to errors. error_description A specific error message that can help a developer to identify the root cause of an authentication error."},{"location":"Managed%20Azure%20AD%20B2C/e2-OAuth-AuthZ-code-grant/#2-get-a-token","title":"2. Get a token","text":"<p>Now that you've acquired an authorization code, you can redeem the code for a token (hence the name code flow) to the desired resource by sending a POST request to the /token endpoint:</p> <p>NOTE!</p> <p>The scope parameter from the initial request to the /authorize endpoint must be exactly the same as the one to the /token endpoint.</p> <pre><code>POST: https://{tenantName}.b2clogin.com/{tenantName}.onmicrosoft.com/oauth2/v2.0/token?p=b2c_1a_v1_signupsignin HTTP/1.1\nHost: https://{tenantName].b2clogin.com\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=authorization_code\n&amp;client_id={clientId}\n$client_secret={clientSecret}\n&amp;scope={clientId} offline_access\n&amp;code=eyJraWQiOiJIUTB6ZERpTlhmWHZ$...\n&amp;redirect_uri={redirectUri}\n</code></pre> Parameter Required Description p Yes The policy that was used to acquire the authorization code. You cannot use a different policy in this request. Note that you add this parameter to the query string, not in the POST body. grant_type Yes The type of grant, which must be authorization_code for the authorization code grant flow. client_id Yes The application ID that the Azure portal assigned to your app. client_secret Yes The application secret. scope Recommended A space separated list of scopes (in this case the scope is not URL encoded). If you do not include the scope parameter, then the initial request determine the tokens you get in return (see description of the initial request above). If you include the scope parameter, then the scope parameters you specify determine what tokens are returned. The scope values can not include any resource or parameter that was not included in the first request that generated the code, but the scope values can be fewer then the first request (smaller scope). code Yes The authorization_code that you acquired in the first leg of the flow. redirect_uri Yes The redirect_uri of the application where you received the authorization_code. <p>A successful response will look like:</p> <pre><code>{\n  \"access_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IkktZDdMQy1TQkltdUtZemNNQlg0WjhDYk10dU84YU9mSjJEZWJyTjM0M3cifQ.eyJpc3MiOiJodHRwczovL2xvZ2luLm1pY3Jvc29mdG9ubGluZ...\",\n  \"id_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IkktZDdMQy1TQkltdUtZemNNQlg0WjhDYk10dU84YU9mSjJEZWJyTjM0M3cifQ.eyJleHAiOjE0OTYwNTk0OTMsIm5iZiI6MTQ5NjA1ODA1MywidmVyIjoiMS4wIiwiaX...\",\n  \"token_type\": \"Bearer\",\n  \"not_before\": \"1585051428\",\n  \"expires_in\": \"86400\",\n  \"expires_on\": \"1585051728\",\n  \"resource\": \"c8412f8b-d7a2-6e1a-810e-d61fc5d0d6b3\",\n  \"id_token_expires_in\": \"3600\",\n  \"profile_info\": \"eyJ2ZXIiOiIxLjAiLCJ0aWQiOiI1YmFmZTQwMC0yYTI1LTRmOTctOTE4NS1lMjgwYzdkY2JiMTUiLCJzdWIiOm51bGwsIm5hbWUiOiJSw7hzYmVyZywgTGFycy1K...\",\n  \"refresh_token\": \"eyJraWQiOiIySlBBbU9EOHVYLTExY2d2U0gtR0FEM05WRU1HSFpsUlB3TUhsWXJ3VEgwIiwidmVyIjoiMS4wIiwiemlwIjoiRGVmbGF0ZSIsInNlciI6IjEuMCJ9.mVIsQu_yMHK7WiNCXUey7VCutoHUFsCT...\",\n  \"refresh_token_expires_in\": \"7776000\"\n}\n</code></pre> Parameter Description not_before The time at which the token is considered valid, in epoch time. token_type The token type value. The only type supported is Bearer. access_token The signed JSON Web Token (JWT) token that you requested. scope The scopes that the token is valid for, which can be used for caching tokens for later use. expires_in The length of time that the token is valid (in seconds). This value is controlled by the B2C policy configuration refresh_token An OAuth 2.0 refresh_token. The app can use this token to acquire additional tokens after the current token expires. Refresh_tokens are long lived, and can be used to retain access to resources for extended periods of time. For more detail, refer to the Overview of tokens in Azure Active Directory B2C. <p>TIP!</p> <p>The token claims can be inspected using jwt.ms which is Microsoft's neat, online JSON Web Token decoder.</p> <p>As an alternative, use the SDK Libraries to view them programmatically. For more information on JWT, please refer to the standard RFC 7519</p>"},{"location":"Managed%20Azure%20AD%20B2C/e2-OAuth-AuthZ-code-grant/#validating-the-id_token","title":"Validating the id_token","text":"<p>Just receiving an id_token is not enough to authenticate the user. You must validate the signature of the id_token and verify the claims in the token as per your app's requirements. The Microsoft Identity Platform uses JSON Web Tokens (JWTs) and public key cryptography to sign tokens and verify that they are valid. See article Validating OAuth 2.0 / OpenID Connect tokens for best practice on how to validate a token. The access_token must be validated by the service (API) that the application is calling.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e2-OAuth-AuthZ-code-grant/#3-use-the-access_token","title":"3. Use the access_token","text":"<p>Now that you've successfully acquired an access_token, you can use the token in requests to your backend web APIs by including it in the Authorization header:</p> <pre><code>GET /tasks\nHost: https://myapi.com\nAuthorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IlNTU...\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e2-OAuth-AuthZ-code-grant/#4-refresh-the-token","title":"4. Refresh the token","text":"<p>Both access_tokens and id_tokens short lived. You must refresh them after they expire to continue being able to access resources. You can do so by submitting another POST request to the /token endpoint. This time provide the refresh_token instead of the code:</p> <pre><code>POST https://{tenantName}.b2clogin.com/{tenantName}.onmicrosoft.com/oauth2/v2.0/token?p=b2c_1a_v1_signupsignin HTTP/1.1\nHost: https://{tenantName}.b2clogin.com\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=refresh_token\n&amp;client_id={clientId} offline_access\n&amp;refresh_token=eyJraWQiOiJIUTB6ZERpTlhmWHZyTWJ5cVpJQy10ZUZpbEV6ZVd5TUxHTUFIVTBmV...\n&amp;redirect_uri={redirectUri}\n&amp;client_secret={clientSecret}\n</code></pre> <p>A successful token response will look like:</p> <pre><code>{\n  \"id_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IkktZDdMQy1TQkltdUtZemNNQlg0WjhDYk10dU84YU9mSjJEZWJyTjM0M3cifQ.eyJleHAiOjE0OTYwNjY...\",\n  \"token_type\": \"Bearer\",\n  \"not_before\": \"1585051428\",\n  \"id_token_expires_in\": \"3600\",\n  \"profile_info\": \"eyJ2ZXIiOiIxLjAiLCJ0aWQiOiI1YmFmZTQwMC0yYTI1LTRmOTctOTE4NS1lMjgwYzdkY2JiMTUiLCJzdWIjpudWxsfQ...\",\n  \"refresh_token\": \"eyJraWQiOiIySlBBbU9EOHVYLTExY2d2U0gtR0FEM05WRU1HSFpsUlB3TUhsWXJ3VEgwIiwidmVyIjoiMS4wIiwiemlwIjoiRGVmbGF0ZSIsInNlciI6IjEuMCJ9.NcoK57fqPBZeLk3hY52KRQ...\",\n  \"refresh_token_expires_in\": \"7776000\"\n}\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e2-OAuth-AuthZ-code-grant/#5-authorization-code-grant-extension-proof-key-for-code-exchange-pkce","title":"5. Authorization code grant extension Proof Key for Code Exchange (PKCE)","text":"<p>With PKCE support for native apps and Single-page apps (SPA) there is no longer any reason to use the implicit grant.</p> <p>Microsoft now recommends the use of PKCE for all application types.</p> <p>For more information, see the PKCE RFC. PKCE is now recommended for all application types - also for confidential clients like web apps as well as native apps and Single Page Apps (SPAs).</p> <p>Reference: OAuth 2.0 authorization code flow in Azure Active Directory B2C</p> <p>For JavaScript single-page apps Microsoft has developed the authentication library MSAL.js. When using MSAL.js, make sure you are using MSAL.js 2.x to be able to work with PKCE. MSAL.js 1.x does NOT support PKCE, and accordingly, MSAL.js 2.x does NOT support the Implicit grant flow.</p> <p>These two Microsoft docs articles give some insights into Single-page apps (JavaScript) and some examples of how to use MSAL.js 2.x.</p> <p>Setting up a test app: Use Microsoft Authentication Library for JavaScript to work with Azure AD B2C. Calling the Graph API: Tutorial: Sign in users and call the Microsoft Graph API from a JavaScript single-page app (SPA) using auth code flow.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e3-OAuth-Client-credentials-grant/","title":"OAuth 2.0 client credentials grant","text":""},{"location":"Managed%20Azure%20AD%20B2C/e3-OAuth-Client-credentials-grant/#table-of-contents","title":"Table of contents","text":"<ul> <li>OAuth 2.0 client credentials grant</li> <li>Table of contents</li> <li>Introduction</li> <li>Get direct authorization<ul> <li>Access control lists</li> <li>Application permission</li> </ul> </li> <li>Get a token<ul> <li>Successful response</li> </ul> </li> <li>Use a token</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e3-OAuth-Client-credentials-grant/#introduction","title":"Introduction","text":"<p>You can use the OAuth 2.0 client credentials grant, sometimes called two-legged OAuth, to access web-hosted resources by using the identity of an application. This type of grant commonly is used for server-to-server interactions that must run in the background, without immediate interaction with a user. These types of applications often are referred to as daemons or service accounts.</p> <p>With the client credentials grant, permissions are granted directly to the application itself. When the app presents a token to a resource, the resource enforces that the app itself has authorization to perform an action, and not that the user has authorization.</p> <p>The entire client credentials grant flow is shown in the figure below:</p> <p></p> <p>The picture illustrates the OAuth consent process in the first request and the response. When using admin consent, the first step is not relevant as this is performed by the B2C tenant administrator when configuring the app registration.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e3-OAuth-Client-credentials-grant/#get-direct-authorization","title":"Get direct authorization","text":"<p>An app typically receives direct authorization to access a resource in one of two ways:</p> <ul> <li>Through an access control list (ACL) at the resource</li> <li>Through application permission assignment</li> </ul> <p>These two methods are the most common, and we recommend them for clients and resources that perform the client credential grant flow. A resource can choose to authorize its clients in other ways, however. Each resource server can choose the method that makes the most sense for its application.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e3-OAuth-Client-credentials-grant/#access-control-lists","title":"Access control lists","text":"<p>For data owned by organizations, we recommend that you get the necessary authorization through application permissions (see below).</p>"},{"location":"Managed%20Azure%20AD%20B2C/e3-OAuth-Client-credentials-grant/#application-permission","title":"Application permission","text":"<p>Instead of using ACLs, you can use APIs to expose a set of application permissions. An application permission is granted to an application by a tenant administrator, and can be used only to access data owned by that organization and its employees.</p> <p>For example, Microsoft Graph exposes several application permissions to do the following:</p> <ul> <li>Read.All : Allow the application to use Read functions in this API</li> <li>Write.All : Allow the application to use Write functions in this API</li> <li>ReadWrite.All : Allow the application full access to this API</li> </ul> <p>The above application roles are configured for each API. Additional roles can be configured on request. The access token will contain a roles claim that present the app roles granted to the calling application. The API must do authorization and verify that the access token contains the roles expected (e.g Read.All).</p> <p>An example of a token is shown below:</p> <pre><code>{\n  \"aud\": \"https://{tenantName}.onmicrosoft.com/2cbfa495-bb7b-48ac-8977-f2c88fc84cd9\",\n  \"iss\": \"https://sts.windows.net/ed815121-cdfa-4097-b524-e2b23cd36eb6/\",\n  \"iat\": 1585051428,\n  \"nbf\": 1585051428,\n  \"exp\": 1585051728,\n  \"aio\": \"Y2VgYHAN2v5u05L2Pd+qXl6s27zlIQA=\",\n  \"appid\": \"d9c1a607-2766-4a8e-bc08-4856fcf3ce11\",\n  \"appidacr\": \"1\",\n  \"idp\": \"https://sts.windows.net/ed815121-cdfa-4097-b524-e2b23cd36eb6/\",\n  \"oid\": \"30102cd8-12ee-40f9-bb4c-7b0493fc80bb\",\n  \"roles\": [\n    \"Write.All\",\"Read.All\"\n  ],\n  \"sub\": \"30102cd8-12ee-40f9-bb4c-7b0493fc80bb\",\n  \"tid\": \"ed815121-cdfa-4097-b524-e2b23cd36eb6\",\n  \"ver\": \"1.0\"\n}\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e3-OAuth-Client-credentials-grant/#get-a-token","title":"Get a token","text":"<p>To get a token by using the client credential grant flow, send a POST request to the /token v2.0 endpoint:</p> <pre><code>POST: https://{tenantName}.b2clogin.com/{tenantName}.onmicrosoft.com/oauth2/v2.0/token HTTP/1.1\nHost: https://{tenantName].b2clogin.com\nContent-Type: application/x-www-form-urlencoded\n\ngrant_type=client_credentials\n&amp;client_id={clientId}\n&amp;client_secret={clientSecret}\n&amp;scope={resource}\n</code></pre> Parameter Required Description grant_type Yes Must be client_credentials. client_id Yes The app ID. client_secret Yes The app secret that you generated for your app in the app registration blade. scope Yes The value passed for the scope parameter in this request should be the resource identifier (app ID URI of the resource you want https://{tenantName}.onmicrosoft.com/4e0b562a-64aa-4f66-80a3-0f83bbeb6b48). This value informs the v2.0 endpoint that of all the direct application permissions you have configured for your app, it should issue a token for the ones associated with the resource you want to use."},{"location":"Managed%20Azure%20AD%20B2C/e3-OAuth-Client-credentials-grant/#successful-response","title":"Successful response","text":"<p>A successful response looks like this:</p> <pre><code>{\n  \"access_token\":\"eyJhbGciOiJSUzI1NiIsIng1dCI6IjdkRC1nZWNOZ1gxWmY3R0xrT3ZwT0IyZGNWQSIsInR5cCI6IkpXVCJ9....\",\n  \"token_type\":\"Bearer\",\n  \"expires_in\":\"3599\",\n  \"ext_expires_in\":\"0\",\n  \"expires_on\":\"1585051728\",\n  \"not_before\":\"1585051428\",\n  \"resource\":\"https://{tenantName}.onmicrosoft.com/4e0b562a-64aa-4f66-80a3-0f83bbeb6b48\"\n}\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e3-OAuth-Client-credentials-grant/#use-a-token","title":"Use a token","text":"<p>Now that you\u2019ve acquired a token, use the access_token to make requests to the resource. When the token expires, repeat the request to the /token endpoint to acquire a fresh access_token. The example below show how the Authorization header is set when sending request to the graph API:</p> <pre><code>GET /v1.0/me/messages\nHost: https://graph.microsoft.com\nContent-Type: application/x-www-form-urlencoded\nAuthorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6Ik5HVEZ2ZEstZnl0aEV1Q...\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e4-OAuth-Implicit-grant/","title":"OAuth 2.0 implicit grant (see authorization code grant)","text":"<ul> <li>OAuth 2.0 implicit grant (see authorization code grant)</li> <li>Introduction</li> <li>Proof Key for Code Exchange (PKCE)</li> <li>Implicit grant</li> <li>Send authentication requests<ul> <li>Use a policy</li> </ul> </li> <li>Validating the id_token<ul> <li>Get additional access tokens for other resources</li> <li>Error response</li> </ul> </li> <li>Refreshing tokens</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e4-OAuth-Implicit-grant/#introduction","title":"Introduction","text":"<p>This article is included as reference to understand how the implicit grant works in case it will be used in test or needs to be implemented for a limited period of time.</p> <p>Even though the implicit grant flow is available it should be replaced by Proof Key for Code Exchange for OAuth Public Clients - PKCE reference.</p> <p>From Microsoft Learn on the use of implicit flow:</p> <p>For most of the history of OAuth 2.0, the implicit flow was the recommended way to build single-page apps. With the removal of third-party cookies and greater attention paid to security concerns around the implicit flow, we've moved to the authorization code flow for single-page apps.</p> <p>To ensure compatibility of your app in Safari and other privacy-conscious browsers, we no longer recommend use of the implicit flow and instead recommend the authorization code flow.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e4-OAuth-Implicit-grant/#proof-key-for-code-exchange-pkce","title":"Proof Key for Code Exchange (PKCE)","text":"<p>The Microsoft Identity platform supports Proof Key for Code Exchange (PKCE) for use with both Single-page apps (JavaScript, MSAL.js 2.x) and mobile / native apps.</p> <p>Many modern apps have a single-page app front end written primarily in JavaScript, often with a framework like Angular, React, or Vue.</p> <p>The Microsoft identity platform endpoint supports these apps by using the OAuth 2.0 authorization code flow.</p> <p>JavaScript and other single page apps that run primarily in a browser face a few interesting challenges when it comes to authentication:</p> <ul> <li>The security characteristics of these apps are significantly different from traditional server-based web applications.</li> <li>Many authorization servers &amp; identity providers do not support CORS (Cross-Origin Resource Sharing) requests.</li> <li>Full page browser redirects away from the app become particularly invasive to the user experience.</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e4-OAuth-Implicit-grant/#implicit-grant","title":"Implicit grant","text":"<p>NOTE!</p> <p>This latter part of document is primarily meant as a reference to better understand what implicit grant is and how it works (and how it doesn't). The implicit grant flow is still used by many applications, which is why the information here can be useful.</p> <p>For any new application integrations, look to use the Authorization code grant with PKCE.</p> <p>The OAuth 2.0 implicit grant is described in section 4.2 of the OAuth 2.0 specification.</p> <p>In this flow, the app receives tokens directly from the Identity platform /authorize endpoint, without any server-to-server exchanges. All authentication logic and session handling takes place entirely in the JavaScript client, without extra page redirects.</p> <p>The Microsoft identity platform extends the OAuth 2.0 implicit grant flows to do more than simple authentication and authorization. It introduces the policy parameter, which enables you to use OAuth 2.0 to add user experiences to your app, such as sign-up, sign-in, and profile management.</p> <p>The entire implicit flow is illustrated below:</p> <p></p>"},{"location":"Managed%20Azure%20AD%20B2C/e4-OAuth-Implicit-grant/#send-authentication-requests","title":"Send authentication requests","text":"<p>When your web app needs to authenticate the user and execute a policy, it directs the user to the /authorize endpoint. This is the interactive portion of the flow, where the user takes action, depending on the policy, and gets an id_token in return from the endpoint.</p> <p>In this request, the client indicates the permissions that it needs to acquire from the user in the scope parameter and the policy to execute in the p parameter.</p> <p>Examples are provided below (line breaks for legibility):</p>"},{"location":"Managed%20Azure%20AD%20B2C/e4-OAuth-Implicit-grant/#use-a-policy","title":"Use a policy","text":"<pre><code>GET https://{tenantName}.b2clogin.com/{tenantName}.onmicrosoft.com/oauth2/v2.0/authorize\n?client_id={clientId}\n&amp;response_mode={response_mode}\n&amp;response_type=id_token+token\n&amp;redirect_uri={redirectUri}\n&amp;scope={scope}\n&amp;p=b2c_1a_v1_signupsignin\n&amp;state={state}\n&amp;nonce={nonce}\n</code></pre> Parameter Required Description client_id Yes The application ID that the Azure portal assigned to your application response_type Yes The response type, which must include token for the implicit flow, but normally you also include id_token so you can authorize the user redirect_uri Yes The redirect_uri of your app, where authentication responses can be sent and received by your app. It must exactly match one of the redirect_uris that you registered in the portal, except that it must be URL encoded scope Yes A space-separated (URL encoded) list of scopes. You shall always specify openid as one of the scope values as this will initiate a OpenID Connect authentication process. If you only specify openid, then you will only get a id_token. If you in addition to openid specify a resource URL or AppID, then you will also get an access_token (Note! You can only specify 1 resource in the scope list. Multiple resources can only be attained by performing separate authorization code flows). Example shown below grid response_mode Recommended The method that should be used to send the resulting token back to your app. It can be one of query, form_post, or fragment state Highly Recommended A value included in the request that will also be returned in the token response. It can be a string of any content that you want, but a CSRF (cross-site request forgery) token i recommended. A randomly generated unique value is typically used for preventing cross-site request forgery attacks. The state is also used to encode information about the user's state in the app before the authentication request occurred, such as the page they were on or the policy being executed. You should store the value of the CSRF token in the users' session to be validated when they return p Yes The policy that will be executed. It is the name of a policy that is created in your B2C directory. The policy name value should begin with b2c_1a_ prompt Optional The type of user interaction that is required. See below for example how to use this parameter nonce Yes A value included in the request (generated by the app) that will be included in the resulting token as a claim. The app can then verify this value to mitigate token replay attacks. The value is typically a randomized, unique string that can be used to identify the origin of the request. Read how to Generate nonce <p>TIP!</p> <p>How to ask for an id_token, refresh_token and access_token to an API (the scope parameter MUST be URL encoded) with appID 4e0b562a-64aa-4f66-80a3-0f83bbeb6b48 and permissions (scopes) read and write:</p> <p>openid+offline_access+https%3a%2f%2f87{tenantName}.onmicrosoft.com%2f4e0b562a-64aa-4f66-80a3-0f83bbeb6b4830%2Fread+https%3a%2f%2f87{tenantName}.onmicrosoft.com%2f4e0b562a-64aa-4f66-80a3-0f83bbeb6b4830%2Fwrite</p> <p>At this point, the user will be asked to complete the policy workflow. This may involve the user entering their user name and password, signing in with a social identity, signing up for the directory, or any other number of steps, depending on how the policy is defined.</p> <p>After the user completes the policy, a response is returned to your app at the indicated redirect_uri, by using the method that is specified in the response_mode parameter. The response will be exactly the same for each of the above cases, independent of the policy that was executed.</p> <p>The response will be presented in the redirect-url and looks like this:</p> <pre><code>{\n    \"token_type\": \"Bearer\",\n    \"expires_in\": \"86400\",\n    \"id_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IkktZDdMQy1TQkltdUtZemNNQlg0WjhDYk10dU84YU9mSjJEZWJyTjM0M3cifQ...\",\n    \"state\": \"state=myState\",\n    \"access_token\": \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IkktZDdMQy1TQkltdUtZemNNQlg0WjhDYk10dU84YU9mSjJEZWJyTjM0M3cifQ...\"\n}\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e4-OAuth-Implicit-grant/#validating-the-id_token","title":"Validating the id_token","text":"<p>Just receiving an id_token is not enough to authenticate the user. You must validate the signature of the id_token and verify the claims in the token according to the requirements of your app.</p> <p>The Microsoft Identity platform uses JSON Web Tokens (JWTs) and public key cryptography to sign tokens and verify that they are valid.</p> <p>See Validating OpenID Connect and OAuth 2.0 tokens for best practice on how to validate a token.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e4-OAuth-Implicit-grant/#get-additional-access-tokens-for-other-resources","title":"Get additional access tokens for other resources","text":"<p>Even if you already received a token using the token response_type, you can use the below method to acquire tokens to additional resources without having to redirect the user to sign in again.</p> <p>In the normal web app flow, you would do this by making a request to the /token endpoint. However, the endpoint does not support CORS requests, so making AJAX calls to get and refresh tokens is out of the question. Instead, you can use the implicit grant in a hidden iframe to get new tokens for other web APIs from the /authorize endpoint:</p> <pre><code>https://{tenantName}.b2clogin.com/{tenantName}.onmicrosoft.com/oauth2/v2.0/authorize?\nclient_id=e0c5fe63-acf2-44c5-89b7-b1bbc4b29dc6\n&amp;response_type=token\n&amp;redirect_uri=https%3A%2F%2Fjwt.ms%2F\n&amp;scope=https%3a%2f%2f{tenantName}.onmicrosoft.com%2f9993ca2f-6cc4-4d47-b0ac-c10811ad43e330%2Fuser_impersonation\n&amp;response_mode=fragment\n&amp;state=arbitrary_data_you_can_receive_in_the_response\n&amp;nonce=12345\n&amp;prompt=none\n&amp;domain_hint=organizations\n&amp;login_hint=myuser@mycompany.com\n&amp;p=b2c_1a_v1_signupsignin\n</code></pre> Parameter Required Description prompt Yes For refreshing and getting additional tokens in a hidden iframe, use prompt=none to ensure that the iframe does not hang on the sign-in page, and returns immediately. login_hint Yes For refreshing and getting tokens in a hidden iframe, you must include the username of &gt;the user in this hint in order to distinguish between multiple sessions the user may have at a given point in time. You can extract the username from a previous sign-in using the preferred_username claim. domain_hint Yes Can be one of consumers or organizations. For refreshing and getting tokens in a hidden iframe, you must include the domain_hint in the request. Extract the tid claim from the id_token of a previous sign-in to determine which value to use. If the tid claim value is 9188040d-6c67-4c5b-b112-36a304b66dad, you should use domain_hint=consumers. Otherwise, use domain_hint=organizations. <p>By setting the prompt=none parameter, this request will either succeed or fail immediately and return to your application. A successful response will be sent to your app at the indicated redirect_uri, using the method specified in the response_mode parameter.</p> <p>A successful response is returned in the reply_url, and using response_mode=fragment would look like this:</p> <pre><code>state=myState\n&amp;access_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsImtpZCI6IkktZDdMQy1TQkltdUtZemNN...\n&amp;token_type=Bearer\n&amp;expires_in=86400\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e4-OAuth-Implicit-grant/#error-response","title":"Error response","text":"<p>Error responses may also be sent to the redirect_uri so the app can handle them appropriately. In the case of prompt=none, an expected error will be:</p> <pre><code>GET https://jwt.ms/#\nerror=user_authentication_required\n&amp;error_description=the+request+could+not+be+completed+silently\n</code></pre> <p>If you receive this error in the iframe request, the user must interactively sign in again to retrieve a new token. You can choose to handle this case in whatever way makes sense for your application.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e4-OAuth-Implicit-grant/#refreshing-tokens","title":"Refreshing tokens","text":"<p>IMPORTANT!</p> <p>Do not mistake refreshing tokens for the OAuth refresh token grant.</p> <p>The implicit grant does NOT provide refresh_tokens. It is possible to refresh tokens using the implicit flow, but it's not recommended for security, application, compatibility and user experience reasons.</p> <p>Both id_tokens and access_tokens expires after a short period of time, so your app must be prepared to refresh these tokens periodically. To refresh either type of token, perform the same hidden iframe request from above using the prompt=none parameter to control the behaviour. To receive a new id_token, be sure to use response_type=id_token and scope=openid, as well as a nonce parameter.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e5-Token-validation/","title":"Validate OpenID Connect and OAuth 2.0 tokens","text":""},{"location":"Managed%20Azure%20AD%20B2C/e5-Token-validation/#table-of-contents","title":"Table of contents","text":"<ul> <li>Validate OpenID Connect and OAuth 2.0 tokens</li> <li>Table of contents</li> <li>Introduction</li> <li>Validating OAuth 2.0 / OpenID Connect tokens</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e5-Token-validation/#introduction","title":"Introduction","text":"<p>This article explain the best practice how to validate tokens issued by the Microsoft Identity platform. There are two types of tokens, an id_token an an access_token. Access tokens are typically validated by APIs that receive the token as part of the authorization header in the API request, while id tokens are typically validated by the client (web server or native) before granting the user access to application features.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e5-Token-validation/#validating-oauth-20-openid-connect-tokens","title":"Validating OAuth 2.0 / OpenID Connect tokens","text":"<p>When receiving an id_token the token must be validated before it can be used to authenticate the user. Tokens are not encrypted, only signed, therefore the embedded signature must validated to ensure the authenticity of the id_token. Only then can the applications process the required claims according to it's requirement. Claims are packaged and transported in JSON Web Tokens (JWTs) and leverages public key cryptography to sign and verify token validity. Validating the access_token is equally important to ensure the authenticity of the token and that it is issued for use to query the resource (API).</p> <p>There are many open-source libraries that are available for validating JWTs, depending on your language of preference. Consider exploring those options rather than implementing your own validation logic. The information here will be useful in figuring out how to properly use those libraries.</p> <p>Every custom policy created in the Identity Experience Framework has a dedicated OpenID Connect metadata endpoint. This allows apps to fetch necessary information at runtime, including amongst others endpoints, token contents, and token signing keys. For example the metadata document for the B2C_1A_v1_signupsignin policy in the {tenantName}.onmicrosoft.com tenant would be located at:</p> <pre><code>https://{tenantName}.b2clogin.com/{tenantName}.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=B2C_1A_v1_signupsignin\n</code></pre> <p>One of the properties of this configuration document is the jwks_uri, which values for the same policy can be found at:</p> <pre><code>https://{tenantName}.b2clogin.com/{tenantName}.onmicrosoft.com/discovery/v2.0/keys?p=B2C_1A_v1_signupsignin\n</code></pre> <p>TIP!</p> <p>When using custom domain, {tenantName}.b2clogin.com, in the examples, can be replaced with the domain name.</p> <p>In order to determine which policy was used in signing an token (and where to fetch the metadata from), there are two options:</p> <ul> <li>The easiest and recommended way is to read the policy name included in the trustFrameworkPolicy or tfp claim in the token. For information on how to parse the claims from an token, see the Overview of tokens in Azure Active Directory B2C.</li> <li>Your other option is to encode the policy in the value of the state parameter when you issue the request, and then decode it to determine which policy was used. Either method is perfectly valid.</li> </ul> <p>After acquiring the metadata document from the OpenID Connect metadata endpoint, use the included RSA 256 public keys to validate the signature of the token. There may be multiple keys listed at this endpoint at any given point in time, each identified by a kid. The header of the token also contains a kid claim, which indicates which of these keys was used to sign the id_token.</p> <p>See Validate signature for more information.</p> <p>Also see Microsoft Learn article Validate the ID token to learn more about OpenID Connect on the Microsoft identity platform, token validation and when it's important and less so.</p> <p>After validating the signature of the token, several claims also require verification, for instance:</p> <ul> <li>Validate the nonce claim to prevent token replay attacks. Its value should be what you specified in the sign-in request.</li> <li>Validate the aud claim to ensure that the id_token was issued for your app. It's value should be the application ID of your app.</li> <li>Validate the iat and exp claims to ensure that the id_token has not expired.</li> <li>Microsoft recommendation for claims validation</li> </ul> <p>There are also several more validations that you should perform, see OpenID Connect Core for details. You might also want to validate additional claims, depending on your scenario. Some common validations include:</p> <ul> <li>Ensuring that the user has proper authorization / privileges.</li> <li>Ensuring that a certain strength of authentication has occurred, such as Multi-Factor Authentication.</li> </ul> <p>After you have completely validated the token, you can begin a session with the user and use the claims in the id_token to obtain information about the user in your app. This information can be used for display, records, authorization, and so on.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e6-Nonce/","title":"Nonce: Mitigate replay attacks when using implicit grant","text":""},{"location":"Managed%20Azure%20AD%20B2C/e6-Nonce/#table-of-contents","title":"Table of contents","text":"<ul> <li>Nonce: Mitigate replay attacks when using implicit grant</li> <li>Table of contents</li> <li>Introduction</li> <li>Generate a cryptographically random nonce</li> <li>Persist nonces across requests</li> <li>Validate the id_token</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e6-Nonce/#introduction","title":"Introduction","text":"<p>When using the implicit grant, a cryptographic nonce must be sent on authentication requests in order to mitigate replay attacks as required by the OpenID Connect specification.</p> <p>The nonce is generated by the client, sent as a nonce query string parameter in the authentication request, and included in the id_token response from the authorization endpoint. This allows clients to correlate the id_token response from the authorization server with the initial authentication request.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e6-Nonce/#generate-a-cryptographically-random-nonce","title":"Generate a cryptographically random nonce","text":"<p>Modern browsers can use the Web Crypto API to generate cryptographically secure random strings to use as nonces.</p> <p>Here is a JavaScript code example on how to generate a  nonce value:</p> <pre><code>function randomString(length) {\n    var bytes = new Uint8Array(length);\n    var random = window.crypto.getRandomValues(bytes);\n    var result = [];\n    var charset = '0123456789ABCDEFGHIJKLMNOPQRSTUVXYZabcdefghijklmnopqrstuvwxyz-._~'\n    random.forEach(function (c) {\n        result.push(charset[c % charset.length]);\n    });\n    return result.join('');\n}\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e6-Nonce/#persist-nonces-across-requests","title":"Persist nonces across requests","text":"<p>The generated nonce must be persisted in your web application using any of the following methods:</p> <ul> <li>HttpOnly session cookie</li> <li>HTML5 local storage</li> </ul> <p>Example:</p> <pre><code>window.localStorage.setItem('nonce', randomString(16));\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e6-Nonce/#validate-the-id_token","title":"Validate the id_token","text":"<p>Once an id_token has been received, this token must be validated and decoded as usual. Its nonce claim must contain the exact same value that was sent in the request. If not, authentication should be rejected by the application.</p> <pre><code>var jwt = '...'; // validated and decoded ID token body\nif (jwt.nonce === window.localStorage.getItem('nonce')) {\n    // Nonce is OK\n} else {\n    // Nonce is not OK! Token replay attack might be underway\n}\n</code></pre> <p>Source:</p> <p>Auth0 - Mitigate replay attacks when using the Implicit Grant</p>"},{"location":"Managed%20Azure%20AD%20B2C/e8-Debug-OIDC-and-OAuth/","title":"Debugging OpenID Connect and OAuth 2.0","text":"<ul> <li>Debugging OpenID Connect and OAuth 2.0</li> <li>Introduction</li> <li>How to debug</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e8-Debug-OIDC-and-OAuth/#introduction","title":"Introduction","text":"<p>OAuth 2.0 and OpenID Connect can be a bit troublesome to get working right away. This is generally something most people experience.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e8-Debug-OIDC-and-OAuth/#how-to-debug","title":"How to debug","text":"<p>To help with debugging, a gentleman by the name of Nate Barbettini, have developed a couple of tools called OAuth debugger and OpenID Connect debugger to help this process. To give these tools some more background and examples on how to use them, check out Nate's Introducing the OpenID Connect debugger post.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e9a-SAML/","title":"Security Assertion Markup Language 2.0 (SAML)","text":"<ul> <li>Security Assertion Markup Language 2.0 (SAML)</li> <li>Introduction</li> <li>The basics</li> <li>Token and claims</li> <li>Identity Experience Framework SAML integration</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e9a-SAML/#introduction","title":"Introduction","text":"<p>Quote from SAML 2.0 Wikipedia post:</p> <p>SAML is a standard for exchanging authentication and authorization data between security domains.</p> <p>SAML 2.0 is an XML-based protocol that uses security tokens containing assertions to pass information about a principal (usually an end user) between a SAML authority, named an Identity Provider, and a SAML consumer, named a Service Provider.</p> <p>SAML 2.0 enables web-based, cross-domain single sign-on (SSO), which helps reduce the administrative overhead of distributing multiple authentication tokens to the user.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e9a-SAML/#the-basics","title":"The basics","text":"<p>Every application that uses the Identity Platform must be associated with an application registered in the B2C directory to be able to service users. Regardless of what protocol used to communicate, the developed app must use these settings from it's dedicated B2C application registration to exchange information:</p> <ul> <li>An Application ID or Client ID that uniquely identifies the application</li> <li>A Redirect URI or package identifier in which the response of the authentication is returned</li> </ul> <p>Once the application is configured with the settings provided by the app registration, the users are ready to sign in, which will trigger the following flow:</p> <p> Source: Choosing an SSO Strategy: SAML vs OAuth2</p> <p>As illustrated and explained in Authentication and Authorization, nearly all OAuth 2.0 and OpenID Connect flows involve four parties. The same goes for SAML. Though, the naming of the involved parties differs slightly. SAML names first:</p> <ul> <li>The Service Provider is the system you are trying to access. OAuth refers to this as the Resource Server</li> <li>The Client is how you are interacting with the Service Provider, for example through a web application using a web browser</li> <li>The Identity Provider in SAML is referred to as the Authorization Server  and is the Identity Platform v2.0 endpoint (but  identity provider is also commonly used). It is responsible for verifying the user's identity</li> <li>The Resource Owner (referred to as User on the flow chart) is typically the end user. It is the party that owns the data</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e9a-SAML/#token-and-claims","title":"Token and claims","text":"<p>The result of a user sign in flow will result in a verified token with the configured amount of claims / statements regarding the user. In a given scenario this would happen:</p> <ol> <li>A client requests a SAML token from a security token service, authenticating to that security token service by using valid credentials</li> <li>The security token service issues a SAML token to the client. The SAML token is signed with a certificate associated with the security token service and contains a proof key encrypted for the target service</li> <li>The client also receives a copy of the proof key. The client then presents the SAML token to the application service (the relying party) and signs the message with that proof key</li> <li>The signature over the SAML token tells the relying party that the security token service issued the token. The message signature created with the proof key tells the relying party that the token was issued to the client</li> </ol> <p>Microsoft's SAML Tokens and Claims article explains how it fits within the Windows Communication Foundation (WCF). However, the implementation of SAML should not differ depending on where the protocol is being used. The principals stay the same.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e9a-SAML/#identity-experience-framework-saml-integration","title":"Identity Experience Framework SAML integration","text":"<p>This Microsoft docs page explains how to integrate with SAML and act as an Identity provider.</p> <p>On the same page you will find guides how to integrate the Identity Experience Framework as a Service Provider (SP) using SAML when either Active Directory Federation Services (ADFS) running on Windows Server 2016) or Salesforce acts as the identity provider.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/","title":"Azure AD B2C: Integrate SAML based applications","text":"<ul> <li>Azure AD B2C: Integrate SAML based applications</li> <li>Introduction</li> <li>The two scenarios<ul> <li>Identity Experience Framework as a SAML Service provider (SP)</li> <li>Identity Experience Framework as a SAML Identity provider (IdP)</li> </ul> </li> <li>Configure Identity Experience Framework as a SAML Identity provider<ul> <li>Create self-signed certificate</li> <li>Use an existing certificate signed by a trusted certificate authority</li> <li>Upload the certificate(s) to the Identity Experience Framework</li> <li>Claims provider</li> <li>Technical profile</li> <li>SAML Token Issuer</li> <li>Metadata</li> <li>CryptographicKeys</li> <li>User Journey</li> <li>SAML Sign In User Journey</li> <li>Execution Policy</li> <li>SAML relying party</li> </ul> </li> <li>SAML Service Provider (SP) configuration<ul> <li>SAML SP metadata</li> <li>SAML SP issuer</li> <li>SAML URL / SAML Endpoint / Login URL</li> </ul> </li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#introduction","title":"Introduction","text":"<p>The Identity Experience Framework can easily be extended to allow external identity provider authentication. Using Security Assertion Markup Language 2.0 protocol it is possible to integrate with SAML-based applications using custom policies.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#the-two-scenarios","title":"The two scenarios","text":"<p>Support for the SAML protocol allows us to connect to applications in two ways. The main difference is where the authentication responsibilities lie. This also dictates where the identity store is located. In either scenario, using the Identity Experience Framework, we can move authentication away from the applications.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#identity-experience-framework-as-a-saml-service-provider-sp","title":"Identity Experience Framework as a SAML Service provider (SP)","text":"<p>Microsoft Docs provides some examples on the configuration of the IEF as a SAML Service Provider (SP):</p> <ul> <li>ADFS as SAML identity provider</li> <li>Salesforce as a SAML identity provider</li> </ul> <p>This enables us to integrate a SAML based external identity provider (IdP) with the IEF. Here it assumes the Service provider role.</p> <p>A user is working in an application integrated with the Identity Platform. The user wants to sign in and is then redirected to the platform sign in page. On this page it is possible to authenticate using the SAML integrated IdP, either ADFS or Salesforce (or any other SAML based IdP). From the application perspective the Identity Platform / Identity Experience Framework is the provider of the authentication service, but what the application doesn't know, is that the IEF may have support for multiple SAML based external IdPs.</p> <p>Upon successful authentication the user is redirected back to the application and signed in.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#identity-experience-framework-as-a-saml-identity-provider-idp","title":"Identity Experience Framework as a SAML Identity provider (IdP)","text":"<p>The second scenario takes place when IEF is assigned the SAML compliant Identity Provider role.</p> <p>A user is working in an application that is connected to the Identity Platform using the SAML protocol. When initiating a login the user is redirected to the sign in page and prompted for credentials. Because IEF is configured to operate as the IdP we can also enable the sign up flow and allow the user to create an account.</p> <p>Upon successful authentication, or a completed sign up flow, the user is returned to the application and signed in.</p> <p>Configuring the Identity Experience Framework as an IdP gives us the added benefit of centralizing user management.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#configure-identity-experience-framework-as-a-saml-identity-provider","title":"Configure Identity Experience Framework as a SAML Identity provider","text":""},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#create-self-signed-certificate","title":"Create self-signed certificate","text":"<p>Using Powershell we create (by self-signing) a certificate that is placed in the CurrentUser\\Personal\\Certificates store and exported to the directory where the script is stored. The certificate and it's private key is stored in an encrypted PKCS #12 container saved as a password protected .PFX file.</p> <p>PKCS #12 is extended from Microsoft PFX file format. In cryptography, PKCS #12 defines an archive file format for storing many cryptography objects as a single file. It is commonly used to bundle a private key with its X.509 certificate or to bundle all the members of a chain of trust.</p> <pre><code>$tenantName = \"{tenantName}.onmicrosoft.com\"\n$certStore = \"Cert:\\CurrentUser\\My\" # \"Cert:\\LocalMachine\\My\"\n$certName = \"IEFClientCert.pfx\"\n$pwdText = \"IEFClientCertPassword\"\n\n$pfxCertFile = if ($PSCommandPath -eq \"\") {$certName} else {($PSCommandPath | Split-Path -Parent) + \"\\\" + $certName}\n$pwd = ConvertTo-SecureString -String $pwdText -Force -AsPlainText\n$signingCert = New-SelfSignedCertificate -CertStoreLocation $certStore -DnsName \"$tenantName\" -Subject \"IEF SAML Signing Cert\" -HashAlgorithm SHA256 -KeySpec Signature -KeyLength 2048 -FriendlyName \"IEF SAML Signing Cert\" -NotAfter (get-date).AddYears(10)\nExport-PfxCertificate -Cert $signingCert -FilePath $pfxCertFile -Password $pwd\nRemove-Item -Path $certStore\\$($signingCert.thumbprint)\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#use-an-existing-certificate-signed-by-a-trusted-certificate-authority","title":"Use an existing certificate signed by a trusted certificate authority","text":"<p>We assume the certificate exists in either the user (CurrentUser) or computer (LocalMachine) certificate store. Modify script to match the appropriate store. We also need the thumbprint of the certificate which can be found by listing the certificate.</p> <pre><code>Get-ChildItem Cert:\\CurrentUser\\My\n# or\nGet-ChildItem Cert:\\LocalMachine\\My\n</code></pre> <pre><code>Get-ChildItem Cert:\\CurrentUser\\My\n\nPSParentPath: Microsoft.PowerShell.Security\\Certificate::CurrentUser\\My\n\nThumbprint                                Subject\n----------                                -------\nD26F7EB6E190A557468C20BEA6D78226F4669229  CN=IEF SAML Signing Cert\n</code></pre> <pre><code>$thumbprint = \"\"\n$certStore = \"Cert:\\CurrentUser\\My\" # \"Cert:\\LocalMachine\\My\"\n$certName = \"IEFSigningCert.pfx\"\n$pwdText = \"IEFSigningCertPassword\"\n\n$pwd = ConvertTo-SecureString -String $pwdText -Force -AsPlainText\n$pfxCertFile = if ($PSCommandPath -eq \"\") {$certName} else {($PSCommandPath | Split-Path -Parent) + \"\\\" + $certName}\nExport-PfxCertificate -Cert ($certStore + \"\\\" + $thumbprint) -FilePath $pfxCertFile -Password $pwd\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#upload-the-certificates-to-the-identity-experience-framework","title":"Upload the certificate(s) to the Identity Experience Framework","text":"<p>SAML uses both an assertion signing and a message signing certificate. We could have uploaded two different certificates, but do not want to add unnecessary complexity so we reuse the same certificate in both containers.</p> <ul> <li>In your B2C tenant, go to Azure AD B2C &gt; Identity Experience Framework &gt; Policy Keys</li> </ul> <p></p> <ol> <li>Select + Add</li> <li>Select Options &gt; Upload</li> <li>Enter a Name (for example NameOfApplicationAssertionSigning). The prefix B2C_1A_ is automatically added to the name of the key container</li> <li>Upload the certificate using the upload file control</li> <li>Enter the certificate's password</li> <li>Select Create</li> </ol> <p></p> <ul> <li>Repeat the process for the message signing certificate.</li> </ul> <p></p> <ul> <li>Verify that the keys now exists in the Policy Keys list.</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#claims-provider","title":"Claims provider","text":"<p>Open the b2c_1a_v1_base policy.</p> <p>Find the section with ClaimsProviders or Custom ClaimsProviders and locate the following claims provider:</p> <pre><code>&lt;ClaimsProvider&gt;\n    &lt;DisplayName&gt;Token Issuer&lt;/DisplayName&gt;\n    &lt;TechnicalProfiles&gt;\n\n    ...\n    ..\n    .\n\n    &lt;/TechnicalProfiles&gt;\n&lt;/ClaimsProvider&gt;\n</code></pre> <p>This is the claims provider for the default Token Issuer.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#technical-profile","title":"Technical profile","text":""},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#saml-token-issuer","title":"SAML Token Issuer","text":"<p>Inside the &lt;ClaimsProvider&gt; add the following &lt;TechnicalProfile&gt; right after the one with Id=\"JwtIssuer\".</p> <pre><code>&lt;!-- Custom SAML Token Issuer --&gt;\n&lt;TechnicalProfile Id=\"Saml2AssertionIssuer\"&gt;\n    &lt;DisplayName&gt;Token Issuer&lt;/DisplayName&gt;\n    &lt;Protocol Name=\"None\" /&gt;\n    &lt;OutputTokenFormat&gt;SAML2&lt;/OutputTokenFormat&gt;\n    &lt;Metadata&gt;\n        &lt;Item Key=\"IssuerUri\"&gt;https://{tenantName}.b2clogin.com/te/{tenantName}.onmicrosoft.com/B2C_1A_saml_application&lt;/Item&gt;\n    &lt;/Metadata&gt;\n    &lt;CryptographicKeys&gt;\n\n        &lt;!-- Custom SAML certificate container references --&gt;\n        &lt;Key Id=\"SamlAssertionSigning\" StorageReferenceId=\"B2C_1A_NameOfApplicationAssertionSigning\" /&gt;\n        &lt;Key Id=\"SamlMessageSigning\" StorageReferenceId=\"B2C_1A_NameOfApplicationMessageSigning\" /&gt;\n\n    &lt;/CryptographicKeys&gt;\n    &lt;InputClaims /&gt;\n    &lt;OutputClaims /&gt;\n    &lt;UseTechnicalProfileForSessionManagement ReferenceId=\"SM-Saml\" /&gt;\n&lt;/TechnicalProfile&gt;\n</code></pre> <pre><code>&lt;TechnicalProfile Id=\"SM-Saml\"&gt;\n    &lt;DisplayName&gt;Session Management Provider&lt;/DisplayName&gt;\n    &lt;Protocol Name=\"Proprietary\" Handler=\"Web.TPEngine.SSO.SamlSSOSessionProvider, Web.TPEngine, Version=1.0.0.0, Culture=neutral, PublicKeyToken=null\" /&gt;\n&lt;/TechnicalProfile&gt;\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#metadata","title":"Metadata","text":"<p>Change the following in the &lt;Metadata&gt; tag:</p> Metadata Value Comment IssuerUri https:// Change tenantName and modify the SAML execution policy name (b2c_1a_*)"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#cryptographickeys","title":"CryptographicKeys","text":"<p>Change the following in the &lt;CryptographicKeys&gt; tag:</p> CryptoGraphicKey Value Comment SamlAssertionSigning StorageReferenceId= B2C_1A_AssertionSign Name of the B2C policy key container for the uploaded SAML assertion signing certificate. SamlMessageSigning StorageReferenceId= B2C_1A_MessageSign Name of B2C the policy key container for the uploaded SAML message signing certificate."},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#user-journey","title":"User Journey","text":""},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#saml-sign-in-user-journey","title":"SAML Sign In User Journey","text":"<p>Now the Trust Policy Framework is ready to issue SAML tokens. Create a User Journey that will issue SAML tokens. Copy an existing User Journey, either a sign up sign in policy or a sign in policy.</p> <ol> <li>Open the base_extensions policy file containing the User Journeys.</li> <li>Copy and paste the example below to the policy file, adjust the journey to your own specific needs.</li> <li>Change UserJourney Id=\"SamlApplicationSignIn\" to the name best suited to the User Journey.</li> <li>Make sure CpimIssuerTechnicalProfileReferenceId=\"Saml2AssertionIssuer\" is matching &lt;TechnicalProfile Id=\"Saml2AssertionIssuer\"&gt; from the SAML token issuer section.</li> </ol> <pre><code>&lt;UserJourney Id=\"SamlApplicationSignIn\"&gt;\n    &lt;PreserveOriginalAssertion&gt;false&lt;/PreserveOriginalAssertion&gt;\n\n    &lt;OrchestrationSteps&gt;\n    &lt;OrchestrationStep Order=\"1\" Type=\"ClaimsProviderSelection\" ContentDefinitionReferenceId=\"api.idpselections\"&gt;\n        &lt;ClaimsProviderSelections&gt;\n        &lt;ClaimsProviderSelection TargetClaimsExchangeId=\"FacebookExchange\" /&gt;\n        &lt;ClaimsProviderSelection TargetClaimsExchangeId=\"GoogleExchange\" /&gt;\n        &lt;ClaimsProviderSelection TargetClaimsExchangeId=\"AADExchange\" /&gt;\n        &lt;ClaimsProviderSelection TargetClaimsExchangeId=\"LocalAccountSigninEmailExchange\" /&gt;\n        &lt;/ClaimsProviderSelections&gt;\n    &lt;/OrchestrationStep&gt;\n\n    &lt;OrchestrationStep Order=\"2\" Type=\"ClaimsExchange\"&gt;\n        &lt;ClaimsExchanges&gt;\n        &lt;ClaimsExchange Id=\"FacebookExchange\" TechnicalProfileReferenceId=\"Facebook-OAUTH\" /&gt;\n        &lt;ClaimsExchange Id=\"GoogleExchange\" TechnicalProfileReferenceId=\"Google-OAUTH\" /&gt;\n        &lt;ClaimsExchange Id=\"AADExchange\" TechnicalProfileReferenceId=\"AAD-OIDC\" /&gt;\n        &lt;ClaimsExchange Id=\"LocalAccountSigninEmailExchange\" TechnicalProfileReferenceId=\"SelfAsserted-LocalAccountSignin-Email\" /&gt;\n        &lt;/ClaimsExchanges&gt;\n    &lt;/OrchestrationStep&gt;\n\n    &lt;OrchestrationStep Order=\"3\" Type=\"ClaimsExchange\"&gt;\n        &lt;Preconditions&gt;\n        &lt;Precondition Type=\"ClaimEquals\" ExecuteActionsIf=\"true\"&gt;\n            &lt;Value&gt;authenticationSource&lt;/Value&gt;\n            &lt;Value&gt;localAccountAuthentication&lt;/Value&gt;\n            &lt;Action&gt;SkipThisOrchestrationStep&lt;/Action&gt;\n        &lt;/Precondition&gt;\n        &lt;/Preconditions&gt;\n        &lt;ClaimsExchanges&gt;\n        &lt;ClaimsExchange Id=\"AADUserReadWithAlternativeSecurityId\" TechnicalProfileReferenceId=\"AAD-UserReadUsingAlternativeSecurityId\" /&gt;\n        &lt;/ClaimsExchanges&gt;\n    &lt;/OrchestrationStep&gt;\n\n    &lt;OrchestrationStep Order=\"4\" Type=\"SendClaims\" CpimIssuerTechnicalProfileReferenceId=\"Saml2AssertionIssuer\" /&gt;\n    &lt;/OrchestrationSteps&gt;\n    &lt;ClientDefinition ReferenceId=\"DefaultWeb\" /&gt;\n\n&lt;/UserJourney&gt;\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#execution-policy","title":"Execution Policy","text":""},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#saml-relying-party","title":"SAML relying party","text":"<p>Create your execution policy and use the following example to create your relying party.</p> <pre><code>&lt;RelyingParty&gt;\n    &lt;DefaultUserJourney ReferenceId=\"SamlApplicationSignIn\" /&gt;\n\n    &lt;TechnicalProfile Id=\"PolicyProfile\"&gt;\n    &lt;DisplayName&gt;SAML application sign in policy profile&lt;/DisplayName&gt;\n    &lt;Protocol Name=\"SAML2\" /&gt;\n\n        &lt;Metadata&gt;\n        &lt;Item Key=\"PartnerEntity\"&gt;https://url_to_sp_metadata&lt;/Item&gt;\n        &lt;Item Key=\"KeyEncryptionMethod\"&gt;Rsa15&lt;/Item&gt;\n        &lt;Item Key=\"DataEncryptionMethod\"&gt;Aes256&lt;/Item&gt;\n        &lt;Item Key=\"XmlSignatureAlgorithm\"&gt;Sha256&lt;/Item&gt;\n        &lt;/Metadata&gt;\n\n        &lt;!-- SAML does not support the input claims in authentication requests --&gt;\n        &lt;InputClaims /&gt;\n\n        &lt;OutputClaims&gt;\n        &lt;OutputClaim ClaimTypeReferenceId=\"objectId\" PartnerClaimType=\"oid\" /&gt;\n        &lt;OutputClaim ClaimTypeReferenceId=\"displayName\" /&gt;\n        &lt;OutputClaim ClaimTypeReferenceId=\"userPrincipalName\" /&gt;\n        &lt;/OutputClaims&gt;\n\n        &lt;SubjectNamingInfo ClaimType=\"oid\" /&gt;\n\n    &lt;/TechnicalProfile&gt;\n&lt;/RelyingParty&gt;\n</code></pre> <p>Change the following in the &lt;RelyingParty&gt; tag:</p> Metadata Value Comment DefaultUserJourney ReferenceId=\"SamlApplicationSignIn\" Change SamlApplicationSignIn to match UserJourney Id from SAML SignIn UserJourney section. <p>Change the following in the &lt;Metadata&gt; tag:</p> Metadata Value Comment PartnerEntity https:// Change PartnerEntity to resolve the Service Provider (SP) metadata document. If the SP does not have a metadata URL the metadata must be added in the Metadata tag KeyEncryptionMethod Rsa15 This is the default value. DataEncryptionMethod Aes256 This is the default value. XmlSignatureAlgorithm Sha256 This is the default value. <p>In the &lt;OutputClaims&gt; tag we configure the claims we wish include in the SAML token:</p> Metadata Value Comment OutputClaim objectId PartnerClaimType=\"oid\" maps the locally defined objectId claim to the oid claim in the SAML token. OutputClaim displayName Optional. OutputClaim userPrincpalName Optional. <p>Examples of commonly used user claims:  givenName, surname, email, identityProvider.</p> <p>The &lt;SubjectNamingInfo&gt; tag sets the claim that uniquely identifies the user in the SAML token, which is the oid claim:</p> Metadata Value Comment SubjectNamingInfo oid Do not modify. Value is mapped to that of the objectId claim by configuring OutputClaim ClaimTypeReferenceId=\"objectId\" PartnerClaimType=\"oid\". This claim is required as it is the unique identifier of the user in the B2C Azure AD. <p>If a case arises where the user unique identifier claim changes, rather look to modify the OutputClaim ClaimTypeReferenceId=\"objectId\" PartnerClaimType=\"oid\" and not the SubjectNamingInfo ClaimType=\"oid\".</p>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#saml-service-provider-sp-configuration","title":"SAML Service Provider (SP) configuration","text":"<p>These are the URLs / endpoints that might be required on the SAML SP side. If the SP cannot get the certificate(s) from metadata, you will need to export the public part of the certificate(s), and provide this to the SP manually.</p> <p>TIP!</p> <p>When using a custom domain, {tenantName}.b2clogin.com can be replaced with the domain name.</p>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#saml-sp-metadata","title":"SAML SP metadata","text":"<pre><code>https://{tenantName}.b2clogin.com/te/{tenantName}.onmicrosoft.com/B2C_1A_v1_SAML_SignIn/Samlp/metadata\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#saml-sp-issuer","title":"SAML SP issuer","text":"<pre><code>https://{tenantName}.b2clogin.com/te/{tenantName}.onmicrosoft.com/B2C_1A_v1_SAML_SignIn\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/e9b-SAML-app-integration/#saml-url-saml-endpoint-login-url","title":"SAML URL / SAML Endpoint / Login URL","text":"<pre><code>https://{tenantName}.b2clogin.com/te/{tenantName}.onmicrosoft.com/B2C_1A_v1_SAML_SignIn/Samlp/sso/login\n</code></pre>"},{"location":"Managed%20Azure%20AD%20B2C/f1-DEV-User-Journeys/","title":"DEV - tenant.onmicrosoft.com - user journeys","text":""},{"location":"Managed%20Azure%20AD%20B2C/f1-DEV-User-Journeys/#table-of-contents","title":"Table of contents","text":"<ul> <li>DEV - tenant.onmicrosoft.com - user journeys</li> <li>Table of contents</li> <li>Introduction</li> <li>Execution policies (User Journeys)</li> <li>Single Sign-On</li> <li>Localization</li> <li>User Journey - signupsignin</li> <li>User Journey - passwordreset</li> <li>User Journey - profileedit</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/f1-DEV-User-Journeys/#introduction","title":"Introduction","text":"<p>User Journey is the term used to define the flow that users go through when signing in. Through the Identity Experience Framework we craft User Journeys using custom policies.</p> <p>When authentication is required, a redirect to the Identity platform happens and a User Journey is triggered.</p> <p>User Journeys are flexible and can be customized to interact with APIs, they can be configured to perform progressive profiling, require the user to sign in using multi-factor authentication and much more, with few limitations.</p> <p>User Journeys does not have to be advanced, nor complex, and best practice is to keep them as simple as possible, while keeping the user experience in mind.</p> <p>The Fortytwo Managed B2C offering leverages custom policies as the building blocks for our User Journeys.  </p> <p>When naming a User Journey it is good practice to use descriptive names, taking into consideration the flow, and potentially also language support.</p>"},{"location":"Managed%20Azure%20AD%20B2C/f1-DEV-User-Journeys/#execution-policies-user-journeys","title":"Execution policies (User Journeys)","text":"<p>Policies commonly used by applications:</p> <ul> <li>v1</li> <li>b2c_1a_v1_signupsignin</li> </ul> <p>Policies (usually) included in Managed B2C deployment:</p> <ul> <li>v2</li> <li>b2c_1a_v2_signupsignin</li> <li>b2c_1a_v2_passwordreset</li> <li>b2c_1a_v2_profileedit</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/f1-DEV-User-Journeys/#single-sign-on","title":"Single Sign-On","text":"<p>User Journeys can be configured for Single Sign-On support using the Scope=\"Tenant\" parameter.</p>"},{"location":"Managed%20Azure%20AD%20B2C/f1-DEV-User-Journeys/#localization","title":"Localization","text":"<p>English language is default, multi-language support is not configured.</p> <p>Localization is configured in the execution policy files, and not represented by claims emitted in issued tokens.</p> <p>Multi-language can be configured in the execution policy file for the User Journey. Localization, meaning supported languages, is decided by configuration policy parameter SupportedLanguages.</p>"},{"location":"Managed%20Azure%20AD%20B2C/f1-DEV-User-Journeys/#user-journey-signupsignin","title":"User Journey - signupsignin","text":"<p>Policy file b2c_1a_v2_signupsignin triggers the primary User Journey signupsignin.</p> <p>When triggered the signupsignin User Journey directs the user to a branded landing page. On the page the user has two options: sign in with email or password reset.</p> <p>There are two themes available through the custom branding feature, Slate Gray and Ocean Blue. Schema content definition configuration says which is applied to the User Journeys, which includes custom html, css and javascript files that shape the B2C pages.</p> <p>Once the user provides a matching username, the Identity Platform issues a token, which is returned to the application, along with the user which is now signed in.</p>"},{"location":"Managed%20Azure%20AD%20B2C/f1-DEV-User-Journeys/#user-journey-passwordreset","title":"User Journey - passwordreset","text":"<p>Policy file b2c_1a_v2_passwordreset triggers the password reset flow.</p> <p>User Journey passwordreset enables the user to reset their password using email verification with one-time passcodes (OTP).</p> <p>After successful email verification, and choosing a password that fulfils the password complexity requirements, a token is issued and the user is signed in.</p>"},{"location":"Managed%20Azure%20AD%20B2C/f1-DEV-User-Journeys/#user-journey-profileedit","title":"User Journey - profileedit","text":"<p>Policy file b2c_1a_v2_profileedit triggers the profile edit flow.</p> <p>User Journey profileedit enables the user to update their personal information (not including email).</p> <p>Profile edit assumes the user already has an existing session and is meant to be triggered within and application by a user with an already active session.</p>"},{"location":"Managed%20Azure%20AD%20B2C/f2-DEV-Custom-policy-files/","title":"DEV - tenant.onmicrosoft.com - custom policy files","text":""},{"location":"Managed%20Azure%20AD%20B2C/f2-DEV-Custom-policy-files/#table-of-contents","title":"Table of contents","text":"<ul> <li>DEV - tenant.onmicrosoft.com - custom policy files</li> <li>Table of contents</li> <li>Introduction</li> <li>v1 policies</li> <li>v2 policies</li> <li>Foundational policy files</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/f2-DEV-Custom-policy-files/#introduction","title":"Introduction","text":"<p>The Identity Experience Framework uses custom policies, which are very flexible and configurable building blocks. Current User Journeys were designed, developed and implemented with custom policies and they are the foundation of the Identity platform.</p> <p>All User Journeys have been configured for tenant-wide Single Sign-On support.</p> <p>TIP!</p> <p>All implementations use the custom domain functionality.</p> <p>When using custom domain, {tenantName}.b2clogin.com, in the examples, can be replaced with the domain name. Both domains are active and functioning, but use one at a time as Single Sign-On does not work across different domains.</p>"},{"location":"Managed%20Azure%20AD%20B2C/f2-DEV-Custom-policy-files/#v1-policies","title":"v1 policies","text":"<p>Policies in the v1 file set are the recommended, and most stable, policies for application integration.</p> Policy file User Journey Description Metadata endpoint User Journey test link Custom domain b2c_1a_v1_signupsignin Sign in The primary (default) User Journey, sign in with email and password reset https://custom.domain.com/tenantname.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=b2c_1a_v1_signupsignin https://tenantname.b2clogin.com/tenantname.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=b2c_1a_v1_signupsignin Sign In custom.domain.com tenantname.b2clogin.com - - - - - -"},{"location":"Managed%20Azure%20AD%20B2C/f2-DEV-Custom-policy-files/#v2-policies","title":"v2 policies","text":"<p>Policies deployed through Managed B2C pipelines.</p> Policy file User Journey Description Metadata endpoint User Journey test link Custom domain b2c_1a_v2_signupsignin Sign in The primary (default) User Journey, sign in with email and password reset https://custom.domain.com/tenantname.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=b2c_1a_v2_signupsignin https://tenantname.b2clogin.com/tenantname.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=b2c_1a_v2_signupsignin Sign In custom.domain.com tenantname.b2clogin.com b2c_1a_v2_passwordreset Password reset Password reset User Journey https://custom.domain.com/tenantname.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=b2c_1a_v2_passwordreset https://tenantname.b2clogin.com/tenantname.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=b2c_1a_v2_passwordreset Password reset custom.domain.com tenantname.b2clogin.com b2c_1a_v2_profileedit Profile edit User Journey for modifying profile data https://custom.domain.com/tenantname.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=b2c_1a_v2_profileedit https://tenantname.b2clogin.com/tenantname.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=b2c_1a_v2_profileedit Profile edit custom.domain.com tenantname.b2clogin.com"},{"location":"Managed%20Azure%20AD%20B2C/f2-DEV-Custom-policy-files/#foundational-policy-files","title":"Foundational policy files","text":"Policy file Description b2c_1a_v1_base / b2c_1a_v2_base Trust Framework Policy base containing all building blocks and definitions necessary for the User Journeys b2c_1a_v1_base_extensions / b2c_1a_v2_base_extensions Trust Framework Policy base extensions holding all the User Journeys"},{"location":"Managed%20Azure%20AD%20B2C/g1-TEST-User-Journeys/","title":"TEST - tenant.onmicrosoft.com - user journeys","text":""},{"location":"Managed%20Azure%20AD%20B2C/g1-TEST-User-Journeys/#table-of-contents","title":"Table of contents","text":"<ul> <li>TEST - tenant.onmicrosoft.com - user journeys</li> <li>Table of contents</li> <li>Introduction</li> <li>Execution policies (User Journeys)</li> <li>Single Sign-On</li> <li>Localization</li> <li>User Journey - signupsignin</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/g1-TEST-User-Journeys/#introduction","title":"Introduction","text":"<p>User Journey is the term used to define the flow that users go through when signing in. Through the Identity Experience Framework we craft User Journeys using custom policies.</p> <p>When authentication is required, a redirect to the Identity platform happens and a User Journey is triggered.</p> <p>User Journeys are flexible and can be customized to interact with APIs, they can be configured to perform progressive profiling, require the user to sign in using multi-factor authentication and much more, with few limitations.</p> <p>User Journeys does not have to be advanced, nor complex, and best practice is to keep them as simple as possible, while keeping the user experience in mind.</p> <p>The Fortytwo Managed B2C offering leverages custom policies as the building blocks for our User Journeys.  </p> <p>When naming a User Journey it is good practice to use descriptive names, taking into consideration the flow, and potentially also language support.</p>"},{"location":"Managed%20Azure%20AD%20B2C/g1-TEST-User-Journeys/#execution-policies-user-journeys","title":"Execution policies (User Journeys)","text":"<p>Policies commonly used by applications:</p> <ul> <li>v1</li> <li>b2c_1a_v1_signupsignin</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/g1-TEST-User-Journeys/#single-sign-on","title":"Single Sign-On","text":"<p>User Journeys can be configured for Single Sign-On support using the Scope=\"Tenant\" parameter.</p>"},{"location":"Managed%20Azure%20AD%20B2C/g1-TEST-User-Journeys/#localization","title":"Localization","text":"<p>English language is default, multi-language support is not configured.</p> <p>Localization is configured in the execution policy files, and not represented by claims emitted in issued tokens.</p> <p>Multi-language can be configured in the execution policy file for the User Journey. Localization, meaning supported languages, is decided by configuration policy parameter SupportedLanguages.</p>"},{"location":"Managed%20Azure%20AD%20B2C/g1-TEST-User-Journeys/#user-journey-signupsignin","title":"User Journey - signupsignin","text":"<p>Policy file b2c_1a_v1_signupsignin triggers the primary User Journey, signupsignin.</p> <p>When triggered the signupsignin User Journey directs the user to a branded landing page. On the page the user has two options: sign in with email or password reset.</p> <p>There are two themes available through the custom branding feature, Slate Gray and Ocean Blue. Schema content definition configuration says which is applied to the User Journeys, which includes custom html, css and javascript files that shape the B2C pages.</p> <p>Once the user provides a matching username, the Identity Platform issues a token, which is returned to the application, along with the user which is now signed in.</p>"},{"location":"Managed%20Azure%20AD%20B2C/g2-TEST-Custom-policy-files/","title":"TEST - tenant.onmicrosoft.com - custom policy files","text":""},{"location":"Managed%20Azure%20AD%20B2C/g2-TEST-Custom-policy-files/#table-of-contents","title":"Table of contents","text":"<ul> <li>TEST - tenant.onmicrosoft.com - custom policy files</li> <li>Table of contents</li> <li>Introduction</li> <li>v1 policies</li> <li>v2 policies?</li> <li>Foundational policy files</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/g2-TEST-Custom-policy-files/#introduction","title":"Introduction","text":"<p>The Identity Experience Framework uses custom policies, which are very flexible and configurable building blocks. Current User Journeys were designed, developed and implemented with custom policies and they are the foundation of the Identity platform.</p> <p>All User Journeys have been configured for tenant-wide Single Sign-On support.</p> <p>TIP!</p> <p>All implementations use the custom domain functionality.</p> <p>When using custom domain, {tenantName}.b2clogin.com, in the examples, can be replaced with the domain name. Both domains are active and functioning, but use one at a time as Single Sign-On does not work across different domains.</p>"},{"location":"Managed%20Azure%20AD%20B2C/g2-TEST-Custom-policy-files/#v1-policies","title":"v1 policies","text":"<p>Policies in the v1 file set are the ones recommended to use for application integration.</p> Policy file User Journey Description Metadata endpoint User Journey test link Custom domain b2c_1a_v1_signupsignin Sign in The primary (default) User Journey, sign in with email and password reset https://custom.domain.com/tenantname.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=b2c_1a_v1_signupsignin https://tenantname.b2clogin.com/tenantname.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=b2c_1a_v1_signupsignin Sign In custom.domain.com tenantname.b2clogin.com - - - - - -"},{"location":"Managed%20Azure%20AD%20B2C/g2-TEST-Custom-policy-files/#v2-policies","title":"v2 policies?","text":"<p>Policies deployed through Managed B2C pipelines.</p> Policy file User Journey Description Metadata endpoint User Journey test link Custom domain <p>|             |              |             |                   |                        |                       |</p>"},{"location":"Managed%20Azure%20AD%20B2C/g2-TEST-Custom-policy-files/#foundational-policy-files","title":"Foundational policy files","text":"Policy file Description b2c_1a_v1_base Trust Framework Policy base containing all building blocks and definitions necessary for the User Journeys b2c_1a_v1_base_extensions Trust Framework Policy base extensions holding all the User Journeys"},{"location":"Managed%20Azure%20AD%20B2C/h1-PROD-User-Journeys/","title":"PROD - tenant.onmicrosoft.com - user journeys","text":""},{"location":"Managed%20Azure%20AD%20B2C/h1-PROD-User-Journeys/#table-of-contents","title":"Table of contents","text":"<ul> <li>PROD - tenant.onmicrosoft.com - user journeys</li> <li>Table of contents</li> <li>Introduction</li> <li>Execution policies (User Journeys)</li> <li>Single Sign-On</li> <li>Localization</li> <li>User Journey - signupsignin</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/h1-PROD-User-Journeys/#introduction","title":"Introduction","text":"<p>User Journey is the term used to define the flow that users go through when signing in. Through the Identity Experience Framework we craft User Journeys using custom policies.</p> <p>When authentication is required, a redirect to the Identity platform happens and a User Journey is triggered.</p> <p>User Journeys are flexible and can be customized to interact with APIs, they can be configured to perform progressive profiling, require the user to sign in using multi-factor authentication and much more, with few limitations.</p> <p>User Journeys does not have to be advanced, nor complex, and best practice is to keep them as simple as possible, while keeping the user experience in mind.</p> <p>The Fortytwo Managed B2C offering leverages custom policies as the building blocks for our User Journeys.  </p> <p>When naming a User Journey it is good practice to use descriptive names, taking into consideration the flow, and potentially also language support.</p>"},{"location":"Managed%20Azure%20AD%20B2C/h1-PROD-User-Journeys/#execution-policies-user-journeys","title":"Execution policies (User Journeys)","text":"<p>Policies commonly used by applications:</p> <ul> <li>v1</li> <li>b2c_1a_v1_signupsignin</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/h1-PROD-User-Journeys/#single-sign-on","title":"Single Sign-On","text":"<p>User Journeys can be configured for Single Sign-On support using the Scope=\"Tenant\" parameter.</p>"},{"location":"Managed%20Azure%20AD%20B2C/h1-PROD-User-Journeys/#localization","title":"Localization","text":"<p>English language is default, multi-language support is not configured.</p> <p>Localization is configured in the execution policy files, and not represented by claims emitted in issued tokens.</p> <p>Multi-language can be configured in the execution policy file for the User Journey. Localization, meaning supported languages, is decided by configuration policy parameter SupportedLanguages.</p>"},{"location":"Managed%20Azure%20AD%20B2C/h1-PROD-User-Journeys/#user-journey-signupsignin","title":"User Journey - signupsignin","text":"<p>Policy file b2c_1a_v1_signupsignin triggers the primary User Journey, signupsignin.</p> <p>When triggered the signupsignin User Journey directs the user to a branded landing page. On the page the user has two options: sign in with email or password reset.</p> <p>There are two themes available through the custom branding feature, Slate Gray and Ocean Blue. Schema content definition configuration says which is applied to the User Journeys, which includes custom html, css and javascript files that shape the B2C pages.</p> <p>Once the user provides a matching username, the Identity Platform issues a token, which is returned to the application, along with the user which is now signed in.</p>"},{"location":"Managed%20Azure%20AD%20B2C/h2-PROD-Custom-policy-files/","title":"PROD - tenantname.onmicrosoft.com - custom policy files","text":""},{"location":"Managed%20Azure%20AD%20B2C/h2-PROD-Custom-policy-files/#table-of-contents","title":"Table of contents","text":"<ul> <li>PROD - tenantname.onmicrosoft.com - custom policy files</li> <li>Table of contents</li> <li>Introduction</li> <li>v1 policies</li> <li>Foundational policy files</li> </ul>"},{"location":"Managed%20Azure%20AD%20B2C/h2-PROD-Custom-policy-files/#introduction","title":"Introduction","text":"<p>The Identity Experience Framework uses custom policies, which are very flexible and configurable building blocks. Current User Journeys were designed, developed and implemented with custom policies and they are the foundation of the Identity platform.</p> <p>All User Journeys have been configured for tenant-wide Single Sign-On support.</p> <p>TIP!</p> <p>All implementations use the custom domain functionality.</p> <p>When using custom domain, {tenantName}.b2clogin.com, in the examples, can be replaced with the domain name. Both domains are active and functioning, but use one at a time as Single Sign-On does not work across different domains.</p>"},{"location":"Managed%20Azure%20AD%20B2C/h2-PROD-Custom-policy-files/#v1-policies","title":"v1 policies","text":"<p>Ony policies in the v1 file set are available in production.</p> Policy file User Journey Description Metadata endpoint User Journey test link Custom domain b2c_1a_v1_signupsignin Sign in The primary (default) User Journey, sign in with email and password reset https://custom.domain.com/tenantname.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=b2c_1a_v1_signupsignin https://tenantname.b2clogin.com/tenantname.onmicrosoft.com/v2.0/.well-known/openid-configuration?p=b2c_1a_v1_signupsignin Sign In custom.domain.com tenantname.b2clogin.com - - - - - -"},{"location":"Managed%20Azure%20AD%20B2C/h2-PROD-Custom-policy-files/#foundational-policy-files","title":"Foundational policy files","text":"Policy file Description b2c_1a_v1_base Trust Framework Policy base containing all building blocks and definitions necessary for the User Journeys b2c_1a_v1_base_extensions Trust Framework Policy base extensions holding all the User Journeys"},{"location":"Security%20Posture%20Portal/","title":"Fortytwo Fortify portal for Microsoft 365","text":""},{"location":"Security%20Posture%20Portal/#intro","title":"Intro","text":"<p>More commercial information can be read here</p> <p>A solution that monitors your Microsoft 365 configuration and compares it to best practices.</p> <p>In an ever-evolving landscape of threats, making sure your Microsoft 365 environment is as secure as possible while also maintaining usability is difficult.</p> <p>Introducing Fortytwo Fortify Portal for Microsoft 365, a solution that continuously monitors your Microsoft 365 configuration and compares it to best practices.</p> <p>All your Microsoft 365 configuration with possible improvements will be reported with an explanation of why we check for this, an explanation on the consequence of following that best practice is, and a detailed guide on how to configure your environment in a best practice manner.</p>"},{"location":"Security%20Posture%20Portal/#what-does-this-solution-solve","title":"What does this solution solve?","text":"<p>We see a lot of customers that are managing their own Microsoft 365 tenant \u2013 which is great. However, many of these customers only have knowledge about 20 to 40 percent of Microsoft 365, while the rest is running happily on default settings. This might have been good enough up until now, but with threat actors setting their eyes on Microsoft 365, a 100% coverage is necessary.</p>"},{"location":"Security%20Posture%20Portal/#azure-marketplace","title":"Azure Marketplace","text":"<p>The portal is available through Microsoft Azure Marketplace</p> <p></p>"},{"location":"Security%20Posture%20Portal/#public-roadmap","title":"Public Roadmap","text":"<p>Our portal is under continuous development and we regularly update our Public Roadmap, which can be found here. If you have any suggestions, ideas, or feedback, we would greatly appreciate hearing from you. Please reach out to us at Support email.</p>"},{"location":"Security%20Posture%20Portal/01_gettingstarted/","title":"Getting started","text":"<p>This is an detailed description of how to setup our Fortify Portal from Azure Marketplace. The steps are pritty much easy to understand but we have documented every step here in this guide.</p> <p>Note</p> <p>From April 2024 the name of the portal changed from \"Security Posture Portal\" to \"Fortify Portal\". It\u00b4s the same product.</p>"},{"location":"Security%20Posture%20Portal/01_gettingstarted/#setup-through-azure-marketplace","title":"Setup through Azure Marketplace","text":""},{"location":"Security%20Posture%20Portal/01_gettingstarted/#install-the-app-from-azure-marketplace","title":"Install the app from Azure marketplace","text":"<ol> <li>Go to our Azure Marketplace Product page</li> <li>Click <code>Get it now</code></li> </ol> <p> 3. Fill out contact details and click <code>Continue</code></p> <p> 4. You are now taken to the Azure portal. Choose <code>Standard</code> on the Plan dropdown and click <code>Subscribe</code></p> <p> 5. Now take the appropiate actions on the following:</p>"},{"location":"Security%20Posture%20Portal/01_gettingstarted/#configure-your-azure-environment","title":"Configure your Azure environment","text":"<p>Note</p> <p>To be able to add the Fortify Portal to your tenant you need at least <code>Contributor</code> access </p> <ol> <li>Configure your tenant environment.<ul> <li>Choose which Azure subscription you would like to add the app to.</li> <li>Choose which Resource group the app should live in. Choose \"New\" if you dont have any.</li> <li>Give the app an appropiate name <code>Fortytwo Fortify Portal</code></li> <li>Choose <code>On</code> on Recurring billing.</li> </ul> </li> </ol> <p> 2. When you are ready click <code>Review + subscribe</code> to start the setup of the portal.</p> <p> 3. The setup will take a couple of minutes. When its done you will be asked to <code>Go to the publisher site to finish setup</code>. You are now being redirected to our onboarding page</p>"},{"location":"Security%20Posture%20Portal/01_gettingstarted/#run-through-our-onboarding-wizard","title":"Run through our onboarding wizard","text":"<p>After you have finished in the Azure Portal you are redirected to https://portal.fortytwo.io/onboarding-msp - Follow the onboarding wizard to connect your tenants data.</p> <p>Note</p> <p>If you have any issues contact us on support@fortytwo.io</p>"},{"location":"Security%20Posture%20Portal/01_gettingstarted/#setup-through-stripevisa-card","title":"Setup through Stripe/Visa card","text":"<p>Navigate directly to https://portal.fortytwo.io and select \"Try it for free\". Signup with your Corporate email account and follow the wizard to buy an subscription.</p>"},{"location":"Security%20Posture%20Portal/02_faq/","title":"FAQ","text":"<p>FAQ is updated and can be read here</p>"},{"location":"Security%20Posture%20Portal/03_cancelsubscription/","title":"Cancel SaaS subscription","text":"<p>Note</p> <p>From April 2024 the name of the portal changed from \"Security Posture Portal\" to \"Fortify Portal\". It\u00b4s the same product.</p> <p>To cancel your subscription of the portal is very easy and are done through your Azure portal. Follow the steps below to cancel at any point.</p> <ol> <li>Go to the Azure portal.</li> <li>In the global search box at the top of the page, enter SaaS and then under Services, select SaaS. Shortcut here</li> </ol> <p> 3. Find the SaaS offering named <code>Security Posture for Microsoft 365</code> and click it. 4. Choose \"Cancel Subscription\" on the SaaS app and follow the screen instructions.</p> <p></p> <p>Remember to delete apps</p> <p>Both Enterprise apps, Fortytwo Portal and Fortytwo - Security Posture Polic Engine are not deleted automatically and needs to be manually deleted from your tenant. Read how to delete and enterprise application here</p> <p>Note</p> <p>If you have any issues contact us on assistance@fortytwo.io .</p>"},{"location":"Security%20Posture%20Portal/03b_changesubscription/","title":"Change the SaaS subscription","text":"<p>Note</p> <p>From April 2024 the name of the portal changed from \"Security Posture Portal\" to \"Fortify Portal\". It\u00b4s the same product.</p>"},{"location":"Security%20Posture%20Portal/03b_changesubscription/#change-the-billing-subscription","title":"Change the billing subscription","text":"<p>To change the billing subscription of the Portal is very easy and are done through your Azure portal. Follow the steps below to change at any point.</p> <ol> <li>Go to the Azure portal.</li> <li>In the global search box at the top of the page, enter SaaS and then under Services, select SaaS. Shortcut here </li> <li>Find the SaaS offering named <code>Security Posture for Microsoft 365</code> and click it.</li> <li>Choose \"Change Azure Subscription\" on the SaaS app and follow the screen instructions.</li> </ol> <p></p>"},{"location":"Security%20Posture%20Portal/03b_changesubscription/#change-the-billing-recurrence","title":"Change the billing recurrence","text":"<p>To change the billing recurrence of the Portal.</p> <p>Choose \"Edit recurring billing\" on the SaaS app and follow the screen instructions.</p> <p></p>"},{"location":"Security%20Posture%20Portal/03b_changesubscription/#references","title":"References","text":"<ul> <li>SaaS subscription lifecycle management</li> </ul> <p>Note</p> <p>If you have any issues contact us on support@fortytwo.io</p>"},{"location":"Security%20Posture%20Portal/04_permissions/","title":"Manage access and permissions to the portal","text":"<p>To manage access to the portal, we utilize app role assignments in Entra ID. By default, if you have no roles assigned, the user will be presented with demo data in the portal.</p> <ol> <li> <p>Go to the Enterprise applications blade in the Entra portal.</p> </li> <li> <p>Find the application named Fortytwo Fortify Portal.</p> </li> <li> <p>In the application pane, find Users and groups and click + Add user/group</p> </li> <li> <p>Select the user or group of users you want to assign access to, and select the role you want to assign. The following roles exists.</p> </li> </ol> Role Description Security Posture Operator Provides access to the security posture feature in the portal, with the ability to accept risks Security Posture Admin Currently same as Security Posture Operator, but in the future, more administrative tasks will be available to this role. Give youself this role. Security Posture Reader Provides a read only access to the security posture feature in the portal"},{"location":"Security%20Posture%20Portal/05_enterpriseapps/","title":"Enterprise applications installed in your tenant","text":"<p>As part of onboarding to use our portal Fortytwo install two Enterprise applications in your tenant. The following page document how and what they are used for.</p>"},{"location":"Security%20Posture%20Portal/05_enterpriseapps/#fortytwo-portal-app","title":"Fortytwo Portal app","text":"<p>To enable seamless single sign-on access to the portal for you and fellow users within your organization, the prerequisite is this application. This dedicated app serves as the cornerstone of authentication for the portal and facilitates all role assignments.</p> <p>It's important to note that this application itself does not possess any access privileges within your tenant.</p> <p>The following roles are available in the app.</p> Role Description Security Posture Operator Provides access to the security posture feature in the portal, with the ability to accept risks Security Posture Admin Currently same as Security Posture Operator, but in the future, more administrative tasks will be available to this role. Give youself this role. Security Posture Reader Provides a read only access to the security posture feature in the portal"},{"location":"Security%20Posture%20Portal/05_enterpriseapps/#fortytwo-security-posture-polic-engine-app","title":"Fortytwo - Security Posture Polic Engine app","text":"<p>This is the primary application responsible for retrieving and processing all configuration data. It interacts with the following systems through the Microsoft Graph API, utilizing READ permissions.</p> <p>NB</p> <p>The application do not have any write or any other permissions able to alter and/or do anything in your tenant.</p> <p>The application requires a large set of read consents for reading from the Microsoft Graph, and Global Reader for accesing Microsoft Teams and Microsoft Exchange.</p>"},{"location":"Security%20Posture%20Portal/05_enterpriseapps/#hide-app-from-users","title":"Hide app from users","text":"<p>It could be a good idea to hide this app from users as this is not used by any user. </p>"},{"location":"managed-identity-services/","title":"Managed Identity Services","text":"<p>Welcome to Fortytwo Managed Identity Services. Here you will find documentation material related to our identity services.</p>"},{"location":"managed-identity-services/consent-landing-pages/group-provisioning/","title":"Thank you","text":"<p>Thank you for consenting to our access.</p>"},{"location":"managed-identity-services/consent-landing-pages/hr-provisioning/","title":"Thank you","text":"<p>Thank you for consenting to our access.</p>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/","title":"Entra ID Advanced Criteria Groups","text":"<p>Note</p> <p>Entra ID dynamic membership rules for groups are awesome, but let's face it, they are simply way too limited. That's why we built a simple open source solution that enables you to build as advanced scenarios as you'd like, while maintaining the lowest complexity possible, and the least amount of code possible.</p> <p>Our solution runs as an Azure Application in your Azure subscription, that contains an Automation Account and an identity that enables you to define your criteria groups in a simple manner. We do not have any access to your environment.</p> <p>This magic is all powered by our open source PowerShell module, that you can also use on your own.</p> <p>Let's have a look at why you would want to use this solution:</p> You want to have a group with Entra ID? This solution Active users \u2705 \u2705 Users with company equals Contoso \u2705 \u2705 Users member of another group \u2705 \u2705 Users with an attribute that ends with a value \u2705 Users with an attribute that matches a regular expression \u2705 Users member of another group, and having company equals Contoso \u2705 Users member of three groups at the same time \u2705 Users member of another group, but not member of a second group \u2705 Users that has not signed in the last 90 days \u2705"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/automation-account/","title":"Use module with an Automation Account","text":"<p>By using our dynamic group module with an Azure Automation Account, you can easily automate and schedule advanced group memberships in a manner that is currently unsupported by the built in dynamic/criteria based groups.</p>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/automation-account/#prerequisites","title":"Prerequisites:","text":"<ul> <li>A working Azure Subscription</li> <li>Account with Global Administrator permissions</li> <li>Group(s) that you want the module to administer</li> <li>(Optional) API endpoints for actions to be taken when adding/removing users from groups</li> </ul>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/automation-account/#configuration","title":"Configuration","text":""},{"location":"managed-identity-services/entraid-advanced-criteria-groups/automation-account/#11-create-automation-account-and-import-module","title":"1.1 Create Automation Account and import module","text":"<ol> <li>Create an Automation Account from the Azure Marketplace and deploy it to your designated subscription/resource group.</li> <li>Go to Shared Resources -&gt; Modules -&gt; Add module </li> <li>Do the following: Select \"Browse from gallery\" Click the link named \"Click here to browse from gallery\", search for \"AdvancedCriteriaBasedGroups\", and click Select. Use Runtime version 7.2. Click on \"Import\" </li> </ol> <p>The module should now be loaded in your Automation Account.</p>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/automation-account/#12-if-not-using-marketplace-offer-create-a-user-assigned-managed-identity","title":"1.2 (If not using Marketplace offer?) Create a User Assigned Managed Identity","text":"<p>\u2757\ufe0f IMPORTANT: This step requires an account with Global Administrator </p> <p>If you are configuring this yourself, you need to create a User Assigned Managed Identity that has the permissions required for the module to run. The permissions are the following: - Owner permissions on groups that the module will administer - User.Read.All OR User.ReadWrite.All - (Optional, depending on use) Group.ReadWrite.All</p>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/automation-account/#121-create-a-user-assigned-managed-identity-and-assign-it","title":"1.2.1 Create a User Assigned Managed Identity and assign it:","text":"<ol> <li>Find User Assigned Managed Identity on the Azure Marketplace.</li> <li>Create it in the same Subscription/ResourceGroup where the Automation Account is located <code>\ud83d\udcdd</code> Keep the Object ID of the Identity, you will need it when setting permissions </li> <li>Assign the Identity to the Automation Account </li> <li>Assign the Identity as owner on the groups that it needs access to</li> </ol>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/automation-account/#122-assign-microsoft-graph-permissions-to-user-assigned-managed-identity","title":"1.2.2 Assign Microsoft Graph permissions to User Assigned Managed Identity","text":"<p>\u2757\ufe0f IMPORTANT: This step requires an account with Global Administrator This step also requires that you do some steps with Powershell on your machine or in the Azure CLI.</p> <ol> <li>Open Powershell as an Administrator</li> <li>Copy the following code-snippet to Visual Studio Code (recommended), notepad or your favourite word processor, and edit the code to match your environment. <pre><code># Replace the object ID below with the one you created earlier\n$managedIdentityObjectId = \"XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\"\n\nInstall-Module -Name AdvancedCriteriaBasedGroups\nImport-Module AdvancedCriteriaBasedGroups -Force\n\nConnect-MgGraph -Environment Global -Scopes AppRoleAssignment.ReadWrite.All, Application.Read.All\n\n\n# Edit -GraphPermission to \"User.ReadWrite.All\" if you require the automation to have write permissions on user objects.\n# You can add more permissions if you wish by comma-separating the permissions.\n#Example: -GraphPermission \"User.Read.All\", \"Group.Read.All\n\nNew-MicrosoftGraphServicePrincipalApplicationPermission -ObjectId $managedIdentityObjectId -GraphPermission \"User.Read.All\"\n</code></pre></li> <li>Run the snippet from VS Code/paste the edited code into Powershell and run it.</li> </ol>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/automation-account/#13-create-a-runbook","title":"1.3 Create a runbook","text":"<ol> <li>Go to Process Automation -&gt; Runbooks -&gt; Create a runbook </li> <li>Set the following Basic information: Name: Pick a suitable name for your action Runbook type: Powershell Runtime version: 7.2 (or whichever version is recommended) Description: A fitting description for your run (optional, but recommended) </li> <li>Add tags if your environment requires it, and click Create</li> </ol>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/examples/","title":"Examples","text":""},{"location":"managed-identity-services/entraid-advanced-criteria-groups/examples/#users-with-an-attribute-that-ends-with-a-value","title":"Users with an attribute that ends with a value","text":"<pre><code># Connect to the Microsoft Graph using Automation Account user assigned identity\nConnect-AdvancedCriteriaBasedGroups\n\n# Start working on a group\nStart-AdvancedCriteriaBasedGroup -ObjectId \"404c71ff-bb33-4434-85e1-2e6c9863d33c\"\n\n# Add uers with userPrincipalname ending with @test.com\nAdd-AdvancedCriteriaBasedGroupMembers -Criteria { $_.UserPrincipalName -like \"*@test.com\"}\n\n# Add this point we have told the module which users should be a member of the group, now we are ready to actually complete the operations in Entra ID.\nComplete-AdvancedCriteriaBasedGroup\n</code></pre>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/examples/#users-with-an-attribute-that-matches-a-regular-expression","title":"Users with an attribute that matches a regular expression","text":"<pre><code># Connect to the Microsoft Graph using Automation Account user assigned identity\nConnect-AdvancedCriteriaBasedGroups\n\n# Start working on a group\nStart-AdvancedCriteriaBasedGroup -ObjectId \"404c71ff-bb33-4434-85e1-2e6c9863d33c\"\n\n# Add uers with jobTitle matching a regular expression\nAdd-AdvancedCriteriaBasedGroupMembers -Criteria { $_.jobTitle -match '^(lead|principal) engineer$'}\n\n# Let's also add users with a few other jobTitle values\nAdd-AdvancedCriteriaBasedGroupMembers -Criteria { $_.jobTitle -in 'project manager', 'key account manager'}\n\n# Add this point we have told the module which users should be a member of the group, now we are ready to actually complete the operations in Entra ID.\nComplete-AdvancedCriteriaBasedGroup -Verbose\n</code></pre>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/examples/#users-member-of-another-group-and-having-company-equals-contoso","title":"Users member of another group, and having company equals Contoso","text":"<pre><code># Connect to the Microsoft Graph using Automation Account user assigned identity\nConnect-AdvancedCriteriaBasedGroups\n\n# Start working on a group\nStart-AdvancedCriteriaBasedGroup -ObjectId \"404c71ff-bb33-4434-85e1-2e6c9863d33c\" -Verbose\n\n# Get all members of another group, but only users having usageLocation 'NO', and add as members of the group we are working on\nGet-AdvancedCriteriaBasedGroupUsers -MembersOfGroupObjectId \"20a2a612-fbd5-4fd6-a94a-1edefcdf48a9\" | \nWhere-Object usageLocation -in \"NO\" |\nAdd-AdvancedCriteriaBasedGroupMember -Debug\n\n# Add this point we have told the module which users should be a member of the group, now we are ready to actually complete the operations in Entra ID.\nComplete-AdvancedCriteriaBasedGroup\n</code></pre>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/examples/#users-member-of-three-groups-at-the-same-time","title":"Users member of three groups at the same time","text":"<p>Todo</p>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/examples/#users-member-of-another-group-but-not-member-of-a-second-group","title":"Users member of another group, but not member of a second group","text":"<pre><code># Connect to the Microsoft Graph using Automation Account user assigned identity, but we can actually disable the user cache, as we have a special cmdlet for this member of one group but not another group scenario - which is way faster. :)\nConnect-AdvancedCriteriaBasedGroups -DoNotCacheAllUsers\n\n# Start working on a group\nStart-AdvancedCriteriaBasedGroup -ObjectId \"404c71ff-bb33-4434-85e1-2e6c9863d33c\" -Verbose\n\n# Writes members of group A22222222-2222-2222-2222-222222222222 and 33333333-3333-3333-3333-333333333333 to group 11111111-1111-11111-1111-111111111111, but only if they are not member of group 44444444-4444-4444-4444-444444444444\nWrite-AdvancedCriteriaBasedGroupMemberOfButNotMemberOfGroup `\n    -DestinationGroup \"11111111-1111-1111-1111-111111111111\" `\n    -MemberOfGroups \"22222222-2222-2222-2222-222222222222\", \"33333333-3333-3333-3333-333333333333\" `\n    -ButNotMemberOfGroups \"44444444-4444-4444-4444-444444444444\"\n</code></pre>"},{"location":"managed-identity-services/entraid-advanced-criteria-groups/examples/#users-that-has-not-signed-in-the-last-90-days","title":"Users that has not signed in the last 90 days","text":"<pre><code># Connect to the Microsoft Graph using Automation Account user assigned identity. In order to get the signInActivity property, we need to tell the module to fetch it into the cache. This requires the auditlog.read.all permission.\nConnect-AdvancedCriteriaBasedGroups -Properties signInActivity\n\n# Start working on a group\nStart-AdvancedCriteriaBasedGroup -ObjectId \"404c71ff-bb33-4434-85e1-2e6c9863d33c\"\n\n# Add users that has not successfully signed in within the last 90 days\nAdd-AdvancedCriteriaBasedGroupMembers -Criteria { $_.signInActivity.lastSuccessfulSignInDateTime -lt (Get-Date).AddDays(-90)}\n\n# Add this point we have told the module which users should be a member of the group, now we are ready to actually complete the operations in Entra ID. Here we actually want to trigger a logicapp through a url when users are added to this group:\nComplete-AdvancedCriteriaBasedGroup `\n    -TransitionInUrls \"https://prod-253.westeurope.logic.azure.com:443/workflows/6826bb7ba2d24e3bb90b75469ab4012f/triggers.....\" \n</code></pre>"},{"location":"managed-identity-services/hr-provisioning/onboarding/","title":"Onboarding","text":"<p>Thank you for your interest in our HR Provisioning service. In order to onboard to the service, the following steps are required:</p> # Who? What? 1 Customer Consent to Fortytwo app for HR Provisioning 2 Customer If using Active Directory, Install the Microsoft Entra Provisioning Agent 3 Customer Create Provisioning API instance 4 Fortytwo Read HR data and write to Entra ID Inbound Provisioning 5 Fortytwo Match user accounts and create report of creates and updates before go-live 6 Fortytwo Go-live of provisioning Ongoing Fortytwo Operations"},{"location":"managed-identity-services/hr-provisioning/onboarding/#step-1-consent-to-fortytwo-app-for-hr-provisioning","title":"Step 1 - Consent to Fortytwo app for HR Provisioning","text":"<p>Navigate to this url and sign in as a Global Administrator in order to consent to Fortytwo accessing your tenant. We need the following permissions:</p> Scope Why? AuditLog.Read.All Used to query the provisioning log for provisioning status. There is no less privileged graph scope for this available. SynchronizationData-User.Upload Required in order to send data to the inbound provisioning API. User.Read.All Required for user joining and determining the consequence of enabling synchronization."},{"location":"managed-identity-services/hr-provisioning/onboarding/#step-2-if-using-active-directory-install-the-microsoft-entra-provisioning-agent","title":"Step 2 - If using Active Directory, Install the Microsoft Entra Provisioning Agent","text":"<p>Follow the Microsoft documentation for installing the Microsoft Entra Provisioning Agent.</p>"},{"location":"managed-identity-services/hr-provisioning/onboarding/#step-3-create-provisioning-api-instance","title":"Step 3 - Create Provisioning API instance","text":""},{"location":"managed-identity-services/hr-provisioning/onboarding/#provisioning-to-active-directory","title":"Provisioning to Active Directory","text":""},{"location":"managed-identity-services/hr-provisioning/onboarding/#provisioning-to-entra-id-cloud-only","title":"Provisioning to Entra ID (Cloud only)","text":"<ul> <li>Sign into the Entra Portal as a Global Administrator</li> <li>Under Enterprise applications click New application</li> </ul> <ul> <li>Search for API-Driven Provisioning and select the one named API-driven provisioning to Microsoft Entra ID</li> </ul> <ul> <li>Give the application a logical name, such as Contoso HR Inbound Provisioning and click Create</li> </ul> <ul> <li>When the application has been created, go to Provisioning in the left menu and click Get started</li> </ul> <ul> <li>Switch Provisioning mode to Automatic and click Save</li> </ul> <ul> <li>Go back to the Overview, still under Provisioning, copy the Provisioning API Endpoint and send to your Fortytwo contact.</li> </ul>"},{"location":"managed-identity-services/hr-provisioning/restarting-sync/","title":"Fully restarting sync","text":"<p>The Entra ID Inbound Provisioning API maintains a \"sticky join\", meaning it will statefully remember which Active Directory and Entra ID object has successfully been synced with a SCIM object.</p> <p>This also means that a wrongly joined user can continue to be wrongly joined, even though an attribute is switched over to another user account.</p> <p>The \"Restart provisioning\" button in the Entra ID portal does not clear this sticky join. Instead, the below steps must be done:</p> <ul> <li>Sign into the Entra ID tenant and find the Inbound Provisioning API</li> <li>Open a PowerShell</li> <li>Extract your Graph access token using developer mode and set the $accesstoken variable in PowerShell:</li> </ul> <p></p> <pre><code>$accesstoken = \"ey....==\"\n</code></pre> <ul> <li>Find the provisioning API endpoint and copy it into the $api variable</li> </ul> <p></p> <pre><code>$api = \"https://..../bulkUpload\"\n</code></pre> <ul> <li> <p>Run the below PowerShell to restart sync fully:</p> <pre><code>Invoke-RestMethod -Uri ($uri -replace \"/bulkUpload\",\"/restart\") -Method Post -Body '{\"criteria\":{\"resetScope\":\"Full\"}}' -ContentType \"application/json\" -Headers @{Authorization = \"Bearer $accesstoken\"}\n</code></pre> </li> <li> <p>The API should now show the following:</p> </li> </ul> <p></p> <p>All joins will now be re-evaluated on the next full sync cycle from the Fortytwo HR provisioning service, which will happen each night.</p>"},{"location":"managed-identity-services/hr-provisioning/service-description/","title":"Service description","text":"<p>At Fortytwo, we understand the critical importance of maintaining seamless integration between your Human Resources (HR) system and your identity platform with Active Directory and Entra ID, for efficient user account management. Our service, Fortytwo HR Provisioning, is designed to streamline and automate the synchronization of HR data with the identity platform through the Entra ID Inbound Provisioning API. This ensures that your user accounts remain up-to-date and aligned with HR processes, facilitating a smooth joiner-mover-leaver lifecycle process.</p> <p></p>"},{"location":"managed-identity-services/hr-provisioning/service-description/#key-features","title":"Key features","text":"<ul> <li>Data sync: Fortytwo HR Provisioning ensures synchronization of employee data from your HR system to Active Directory and Entra ID, reducing manual efforts and minimizing the risk of discrepancies.</li> <li>Seamless integration: Our service seamlessly integrates with Entra ID, establishing a robust connection that guarantees the accuracy and consistency of user account information.</li> <li>Automated Joiner-Mover-Leaver process: Fortytwo HR Provisioning automates the entire joiner-mover-leaver process, linking HR events directly to the corresponding user accounts in Entra ID. This results in efficient onboarding, relocation, and offboarding procedures. The service can also be used in conjunction with Entra ID Lifecycle Workflows, in order to customize the onboarding workflow.</li> <li>Customizable mapping: Tailor the mapping of HR data fields to Active Directory and Entra ID attributes based on your organization's unique requirements. This flexibility ensures that the service adapts to your specific HR data model.</li> <li>Audit trail and reporting: Gain insights into the provisioning activities with a comprehensive audit trail. Detailed reports provide transparency and accountability, allowing you to track changes and ensure compliance.</li> <li>Scalability and reliability: Fortytwo HR Provisioning is designed to scale with your organization's growth. The service is built on a reliable infrastructure, ensuring continuous operation and data integrity.</li> </ul>"},{"location":"managed-identity-services/hr-provisioning/service-description/#benefits","title":"Benefits","text":"<ul> <li>Utilize Entra ID to the max: Ensure that you can utilize the full potential of your already purchased licenses.</li> <li>Efficiency: Eliminate manual data entry and reduce the risk of errors by automating the provisioning process.</li> <li>Reduced IT cost: Eliminate manual processes for IT.</li> <li>Compliance: Ensure compliance with HR policies and regulations through accurate and timely updates to user accounts in Entra ID.</li> <li>Enhanced security: Fortytwo HR Provisioning prioritizes data security, employing industry-standard protocols to safeguard sensitive HR information during transmission and storage.</li> <li>User experience: Employees experience minimal disruption as their Entra ID accounts seamlessly reflect HR-related changes, fostering a positive user experience.</li> </ul> <p>Fortytwo HR Provisioning empowers your organization with a reliable and efficient solution for maintaining synchronization between your HR system and Entra ID, enabling you to focus on strategic HR initiatives while ensuring data accuracy and compliance. Experience the next level of HR and identity management integration with Fortytwo.</p>"},{"location":"managed-identity-services/hr-provisioning/service-description/#responsibility-matrix","title":"Responsibility matrix","text":"Task/Activity Responsible Service Implementation Configure service settings Fortytwo Establish HR system connection Fortytwo Define attribute mapping Shared Microsoft user licensing Customer Ongoing Operations and Support HR data quality Customer Address data discrepancies Customer Monitor data synchronization Fortytwo Address service issues Fortytwo Address API changes Fortytwo Configuration Changes Update data mapping Fortytwo Adjust service settings Fortytwo Communication Provide service updates Fortytwo Share best practices Fortytwo Report issues Customer Inform end users about data processing Customer"},{"location":"managed-identity-services/hr-provisioning/service-description/#pricing-and-information","title":"Pricing and information","text":"<ul> <li>500 USD per month, includes 300 users</li> <li> <p>0.30 USD per additional user</p> </li> <li> <p>Billing can be done through Azure Marketplace or directly.</p> </li> <li>More info here</li> </ul>"},{"location":"managed-identity-services/hr-provisioning/hr-systems/dottie/","title":"Dottie","text":""},{"location":"managed-identity-services/hr-provisioning/hr-systems/dottie/#required-hr-configuration","title":"Required HR configuration","text":"<p>In order for Fortytwo to connect to the HR system, we require a Client ID and Client secret configured under API access, to access this API. Please provide this to your Fortytwo contact during the initial phase of implementation.</p>"},{"location":"managed-identity-services/hr-provisioning/hr-systems/dottie/#how-to-create-client-id-and-secret-in-dottie","title":"How to create Client ID and Secret in Dottie","text":"<ul> <li>Go to Settings -&gt; Integrations on this url</li> <li>Click \"New API User\".</li> </ul> <ul> <li>Click \"Create new\".</li> <li>Take a note of \"Client ID\" and \"API Key\" and click \"Close\".</li> </ul> <ul> <li>Now, Edit the user you just created. (You might need to refresh the browser to see it)</li> </ul> <ul> <li>Add the role \"Toppleder/Top Leader\". and click \"Close\" and \"Close\".</li> </ul> <ul> <li>Done. Give the keys to your Fortytwo contact person.</li> </ul>"},{"location":"managed-identity-services/hr-provisioning/hr-systems/dottie/#schema-used-for-attribute-mapping","title":"Schema used for attribute mapping","text":"<p>The service sendes each employee as a standard SCIM representation to the Entra ID Inbound Provisioning API. The below is a full example of the payload we send, and can be used to define attribute mapping in the customer tenant:</p> <pre><code>{\n  \"displayName\": \"Alma Nakken\",\n  \"urn:ietf:params:scim:schemas:extension:enterprise:2.0:User\": {\n    \"department\": null,\n    \"manager\": {\n      \"value\": \"2\"\n    },\n    \"employeeNumber\": \"1\",\n    \"organization\": \"Company Inc\",\n    \"division\": \"HR\"\n  },\n  \"urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User\": {\n    \"enddate\": null,\n    \"jobtitleid\": 17,\n    \"orglevel0id\": \"197\",\n    \"orglevel0name\": \"Company Inc\",\n    \"orglevel1id\": \"187\",\n    \"orglevel1name\": \"HR\",\n    \"orglevel2id\": null,\n    \"orglevel2name\": null,\n    \"orglevel3id\": null,\n    \"orglevel3name\": null,\n    \"orglevel4id\": null,\n    \"orglevel4name\": null,\n    \"orglevelids\": [\n      \"197\",\n      \"187\"\n    ],\n    \"raw\": null,\n    \"ssn\": null,\n    \"startdate\": null\n  },\n  \"name\": {\n    \"familyName\": \"Nakken\",\n    \"givenName\": \"Alma\"\n  },\n  \"phoneNumbers\": [\n    {\n      \"type\": \"mobile\",\n      \"value\": \"+4799999999\"\n    }\n  ],\n  \"externalid\": \"1\",\n  \"active\": true,\n  \"schemas\": [\n    \"urn:ietf:params:scim:schemas:core:2.0:User\",\n    \"urn:ietf:params:scim:schemas:extension:enterprise:2.0:User\",\n    \"urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User\"\n  ],\n  \"title\": \"HR Consultant\",\n  \"addresses\": [\n    {\n      \"primary\": true,\n      \"type\": \"work\",\n      \"region\": \"Oslo\",\n      \"postalCode\": \"0862\",\n      \"locality\": \"Oslo\",\n      \"streetAddress\": \"Folke bernadottes vei 9A\",\n      \"country\": \"NOR\"\n    }\n  ]\n}\n</code></pre> SCIM attribute HR source object HR source attribute externalid Employee employeeNumber displayName Employee firstname + lastname title Employee, JobTitle jobTitleId used to look in JobTitle name.familyName Employee lastname name.givenName Employee firstName phoneNumbers[type eq \"mobile\"].value EmployeePhone phoneNumber of kind 1 phoneNumbers[type eq \"work\"].value EmployeePhone phoneNumber of kind 0 active Employee firstDayOfWork, lastDayOfWork urn:ietf:params:scim:schemas:extension:enterprise:2.0:User:employeeNumber Employee employeeNumber urn:ietf:params:scim:schemas:extension:enterprise:2.0:User:manager Employee employeeid of leaderId urn:ietf:params:scim:schemas:extension:enterprise:2.0:User:organization Employee, OrganizationUnit organizationUnitId used to get level 1 of org structure urn:ietf:params:scim:schemas:extension:enterprise:2.0:User:division Employee, OrganizationUnit organizationUnitId used to get level 2 of org structure urn:ietf:params:scim:schemas:extension:enterprise:2.0:User:department Employee, OrganizationUnit organizationUnitId used to get level 3 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User:startdate Employee firstDayOfWork urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User:enddate Employee lastDayOfWork urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User:ssn UserProfile nationalIdNumber urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User:jobtitleid Employee jobTitleId urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel0name Employee, OrganizationUnit organizationUnitId used to get level 1 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel1name Employee, OrganizationUnit organizationUnitId used to get level 2 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel2name Employee, OrganizationUnit organizationUnitId used to get level 3 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel3name Employee, OrganizationUnit organizationUnitId used to get level 4 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel4name Employee, OrganizationUnit organizationUnitId used to get level 5 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel0id Employee, OrganizationUnit organizationUnitId used to get level 1 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel1id Employee, OrganizationUnit organizationUnitId used to get level 2 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel2id Employee, OrganizationUnit organizationUnitId used to get level 3 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel3id Employee, OrganizationUnit organizationUnitId used to get level 4 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel4id Employee, OrganizationUnit organizationUnitId used to get level 5 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevelids Employee, OrganizationUnit organizationUnitId used to get all ids from the org structure"},{"location":"managed-identity-services/hr-provisioning/hr-systems/evolution-hr/","title":"Evolution HR","text":""},{"location":"managed-identity-services/hr-provisioning/hr-systems/evolution-hr/#required-hr-configuration","title":"Required HR configuration","text":"<p>In order for Fortytwo to connect to the HR system, we require a Client ID and Client secret configured under API access, to access the this API. Please provide this to your Fortytwo contact during the initial phase of implementation.</p>"},{"location":"managed-identity-services/hr-provisioning/hr-systems/evolution-hr/#schema-used-for-attribute-mapping","title":"Schema used for attribute mapping","text":"<p>The service sendes each employee as a standard SCIM representation to the Entra ID Inbound Provisioning API. The below is a full example of the payload we send, and can be used to define attribute mapping in the customer tenant:</p> <pre><code>{\n  \"displayName\": \"Alma Nakken\",\n  \"urn:ietf:params:scim:schemas:extension:enterprise:2.0:User\": {\n    \"department\": null,\n    \"manager\": {\n      \"value\": \"2\"\n    },\n    \"employeeNumber\": \"1\",\n    \"organization\": \"Company Inc\",\n    \"division\": \"HR\"\n  },\n  \"urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User\": {\n    \"enddate\": null,\n    \"jobtitleid\": 17,\n    \"orglevel0id\": \"197\",\n    \"orglevel0name\": \"Company Inc\",\n    \"orglevel1id\": \"187\",\n    \"orglevel1name\": \"HR\",\n    \"orglevel2id\": null,\n    \"orglevel2name\": null,\n    \"orglevel3id\": null,\n    \"orglevel3name\": null,\n    \"orglevel4id\": null,\n    \"orglevel4name\": null,\n    \"orglevelids\": [\n        \"197\",\n        \"187\"\n    ],\n    \"raw\": null,\n    \"ssn\": null,\n    \"startdate\": null\n  },\n  \"name\": {\n    \"familyName\": \"Nakken\",\n    \"givenName\": \"Alma\"\n  },\n  \"phoneNumbers\": [\n    {\n      \"type\": \"mobile\",\n      \"value\": \"+4799999999\"\n    }\n  ],\n  \"externalid\": \"1\",\n  \"active\": true,\n  \"schemas\": [\n    \"urn:ietf:params:scim:schemas:core:2.0:User\",\n    \"urn:ietf:params:scim:schemas:extension:enterprise:2.0:User\",\n    \"urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User\"\n  ],\n  \"title\": \"HR Consultant\",\n  \"addresses\": [\n    {\n      \"primary\": true,\n      \"type\": \"work\",\n      \"region\": \"Oslo\",\n      \"postalCode\": \"0862\",\n      \"locality\": \"Oslo\",\n      \"streetAddress\": \"Folke bernadottes vei 9A\",\n      \"country\": \"NOR\"\n    }\n  ]\n}\n</code></pre> SCIM attribute HR source object HR source attribute externalid Employment employeeid displayName Employment user.name title Employment job.title name.familyName UserProfile surname name.givenName UserProfile firstName phoneNumbers[type eq \"mobile\"].value UserProfile workContactDetails.contactInfo.mobilePhone active Employment firstWorkingDay, lastWorkingDay addresses[type eq \"work\"].streetAddress UserProfile workContactDetails.addressInfo.visitAddress.address addresses[type eq \"work\"].locality UserProfile workContactDetails.addressInfo.visitAddress.city addresses[type eq \"work\"].region UserProfile workContactDetails.addressInfo.visitAddress.municipality addresses[type eq \"work\"].postalCode UserProfile workContactDetails.addressInfo.visitAddress.zipCode addresses[type eq \"work\"].country UserProfile workContactDetails.addressInfo.visitAddress.country urn:ietf:params:scim:schemas:extension:enterprise:2.0:User:employeeNumber Employment employeeid urn:ietf:params:scim:schemas:extension:enterprise:2.0:User:manager Employment manager.employeeid urn:ietf:params:scim:schemas:extension:enterprise:2.0:User:organization Employment, OrgStructure orgUnit.id used to get level 1 of org structure urn:ietf:params:scim:schemas:extension:enterprise:2.0:User:division Employment, OrgStructure orgUnit.id used to get level 2 of org structure urn:ietf:params:scim:schemas:extension:enterprise:2.0:User:department Employment, OrgStructure orgUnit.id used to get level 3 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User:startdate Employment firstWorkingDay urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User:enddate Employment lastWorkingDay urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User:ssn UserProfile personalIdentification urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User:jobtitleid Employment job.id urn:ietf:params:scim:schemas:extension:fortytwo:1.0:User:startdate Employment firstWorkingDay urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel0name Employment, OrgStructure orgUnit.id used to get level 1 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel1name Employment, OrgStructure orgUnit.id used to get level 2 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel2name Employment, OrgStructure orgUnit.id used to get level 3 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel3name Employment, OrgStructure orgUnit.id used to get level 4 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel4name Employment, OrgStructure orgUnit.id used to get level 5 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel0id Employment, OrgStructure orgUnit.id used to get level 1 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel1id Employment, OrgStructure orgUnit.id used to get level 2 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel2id Employment, OrgStructure orgUnit.id used to get level 3 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel3id Employment, OrgStructure orgUnit.id used to get level 4 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevel4id Employment, OrgStructure orgUnit.id used to get level 5 of org structure urn:ietf:params:scim:schemas:extension:fortytwo:2.0:User:orglevelids Employment, OrgStructure orgUnit.id used to get all ids from the org structure"},{"location":"managed-identity-services/organizational-structure-groups/security-groups/how-to-use/","title":"How to use","text":"<p>Through our \"organizational structure as security groups\"-service, we generate each element in the organizational hierarchy as security groups in Entra ID, with the option of enabling write-back to on-premises Active Directory. The groups are usually named org - Company - Top unit - Lower unit and similar, and can be found by a simple starts-with search. Please do not modify or delete these groups, as our service will modify them back or re-create them automatically, to reflect the current organization hierarchy.</p>"},{"location":"managed-identity-services/organizational-structure-groups/security-groups/how-to-use/#how-to-use-the-groups","title":"How to use the groups","text":"<p>These groups can either be granted permissions directly, such as permissions on a file share, SharePoint site or assigned an enterprise app, or they can be added as member of other groups. Please note that there are very few features in Entra ID that supports nested groups. Instead of nested groups, what you can do is to use the feature Group membership in a dynamic group in Microsoft Entra ID.</p> <p>This means that if you have an existing Team, where you want to dynamically add users, you can convert the team to criteria based membership by following these steps:</p> <ol> <li>In the Entra or Azure portal, find the group and update the Membership type to Dynamic user, and click Add dynamic query</li> </ol> <p></p> <ol> <li>Edit the query and insert something like this, where the GUID values below are replaced with the object id of the groups you want to add:</li> </ol> <p>Add members from a single group</p> <p><code>user.memberof -any (group.objectId -in ['0ec82ade-dc40-4ad9-bf0d-0993adc231aa'])</code></p> <p>Add members from three different groups</p> <p><code>user.memberof -any (group.objectId -in ['0ec82ade-dc40-4ad9-bf0d-0993adc231aa','c240c88b-6554-4158-92ee-fdef974c3dc4','c240c88b-6554-4158-92ee-fdef974c3dc4'])</code></p> <p>There are quite a few limitations to the feature currently. Most noteably it is not possible to use other operations, such as -all (in order to only add members that are a member of multiple groups) and it is not possible to combine with other filters, such as user.jobTitle -ne 'Consultant'.</p> <p>I want a dynamic Team, but also one ekstra person</p> <p>Due to the limitation of combining the memberOf query with other queries, what you need to do if you want to add some manual users as well as the dynamic ones, you can create an additional group with the manual users and add the object id of that group to the filter. </p> <p>As an example, you can have the Team HR Department, where you have our dynamic group org - Company - HR as a memberof, but also the group HR Department - Manual users, where you put the manually managed ones.</p> <p><code>user.memberof -any (group.objectId -in ['ObjectID of org - Company - HR','ObjectID of HR Department - Manual users'])</code></p>"},{"location":"managed-identity-services/organizational-structure-groups/security-groups/service-description/","title":"Service description","text":"<p>At Fortytwo, we understand the critical importance of maintaining seamless integration between your Human Resources (HR) system and Entra ID for efficient user account and access management. Our managed service, Organizational structure as security groups, is designed to streamline and automate the synchronization of the HR organizational structure / hierarchy into an Entra ID security group structure that can be used to automatically assign licenses, services, applications and other Entra ID managed resources such as Teams.</p> <p></p>"},{"location":"managed-identity-services/organizational-structure-groups/security-groups/service-description/#key-features","title":"Key Features","text":"<ul> <li>Data sync: This service ensures synchronization of the organizational structure from your HR system to Active Directory and Entra ID security groups, reducing manual efforts and minimizing the risk of discrepancies.</li> <li>Seamless integration: Our service seamlessly integrates with Entra ID, establishing a robust connection that guarantees the accuracy and consistency of user account information.</li> <li>Improved Joiner-Mover-Leaver process: WHen a user joins or moves withing your organization, permissions are automatically updated using the created security groups. This results in efficient onboarding, relocation, and offboarding procedures. </li> <li>Scalability and reliability: The service is designed to scale with your organization's growth and is built on a reliable infrastructure, ensuring continuous operation and data integrity.</li> </ul>"},{"location":"managed-identity-services/organizational-structure-groups/security-groups/service-description/#benefits","title":"Benefits","text":"<ul> <li>Utilize Entra ID to the max: Ensure that you can utilize the full potential of your already purchased licenses.</li> <li>Efficiency: Eliminate manual data entry and reduce the risk of errors by automating the provisioning process.</li> <li>Reduced IT cost: Eliminate manual processes for IT.</li> <li>Compliance: Ensure that users loose access to services they are no longer entitled to when leaving or moving within the organization.</li> <li>User experience: Users are automatically assigned applications and permissions relevant for them.</li> </ul> <p>The service empowers your organization with a reliable and efficient solution for maintaining synchronization between your HR system and Entra ID, enabling you to focus on strategic HR initiatives while ensuring data accuracy and compliance. Experience the next level of HR and identity management integration with Fortytwo.</p>"},{"location":"managed-identity-services/organizational-structure-groups/security-groups/service-description/#responsibility-matrix","title":"Responsibility matrix","text":"Task/Activity Responsible Service Implementation Configure service settings Fortytwo Establish HR system connection Fortytwo Ongoing Operations and Support HR org structure quality Customer Monitor data synchronization Fortytwo Address service issues Fortytwo Address API changes Fortytwo Configuration Changes Adjust service settings Fortytwo Communication Provide service updates Fortytwo Share best practices Fortytwo Report issues Customer Inform end users about data processing Customer"},{"location":"managed-identity-services/organizational-structure-groups/security-groups/service-description/#pricing","title":"Pricing","text":"<p>200 USD per month</p> <p>Billing can be done through Azure Marketplace or directly.</p>"},{"location":"marketplace-offerings/","title":"Marketplace Offerings","text":"<p>Welcome to Marketplace Offerings.</p>"},{"location":"marketplace-offerings/github-runner-container-apps-job/","title":"Github Runner Container Apps Job","text":"<p>Self Hosted Github runners based on Jobs running in Azure Container Apps. Low cost and low effort to setup and maintain. Scales up and down based on the queue of jobs waiting in Github.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/","title":"Managed Azure Kubernetes Service","text":"<p>Azure Kubernetes Service (AKS) stands at the forefront of innovation, offering a powerful, scalable, and highly flexible platform that's perfect for businesses looking to leverage the full potential of containerized applications. With AKS, you're not just adopting a technology; you're embracing a future where agility, speed, and efficiency define your operational capabilities.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/#the-challenge-security-production-readiness","title":"The Challenge: Security &amp; Production Readiness","text":"<p>The journey with AKS can often be complex, especially when it comes to transitioning from development to a secure, production-ready environment. While AKS provides a cutting-edge foundation, ensuring that your cluster is secure, compliant, and ready to handle real-world, production-grade workloads requires additional expertise and configuration. This is where many face challenges \u2014 implementing the necessary security measures and ensuring the production readiness of their AKS environment can be a daunting task.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/#managed-azure-kubernetes-secure-by-default","title":"Managed Azure Kubernetes: Secure by Default","text":"<p>Recognizing this critical need, we at Fortytwo are thrilled to introduce \"Azure Kubernetes by Fortytwo\" \u2014 a solution exclusively available on the Azure Marketplace, offering a production-grade AKS cluster that's secure by default. Our platform team, with its deep expertise in cloud infrastructure and security, has meticulously crafted a solution that takes the robustness of AKS and enhances it with layers of security and operational readiness.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/#why-choose-managed-azure-kubernetes","title":"Why Choose Managed Azure Kubernetes?","text":"<p>Production-Grade Security: With Azure Kubernetes by Fortytwo, you don't just get AKS; you get AKS that's been fortified. Our clusters are configured with Microsofts own best practices considering security, ensuring that your applications are protected from day one.</p> <p>Seamless Integration: Our solution integrates seamlessly into your Azure environment, providing a smooth and familiar experience without the need for extensive reconfiguration or additional resources.</p> <p>Compliance and Governance: Adhering to the strictest compliance standards, our clusters are designed to meet the needs of highly regulated industries, offering peace of mind and reliability.</p> <p>Expert Support: Our Fortytwo platform team is always on hand to provide expert guidance and support, ensuring your AKS journey is smooth and efficient.</p> <p>Cutting-Edge Yet Safe: While AKS offers the latest in Kubernetes technology, Azure Kubernetes by Fortytwo ensures that this cutting-edge technology is harnessed safely and securely, making it truly production-ready.</p> <p>Focus on Innovation, Not Infrastructure: Free up your valuable resources to focus on what they do best \u2014 innovating and building great applications. Let us handle the complexities of securing and managing the Kubernetes infrastructure.</p> <p>Complete Ownership and Controlled Access: With Azure Kubernetes by Fortytwo, the control is entirely in your hands. You own the entire infrastructure and cluster, ensuring that you have full authority and oversight over your environment.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/#can-i-have-the-code","title":"Can I have the code?","text":"<p>The code is available from the automation template once you have deployed the application. This means if you wish to own the code, or dive deeper into how we build and maintain our state-of-the-art Kubernetes solutions, you have complete freedom to do so. Furthermore, if you prefer a more hands-on approach, we are ready to provide the code personally and assist you in your journey. Whether you plan to add new resources, customize existing configurations, or just want to understand the nuts and bolts of your Kubernetes environment, our open-source commitment puts you in the driver's seat.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/1.%20Installation/","title":"1. Installation","text":""},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/1.%20Installation/#overview","title":"Overview","text":"<p>This guide provides a quick walkthrough for installing the Managed Azure Kubernetes service application from the Azure Marketplace.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/1.%20Installation/#prerequisites","title":"Prerequisites","text":"<p>For the application to work as expected. The following resource providers must be registered in your subscription.</p> <p>Warning</p> <p>The required resource providers must be registered before you start the installation process. Failing to do so will result in a failed deployment.</p> <ol> <li>Go to your subscription in the Azure Portal (the subscription where you plan to deploy the application).</li> <li>Select <code>Resource providers</code> under <code>Settings</code> in the Menu.</li> <li>Ensure the following providers have the status <code>Registered</code><ul> <li><code>Microsoft.Monitor</code></li> <li><code>Microsoft.Dashboard</code></li> </ul> </li> </ol>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/1.%20Installation/#install-the-application","title":"Install the application","text":"<ol> <li> <p>Visit the application's page on the Azure Marketplace:     Azure Kubernetes by Fortytwo.</p> </li> <li> <p>Click on the <code>Get it now</code> button to initiate the setup process. Click <code>Continue</code> to proceed.</p> </li> <li> <p>Choose the preferred plan and click on the <code>Create</code> button to configure the application.</p> </li> <li> <p>Follow the configuration steps provided by the setup wizard. It will guide you through the necessary configurations for your requirements.</p> </li> <li> <p>After completing the configuration, click <code>Create</code> and wait for the deployment to finish.</p> </li> </ol> <p>Your application installation is now underway!</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/1.%20Installation/#next-step","title":"Next step","text":"<ul> <li>Grant access to the cluster</li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/2.%20Grant%20access%20to%20AKS/","title":"2. Grant access to AKS","text":""},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/2.%20Grant%20access%20to%20AKS/#overview","title":"Overview","text":"<p>This guide details how to grant yourself access to an Azure Kubernetes Service (AKS) cluster using Azure RBAC roles in the Azure portal.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/2.%20Grant%20access%20to%20AKS/#prerequisites","title":"Prerequisites","text":"<ul> <li>Successfull deployment of the managed application.</li> <li>Required account privileges to grant resource access</li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/2.%20Grant%20access%20to%20AKS/#grant-access-to-users","title":"Grant access to users","text":"<ol> <li> <p>Log into Azure Portal:</p> <ul> <li>Go to Azure Portal and sign in.</li> </ul> </li> <li> <p>Navigate to Your AKS Cluster:</p> <ul> <li>Click <code>Go to resource</code> and click the managed resource group (eg. <code>mrg-kubernetes-xxxx</code> if you installed with default settings) in essentials section under <code>Overview</code>.</li> <li>Find your Kubernetes service resource and click it.</li> </ul> </li> <li> <p>Access Control (IAM):</p> <ul> <li>Click the <code>Access Control (IAM)</code> section and click on <code>+ Add</code>.</li> <li>Select the <code>Azure Kubernetes Service RBAC Cluster Admin</code> role and click <code>Next</code>.</li> <li>Click <code>Select members</code> and find your own user account (and any other user that needs access) in the list. Click <code>Select</code> to save the user selection.</li> <li>Click <code>Next</code> and then <code>Review + Assign</code> to save the changes.</li> </ul> </li> </ol>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/2.%20Grant%20access%20to%20AKS/#conclusion","title":"Conclusion","text":"<p>You now have the necessary permissions on your AKS cluster.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/2.%20Grant%20access%20to%20AKS/#next-step","title":"Next step","text":"<ul> <li>Connect to the AKS cluster</li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/3.%20Connect%20to%20the%20cluster/","title":"3. Connect to the cluster","text":""},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/3.%20Connect%20to%20the%20cluster/#overview","title":"Overview","text":"<p>This guide helps you connect to your Azure Kubernetes Service (AKS) cluster using Azure CLI commands.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/3.%20Connect%20to%20the%20cluster/#prerequisites","title":"Prerequisites","text":"<ul> <li>Azure account with necessary privileges.</li> <li>Azure Cloud Shell / Any CLI</li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/3.%20Connect%20to%20the%20cluster/#connect-to-the-aks-cluster","title":"Connect to the AKS cluster","text":"<ol> <li> <p>Log in to Azure</p> <ul> <li>Go to the Azure Portal and login.</li> <li>Open your Azure Cloud Shell by clicking the following button:</li> </ul> <p></p> <ul> <li>Follow the browswer prompt and use your Microsoft SSO login to authenticate. </li> </ul> </li> <li> <p>Set Azure Subscription</p> <p>Note</p> <p>For convenience, Azure provides the commands below prefilled in the Azure Portal under your Kubernetes services resource's <code>Connect</code> section. Copy and paste the commands from there to avoid doing these steps manually</p> <ul> <li>Run the following command in your cloud shell, replacing <code>&lt;subscription-id&gt;</code> with your Azure subscription ID:   <pre><code>az account set --subscription &lt;subscription-id&gt;\n</code></pre></li> </ul> </li> <li> <p>Get AKS Credentials</p> <ul> <li>Replace <code>&lt;resource-group-name&gt;</code> and <code>&lt;cluster-name&gt;</code> with your resource group and cluster name, respectively:   <pre><code>az aks get-credentials --resource-group &lt;resource-group-name&gt; --name &lt;cluster-name&gt;\n</code></pre></li> </ul> </li> <li> <p>Convert KubeConfig for Azure AD Integration</p> <ul> <li>Use kubelogin to convert your kubeconfig:   <pre><code>kubelogin convert-kubeconfig -l azurecli\n</code></pre></li> </ul> </li> </ol>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/3.%20Connect%20to%20the%20cluster/#conclusion","title":"Conclusion","text":"<p>After executing these commands, you will be connected to your AKS cluster and can start managing it via <code>kubectl</code>.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/3.%20Connect%20to%20the%20cluster/#next-steps","title":"Next steps","text":"<ul> <li>Configure Keyvault addon for Kubernetes secrets</li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/4.%20Secrets%20integration/","title":"4. Secrets integration","text":""},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/4.%20Secrets%20integration/#overview","title":"Overview","text":"<p>This guide walks you through setting up the CSI Secret Driver for Azure, allowing Kubernetes to use secrets stored in Azure Key Vault using a user-assigned managed identity.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/4.%20Secrets%20integration/#prerequisites","title":"Prerequisites","text":"<ul> <li>Access to the Key vault</li> <li>Connected to the AKS cluster</li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/4.%20Secrets%20integration/#csi-secret-store-driver-configuration","title":"CSI Secret Store Driver configuration","text":"<ol> <li> <p>Access Your Key vault</p> <ul> <li>In your managed resource group (eg. <code>mrg-kubernetes-by-fortytwo-xxxx</code> if you are using the default values). Locate the Key vault resource type in the resource list and click it. </li> </ul> </li> <li> <p>Update IAM Settings</p> <ul> <li>Go to Access control (IAM) section of your Key vault and click <code>+ Add</code> and <code>Add role assignment</code>.</li> <li>Select the <code>Key Vault Secrets Officer</code> role and click <code>Next</code>.</li> <li>Click the <code>Select members</code> button and find your own user in the list.</li> <li>Click <code>Next</code> and then <code>Review + assign</code> to save the changes.</li> </ul> </li> <li> <p>Add your IP address to the Key vault firewall</p> <ul> <li>Find your own IP address (eg. by using <code>https://whatismyipaddress.com/</code>) and copy it to your clipboard.</li> <li>Go to the <code>Networking</code> section in the left menu under <code>Settings</code>.</li> <li>Under <code>Firewall</code> click <code>+ Add your client IP address</code></li> <li>Paste in your IP address in the list and click <code>Apply</code> to apply the changes.</li> </ul> </li> <li> <p>Add Secrets to Key vault</p> <ul> <li>Click <code>Secrets</code> in the left menu in your Key vault.</li> <li>Click on <code>+ Generate/Import</code> to add new secrets.</li> <li>Enter the secret name <code>secret1</code> and some random secret value.</li> <li>Click <code>Create</code> to save the secret in the Key vault.</li> </ul> </li> <li> <p>Configure Kubernetes to Use Azure Key Vault with User-Assigned Managed Identity</p> <ul> <li>Copy and paste the following code in your terminal, which utilizes a user-assigned managed identity to access your Key vault. Replace <code>&lt;key-vault-name&gt;</code>, <code>&lt;tenant-id&gt;</code>, and <code>&lt;client-id&gt;</code> with your own values.</li> </ul> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: workloads\n---\napiVersion: secrets-store.csi.x-k8s.io/v1\nkind: SecretProviderClass\nmetadata:\n  name: azure-kvname-user-msi\n  namespace: workloads\nspec:\n  provider: azure\n  parameters:\n    usePodIdentity: \"false\"\n    useVMManagedIdentity: \"true\"\n    userAssignedIdentityID: &lt;managed-identity-client-id&gt;   # Replace with the clientID of the managed identity\n    keyvaultName: &lt;keyvault-name&gt;                          # Replace with your Key Vault name\n    objects:  |\n      array:\n        - |\n          objectName: secret1\n          objectType: secret\n          objectVersion: \"\"\n    tenantId: &lt;tenant-id&gt;                                  # Replace with your Azure tenant ID\nEOF\n</code></pre> <ul> <li>Finding Tenant ID:<ul> <li>In your Key vault, click the \"Overview\" and look for the \"Directory ID\" in the \"Essentials\" section.</li> </ul> </li> <li>Finding Managed Identity:<ul> <li>The managed identity client-id can be found in the Azure portal under the resource type \"Managed Identity\". Its name typically follows the format <code>azurekeyvaultsecretsprovider-{cluster-name}</code>.</li> </ul> </li> </ul> </li> </ol>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/4.%20Secrets%20integration/#conclusion","title":"Conclusion","text":"<p>After following these steps, the CSI Secret Driver will be configured in your Kubernetes cluster using Azure Key Vault with a user-assigned managed identity.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/4.%20Secrets%20integration/#next-steps","title":"Next steps","text":"<ul> <li>Configure ArgoCD UI</li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/5.%20ArgoCD%20UI/","title":"5. ArgoCD UI","text":""},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/5.%20ArgoCD%20UI/#overview","title":"Overview","text":"<p>This guide explains how to quickly expose the Argo CD server UI in your Kubernetes cluster and authenticate using the initial admin account.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/5.%20ArgoCD%20UI/#expose-argocd-server-service","title":"Expose argocd-server service","text":"<ol> <li> <p>Change Argo CD Service Type:</p> <ul> <li>Edit the Argo CD server service to change its type to LoadBalancer:   <pre><code>kubectl patch svc argocd-server -n argocd -p '{\"spec\": {\"type\": \"LoadBalancer\"}}'\n</code></pre></li> </ul> </li> <li> <p>Retrieve the External IP:</p> <ul> <li>Once the service is exposed, get the external IP:   <pre><code>kubectl get svc argocd-server -n argocd -o=jsonpath='{.status.loadBalancer.ingress[0].ip}'\n</code></pre></li> </ul> <p>Note</p> <p>The external IP needs to be generated and it can take a couple of seconds before its visible.</p> </li> <li> <p>Access Argo CD UI:</p> <ul> <li>Copy and paste the external IP to access the Argo CD UI through a web browser.</li> </ul> <p>Info</p> <p>The ArgoCD UI will not be secured with a certificate using this approach. You will get a warning stating <code>Your connection is not private</code>. You can ignore this and proceed by clicking <code>Advanced</code> and <code>Proceed to IP (unsafe)</code>.</p> <p>Use the automatically installed <code>ingress-nginx controller</code> in your cluster to issue an ingress resource for your ArgoCD UI and remove this warning.</p> <p>Quick guide: Configure Ingress for ArgoCD UI</p> </li> <li> <p>Retrieve Initial Admin Password:</p> <ul> <li> <p>Get the initial admin password from the <code>argocd-initial-admin-secret</code> in the Argo CD namespace:</p> <ul> <li> <p>Mac/UNIX:   <pre><code>kubectl get secret argocd-initial-admin-secret -n argocd -o jsonpath=\"{.data.password}\" | base64 -d\n</code></pre></p> </li> <li> <p>Powershell: <pre><code>$decodedPassword = kubectl get secret argocd-initial-admin-secret -n argocd -o jsonpath='{.data.password}' | ForEach-Object { [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($_)) }\nWrite-Output \"Decoded Password: $decodedPassword\"\n</code></pre></p> </li> </ul> </li> </ul> </li> <li> <p>Log In:</p> <ul> <li>Use the username <code>admin</code> and the retrieved password to log in to the Argo CD UI.</li> </ul> </li> </ol>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/5.%20ArgoCD%20UI/#conclusion","title":"Conclusion","text":"<p>You can now access and manage your Argo CD deployments through the UI with the initial admin credentials.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/5.%20ArgoCD%20UI/#next-step","title":"Next step","text":"<ul> <li>Using Private github repositories</li> <li>Deploy your workloads</li> </ul> <p>Note</p> <p>If your Github repository is public, you can skip directly to deploying your workloads.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/5.%20ArgoCD%20UI/#51-use-ingress","title":"5.1 Use Ingress","text":""},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/5.%20ArgoCD%20UI/#overview_1","title":"Overview","text":"<p>This small guide will show you how to use ArgoCD itself to create the ingress resources required to issue certificates for the argocd-server and securely handle tls for your UI. The ingress resource for the UI will be controlled by the ArgoCD application.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/5.%20ArgoCD%20UI/#deploy-ingress-using-argocd","title":"Deploy ingress using ArgoCD","text":"<ul> <li>Prerequisites:<ul> <li>Your own domain</li> <li> <p>AAA Record pointing to Ingress IP</p> <p>Note</p> <p>You can fetch your Ingress IP by running the following command in your terminal:</p> <pre><code>kubectl get svc ingress-nginx-controller -n ingress-nginx -o=jsonpath='{.status.loadBalancer.ingress[0].ip}'\n</code></pre> </li> </ul> </li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/5.%20ArgoCD%20UI/#manifests","title":"Manifests","text":"<ul> <li>Push the following files (with your own values) to your github repository.</li> </ul> <p>Ingress setup manifests:</p> <pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: &lt;your-email&gt;\n    privateKeySecretRef:\n      name: letsencrypt-prod\n    solvers:\n      - http01:\n          ingress:\n            class: nginx\n            podTemplate:\n              metadata:\n                labels:\n                  podtype: acme-solver\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: argocd-server-ingress\n  namespace: argocd\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    nginx.ingress.kubernetes.io/ssl-passthrough: \"true\"\n    kubernetes.io/tls-acme: \"true\"\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: argo.yourdomain.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: argocd-server\n            port:\n              name: https\n  tls:\n  - hosts:\n    - argo.yourdomain.com\n    secretName: argocd-server-tls # Dont change this\n</code></pre> <p>Use ArgoCD to deploy its own ingress as application:</p> <ul> <li>Apply the following ArgoCD application manifest to deploy your ingress resources.</li> </ul> <pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: argocd-ingress\n  namespace: argocd\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/your-github-username/your-repo-name.git # change this to your repostiroy url\n    path: path/to/your/kubernetes/manifests # change this to the location of your ingress manifests that you pushed to git earlier\n    targetRevision: HEAD\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: argocd\n  syncPolicy:\n    automated:\n      prune: false\n      selfHeal: true\n    syncOptions:\n      - CreateNamespace=true\n</code></pre> <p>Info</p> <p>Propagation can take some time depending on your DNS provider. Because of this, the UI might not be available directly after applying these manifests. Give it a couple of minutes.</p> <ul> <li>Check your ArgoCD UI in the browser by going to <code>argo.yourdomain.com</code>.</li> <li>You can also verify the status of your ArgoCD Ingress application by running the following command:</li> </ul> <pre><code>kubectl get applications --namesppace argocd\n</code></pre>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/5.%20ArgoCD%20UI/#conclusion_1","title":"Conclusion","text":"<ul> <li>You have successfully exposed the ArgoCD UI with a Kubernetes Ingress resource, using Ingress NGINX, Cert-manager and Lets Encrypt.</li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/6.%20Using%20private%20github%20repositories/","title":"6. Using private github repositories","text":""},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/6.%20Using%20private%20github%20repositories/#overview","title":"Overview","text":"<p>This guide will help you set up access to a private GitHub repository in Argo CD for managing your applications.</p> <p>Note</p> <p>Please continue to the next step if you are using a public repository - 7. Deploy your workloads</p> <p>Dont have any repository but still want to test the deployment process?</p> <p>You can use the following public sample repository.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/6.%20Using%20private%20github%20repositories/#configure-access-to-private-github-repository","title":"Configure access to private github repository","text":"<ol> <li> <p>Navigate to Argo CD UI:</p> <ul> <li>Open the Argo CD UI in your web browser.</li> </ul> </li> <li> <p>Open Settings:</p> <ul> <li>Go to the <code>Settings</code> section in the left menu.</li> </ul> </li> <li> <p>Connect to Repository:</p> <ul> <li>Click on <code>Repositories</code>.</li> <li>Choose <code>Connect Repo</code>.</li> <li>Keep the default setting of <code>Via SSH</code> in the connection method dropdown.</li> <li>Select the <code>default</code> project.</li> <li>Paste your Github Repository URL into the <code>Repository URL</code> field. Eg. <code>https://github.com/fortytwoservices/sampleapps.git</code></li> <li>In the <code>SSH private key data</code> field, paste your SSH private key. This key is generated in your GitHub repository settings.</li> </ul> <p>Info</p> <p>Not sure where to find or how to create a Github SSH Key? Check out the docs: GitHub SSH Key Setup.</p> </li> </ol>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/6.%20Using%20private%20github%20repositories/#conclusion","title":"Conclusion","text":"<p>You have now configured Argo CD to access a private GitHub repository, enabling you to manage applications hosted in that repository.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/6.%20Using%20private%20github%20repositories/#next-step","title":"Next step","text":"<ul> <li>Deploy your workloads</li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/7.%20Deploy%20workloads/","title":"7. Deploy workloads","text":""},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/7.%20Deploy%20workloads/#overview","title":"Overview","text":"<p>This guide will help you deploy your workload using Argo CD by creating an application manifest that utilizes secrets from Azure Key Vault and targets your GitHub repository.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/7.%20Deploy%20workloads/#prerequisites","title":"Prerequisites","text":"<ul> <li>A GitHub repository with your application code.</li> <li>Secrets stored in Azure Key vault (if your application requires it).</li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/7.%20Deploy%20workloads/#proposed-git-structure","title":"Proposed Git structure","text":"<ul> <li> <p>You should have at least two repositories.</p> <ul> <li>One repository for your application code. This will include your application backend and frontend.</li> <li>One repository for your Kubernetes manifests and platform specific things. This will include ArgoCD applications, application sets and YAML files.<ul> <li>You should split this repository up into logical folders.<ul> <li><code>apps</code>: this folder holds all your Kubernetes manifests for your applications.</li> <li><code>projects</code>: this folder holds all your ArgoCD projects, applications and application sets.</li> </ul> </li> </ul> </li> </ul> <p>Info</p> <p>Whatever combination of repositories you prefer is sufficient to follow and complete this guide. </p> <p>However, you should opt for a more structured approach for your production workloads.</p> </li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/7.%20Deploy%20workloads/#deploy-your-workloads","title":"Deploy your workloads","text":"<ol> <li>Prepare your Application Manifest:<ul> <li>Create your application manifest in your Github repository.<ul> <li>Remember to reference the <code>SecretProviderClass</code> in your Kubernetes deployment manifests to use secrets from Azure Key Vault.</li> </ul> </li> <li>Example application manifest (eg. <code>busybox.yaml</code>) located in your Github repository (or any public repository you are using): <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: busybox-secrets-store-deployment\n  namespace: workloads\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: busybox-secrets-store\n  template:\n    metadata:\n      labels:\n        app: busybox-secrets-store\n    spec:\n      containers:\n      - name: busybox\n        image: registry.k8s.io/e2e-test-images/busybox:1.29-4\n        command: [\"sleep\", \"300\"]\n        volumeMounts:\n        - name: secrets-store01-inline\n          mountPath: \"/mnt/secrets-store\"\n          readOnly: true\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"500m\"\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsNonRoot: true\n          readOnlyRootFilesystem: true\n          runAsUser: 65533\n        livenessProbe:\n          exec:\n            command:\n            - cat\n            - /mnt/secrets-store/secret1\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          exec:\n            command:\n            - cat\n            - /mnt/secrets-store/secret1\n          initialDelaySeconds: 5\n          periodSeconds: 10\n      volumes:\n      - name: secrets-store01-inline\n        csi:\n          driver: secrets-store.csi.k8s.io\n          readOnly: true\n          volumeAttributes:\n            secretProviderClass: \"azure-kvname-user-msi\" # Change this to reflect your secretProviderClass name if you deviated from the walkthrough\n</code></pre></li> </ul> </li> <li> <p>Prepare the ArgoCD manifest:</p> <ul> <li>Create an application manifest file (e.g., <code>app.yaml</code>). Here is a example ArgoCD application that deploys the application manifest above. Copy and run the following code in your terminal:</li> </ul> <pre><code>  kubectl apply -f - &lt;&lt;EOF\n  apiVersion: argoproj.io/v1alpha1\n  kind: Application\n  metadata:\n    name: busybox-deployment\n    namespace: argocd\n  spec:\n    project: default\n    source:\n      repoURL: https://github.com/fortytwoservices/sampleapps.git\n      path: amesto42/sample/\n      targetRevision: HEAD\n    destination:\n      server: https://kubernetes.default.svc\n      namespace: workloads  # Change to match your workload namespace\n    syncPolicy:\n      automated:\n        prune: false\n        selfHeal: true\n      syncOptions:\n        - CreateNamespace=true\nEOF\n</code></pre> <p>Info</p> <p>This is just a sample deployment. While it will work if you deploy this, it is deploying a <code>busybox</code> image which will fail eventually. You should try deploying your own environment specific workloads instead.</p> <p>The example is just to gain an understanding of how the deployment process works in your new platform.</p> </li> <li> <p>Verify deployment:</p> <ul> <li> <p>You now have two options.</p> <ol> <li> <p>Check the ArgoCD UI in your browser by using the external IP from the argocd-server service. The application tile should be visible in the <code>Applications</code> section. Click the application tile if you want to inspect the application and its components further.</p> </li> <li> <p>Use kubectl to interact with ArgoCD through your terminal/CLI and list the applications in your cluster. You can run the following command to achieve this:</p> <p><code>kubectl get applications --namespace argocd</code></p> </li> </ol> <p>Note</p> <p>You can fetch the External IP of the ArgoCD server by running the following command:</p> <p><code>kubectl get svc argocd-server -n argocd -o=jsonpath='{.status.loadBalancer.ingress[0].ip}'</code></p> </li> </ul> </li> <li> <p>Verify workload content</p> <ul> <li> <p>As a final step and to verify that the secret you uploaded in the Azure Key vault has been mounted correctly inside your workload in a secure manner. Run the following commands:</p> <p><code>kubectl exec busybox-secrets-store-deployment -- ls /mnt/secrets-store/</code></p> <p><code>kubectl exec busybox-secrets-store-deployment -- cat /mnt/secrets-store/secret1</code></p> </li> </ul> </li> </ol>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/getting-started/7.%20Deploy%20workloads/#conclusion","title":"Conclusion","text":"<p>Your application is now deployed using Argo CD, with secrets securely managed by Azure Key Vault and code hosted in a GitOps way on GitHub.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/monitoring/1.%20Managed%20Grafana/","title":"1. Managed Grafana","text":""},{"location":"marketplace-offerings/managed-azure-kubernetes-service/monitoring/1.%20Managed%20Grafana/#overview","title":"Overview","text":"<p>Grafana, a popular open-source platform for monitoring and observability, is automatically deployed in your Managed Azure Kubernetes Service (AKS) environment. This deployment is part of our standard service to enhance your ability to monitor, visualize, and analyze your Kubernetes workloads.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/monitoring/1.%20Managed%20Grafana/#granting-access-to-users","title":"Granting access to users","text":"<p>To grant access to users:</p> <ul> <li>In your managed resource group (eg. <code>mrg-kubernetes-xxxx</code>), look for the Azure Managed Grafana resource type. The resource name will be prefixed with <code>amg-</code>.</li> <li>Click <code>Access control (IAM)</code> followed by <code>+ Add</code> and <code>Add role assignment</code>.</li> <li>Find the appropriate access role. There are currently three different access levels.</li> </ul> <p>Info</p> <p><code>Grafana Admin</code> are for administrators providing full access to Grafana. Eg. edit data sources and plugins.</p> <p><code>Grafana Editor</code> are for users that require privileges to eg. create and edit dashboards.</p> <p><code>Grafana Reader</code> are for users that only require read access. Eg. look at dashboards and metrics.</p> <ul> <li>Click <code>Next</code> and <code>+ Select members</code>. Select the user you want to grant access to in the list and click <code>Select</code>. Click <code>Next</code> followed by <code>Review + assign</code> to apply the changes.</li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/monitoring/1.%20Managed%20Grafana/#accessing-grafana","title":"Accessing Grafana","text":"<p>To access the Grafana UI:</p> <ul> <li>In the <code>Overview</code> section of your <code>Azure Managed Grafana</code> resource, copy the <code>Endpoint</code> from the <code>Essentials</code> and paste it into your browser. Use your Microsoft account and SSO login.</li> </ul> <p>Info</p> <p>The endpoint will look similar but not exactly like this:    <code>https://amg-bkm3khei3qnq2-ctgse4gmgfckb4gt.weu.grafana.azure.com</code></p> <ul> <li>Delve into the already provisioned dashboards via <code>Dashboards</code> or look right at the metrics in <code>Explore</code>.s</li> </ul>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/monitoring/3.%20Managed%20Prometheus/","title":"3. Managed Prometheus","text":""},{"location":"marketplace-offerings/managed-azure-kubernetes-service/monitoring/3.%20Managed%20Prometheus/#overview","title":"Overview","text":"<p>Prometheus is an open-source monitoring and alerting toolkit known for its reliability and scalability. It collects and stores its metrics as time series data, i.e., data points with timestamp information attached. In an Azure Kubernetes Service (AKS) cluster, Prometheus works by scraping metrics from configured endpoints at specified intervals. These endpoints are usually exposed by Kubernetes components and workloads running within the cluster.</p> <p>Once Prometheus collects these metrics, it can process them through its powerful querying language, PromQL, allowing for detailed insights and analysis. This data can then be forwarded to visualization tools like Grafana.</p>"},{"location":"marketplace-offerings/managed-azure-kubernetes-service/monitoring/3.%20Managed%20Prometheus/#prometheus-data-endpoint","title":"Prometheus data endpoint","text":"<ul> <li>Find the URL/Endpoint for Prometheus in the 'Overview' section of the Managed Prometheus resource on the Azure Portal.</li> </ul>"},{"location":"marketplace-offerings/managed-azure-landing-zones/","title":"Managed Azure landing zones","text":"<p>This product is a full Managed azure landing zones implementation based on Microsoft Cloud Adoption Framework for Azure. It is designed for environments which require a secure, scalable and cost-effective landing zone in Azure. The landing zone is designed to be a foundation for future workloads, and is designed to be secure, scalable and cost-effective. Fully integrated with Azure devops, and can be used to deploy workloads in a secure and cost-effective way - using Infrastructure as Code.</p>"},{"location":"marketplace-offerings/managed-desktop-light/","title":"Managed Desktop Light","text":"<p>This product is a lightweight Managed Desktop solution. It is designed for environments which require a simple, secure and low-cost desktop environment, and do not want the complexity of a full Managed Desktop solution with multiple sessionHosts, user profiles and network connectivity to other services.</p> <p>Link to offer on Azure Marketplace</p>"},{"location":"marketplace-offerings/managed-desktop-light/#use-cases","title":"Use cases","text":"<p>Designed for applications that needs to be accessible from multiple locations and hosted in Azure:</p> <ul> <li>Archive of old finance system, needs to be accessible for 5 years (in norway) after the system is decomissioned. Typically used by a few users, and not that often - less and less frequent.</li> <li>Application that use classic \"on-prem\" architecture, and is not possible to migrate to a modern architecture. Often needs to be accessible from multiple locations, and hosted in Azure.</li> <li>The need to have an Office application running in Azure.</li> </ul>"},{"location":"marketplace-offerings/managed-desktop-light/Architecture/","title":"Architecture","text":"<p>The solution is based on a single Windows 11 multi-session host. The host is joined to Azure AD, and users are authenticated using Azure AD. The host is not joined to any on-prem domain, and is not connected to any on-prem network. The host is not connected to any other Azure network, and is not connected to any other Azure resources.</p>"},{"location":"marketplace-offerings/managed-desktop-light/Architecture/#network","title":"Network","text":"<ul> <li>1x Virtual Network</li> <li>1x Subnet</li> <li>1x Network Security Group</li> </ul>"},{"location":"marketplace-offerings/managed-desktop-light/Architecture/#azure-virtual-desktop","title":"Azure Virtual Desktop","text":"<p>Consist of the following components:</p> <ul> <li>1x Host Pool</li> <li>2x Application Groups</li> <li>1x Workspace</li> </ul>"},{"location":"marketplace-offerings/managed-desktop-light/Architecture/#virtual-machine","title":"Virtual Machine","text":"<ul> <li>1x Virtual Machine</li> <li>1x Managed Disk</li> <li>1x Network Interface</li> </ul>"},{"location":"marketplace-offerings/managed-desktop-light/Architecture/#log-analytics","title":"Log Analytics","text":"<ul> <li>1x Log Analytics Workspace</li> </ul>"},{"location":"marketplace-offerings/managed-desktop-light/Architecture/#backup","title":"Backup","text":"<ul> <li>1x Recovery Services Vault</li> </ul>"},{"location":"marketplace-offerings/managed-desktop-light/Architecture/#automation-account","title":"Automation Account","text":"<ul> <li>1x Automation Account</li> <li>1x Runbook</li> <li>1x Schedule</li> <li>1x Managed Identity</li> </ul>"},{"location":"marketplace-offerings/managed-desktop-light/Backup/","title":"Backup","text":"<p>There is a weekly schedule for backup of the virtual machine, and the backup is stored in a Recovery Services Vault. The backup is stored for 4 weeks. In addition there is a instant restore snapshot of the virtual machine, and the snapshot is stored for 5 days.</p> <p></p> <p>The Recovery Services Vault is placed in the same resource group as the virtual machine, and the backup is stored in the same region as the virtual machine. The softdelete is enabled on the Recovery Services Vault, and the retention is set to 14 days.</p>"},{"location":"marketplace-offerings/managed-desktop-light/Deployment/","title":"Deployment","text":"<p>Managed Desktop Light is deployed through the Azure Portal, using Azure Marketplace. The deployment is done in a few steps, and is fully automated. The resources is placed in a resource group, and the resource group is placed in a subscription that lives in your own tenant. The subscription is billed monthly, and the cost is based on the number of users.</p>"},{"location":"marketplace-offerings/managed-desktop-light/Deployment/#decisions","title":"Decisions","text":"<p>There is a few descicions that needs to be made before the deployment can be started.</p> <ul> <li>The name of the resource group</li> <li>The name of the Managed Application</li> <li>The name of the Managed Resource Group</li> <li>Company name (ie. Contoso Ltd.)</li> <li>Environment name (ie. Visma Archive Solution)</li> <li>Does the environment have a need for the Office Suite?</li> <li>If the environment have the Office Suite, should it be published as a remoteApp?</li> <li>Should the solution be shutdown at a certain time of day? (cost saving)</li> <li>What size should the datadisk be? (default is 128GB)</li> <li>What SKU should the Virtual Machine have? (default is Standard_B2ms_v2 - which suites a simple application with a few users)</li> </ul>"},{"location":"marketplace-offerings/managed-desktop-light/Deployment/#prerequisites","title":"Prerequisites","text":"<p>There is a few prerequisites that needs to be in place before the deployment can be started.</p> <ul> <li>ObjectID of the two groups that should grant access to the solution, from your own EntraID tenant.</li> </ul> <p></p> <p>The application \"Azure Virtual Desktop\" with ClientID 5a0aa725-4958-4b0c-80a9-34562e23f3b7 (Object ID is different in each tenant) needs to be granted the the permission \"Desktop Virtualization Power On Off Contributor\" on the subscription. This is done in the Azure Portal, under \"Subscriptions\" -&gt; \"Access Control (IAM)\" -&gt; \"Add role assignment\". The role is \"Desktop Virtualization Power On Off Contributor\", and the assignee is \"Azure Virtual Desktop\".</p> <p></p> <p>NB! The role must be granted on the subscription level.</p>"},{"location":"marketplace-offerings/managed-desktop-light/Deployment/#entraid-previously-azure-ad","title":"EntraID (previously Azure AD)","text":"<p>The solution is based on Azure AD, and the users needs to be created in Azure AD. The users can be created in the Azure Portal, or synced from an on-prem AD using Azure AD Connect. You need two groups in Azure AD, one for the users that should have access to the solution, and one for the users that should have admin access to the solution. The groups is used to grant access to the Virtual Machine (session host).</p>"},{"location":"marketplace-offerings/managed-desktop-light/Deployment/#admin-group","title":"Admin group","text":"<p>The users in the admin group will be granted the following roles on the resource group:</p> <ul> <li>Virtual Machine Administrator Login (description)</li> <li>Backup Operator (description)</li> <li>Desktop Virtualization User (description)</li> </ul>"},{"location":"marketplace-offerings/managed-desktop-light/Deployment/#user-group","title":"User group","text":"<p>The users in the user group will be granted the following roles on the resource group:</p> <ul> <li>Virtual Machine User Login (description)</li> <li>Desktop Virtualization User (description)</li> </ul>"},{"location":"marketplace-offerings/managed-desktop-light/End%20User/","title":"End user Documentation for Managed Desktop Light","text":""},{"location":"marketplace-offerings/managed-desktop-light/End%20User/#pre-requisites","title":"Pre-requisites","text":"<p>The Azure Virtual Desktop client is available for Windows, MacOS, iOS, Android and HTML5. The client is available from this page: Azure Virtual Desktop clients</p> <p>NB! Printing is NOT supported in the HTML5 client.</p>"},{"location":"marketplace-offerings/managed-desktop-light/End%20User/#introduction","title":"Introduction","text":"<p>Connecting from the Azure Virtual Desktop client is quite simple, you click on subscribe, and the client will pop-up an authentication window. You need to authenticate with your EntraID account (if MFA is required this will also pop-up), and then you will see the available resources.</p>"},{"location":"marketplace-offerings/managed-desktop-light/End%20User/#connecting","title":"Connecting","text":"<p>The first time you login to the sessionDesktop, you will be asked to authenticate again. You will also be asked to grant the Azure Virtual User Login permission to the sessionDesktop. This is needed to be able to login to the sessionDesktop.</p> <p></p> <p>You can also adjust the settings for the sessionDesktop, by right clicking on the sessionDesktop and select \"Settings\".</p> <p></p> <p>If you ie. want to have the sessionDesktop in just a window, and not full screen, you can adjust this in the settings.</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/","title":"Self Hosted Runners","text":"<p>Do you need self hosted runners for Azure DevOps og GitHub, and simply want to have the same runners as Microsoft's Hosted Runners without any more fuzz? Look no further. This solution uses an image that is continuously updated with the same cadence as the Microsoft Hosted Runners, with the same application versions installed.</p>"},{"location":"marketplace-offerings/self-hosted-runners/#possibilities","title":"Possibilities","text":""},{"location":"marketplace-offerings/self-hosted-runners/#access-any-cloud-platform-from-your-runners","title":"Access any cloud platform from your runners","text":"<p>You can choose to allow the self hosted runners to access any internet connected service for deployment.</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/#enable-private-access-to-azure-resources","title":"Enable private access to Azure resources","text":"<p>You can enable private access to Azure resources through either service endpoints or private endpoints / Private Link.</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/#enable-access-to-on-premises","title":"Enable access to on-premises","text":"<p>You can connect your self hosted runners to on-premises, other landing zones or privately to other cloud services through several methods. An example cloud by Virtual WAN, but of course network peering, VPN gateways and other methods are also available:</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/#can-you-see-my-data","title":"Can you see my data?","text":"<p>No, this is simply a configuration of a Virtual machine scale set using published VM images and contains no call home functionality or similar.</p>"},{"location":"marketplace-offerings/self-hosted-runners/#can-you-access-my-virtual-machines","title":"Can you access my virtual machines?","text":"<p>No, you control everything yourself.</p>"},{"location":"marketplace-offerings/self-hosted-runners/#why-do-you-recommend-using-a-virtual-machine-scale-set","title":"Why do you recommend using a Virtual Machine Scale Set?","text":"<p>We recommend using a Virtual Machine Scale Set because it can continuously grab the latest image from Azure Marketplace, ensuring that you always have the latest runner, and because it can be used to automatically scale up and down the number of agents you have available, without you needing to worry about it. It is also cheaper, as you do not need to run many idle agents.</p>"},{"location":"marketplace-offerings/self-hosted-runners/#how-do-i-configure-this","title":"How do I configure this?","text":"<p>Follow one of these:</p> <ul> <li>Azure DevOps</li> <li>GitHub</li> </ul>"},{"location":"marketplace-offerings/self-hosted-runners/ado/","title":"Configuring Azure DevOps self hosted runners using VMSS","text":"<p>This documentation shows you how to configure an Azure Virtual Machine Scale Set (VMSS) that will always be running the latest Self Hosted Runner image, and connecting the VMSS as an agent pool in Azure DevOps. Using a VMSS in Azure DevOps gives you the ability to automatically increase and decrease the number of active runners dynamically based on pipeline demand. Additionally, the VMSS will always create instances based on the latest runner image published to the Azure Marketplace, so you will never need to worry about updating the operating system and toolkit - just like the Microsoft Hosted Runners!</p> <p>To configure, you need to follow the three steps below:</p> <ol> <li>Configuring the Virtual Machine Scale Set</li> <li>Adding the VMSS as an Azure DevOps Agent Pool</li> <li>Testing the self hosted runner (Not really required)</li> </ol>"},{"location":"marketplace-offerings/self-hosted-runners/ado/#select-your-deployment-option","title":"Select your deployment option:","text":"<ul> <li>Manual configuration in the Azure Portal</li> <li>Deploy using Terraform</li> </ul>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step1-manual/","title":"Step 1a - Configuring the Virtual Machine Scale Set manually","text":"<p>Note: If you do not want to handle the creation of the VMSS manually, you can use our other methods instead.</p> <p>Start by going to the Azure Portal and click +Create a resource. </p> <p></p> <p>Search for Virtual Machine Scale Set, click on the result and click Create</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step1-manual/#basics","title":"Basics","text":"<ul> <li>Project details<ul> <li>Subscription - A subscription you have contributor access to<ul> <li>Resource group - A new or existing resource group</li> </ul> </li> </ul> </li> <li>Scale set details<ul> <li>Virtual machine scale set name - The name of the scale set itself. Cannot be changed after deployment, but everything is stateless, so you can simply deploy a new scale set if needed.</li> <li>Region - The region where you want your runners to be located</li> <li>Availability zone - Configure to None in order to allow for a cluster with few running instances</li> </ul> </li> <li>Orchestration<ul> <li>Orchestration mode - Configure to Uniform, as we will be running only a single image and runner type</li> <li>Security type - Standard is the only supported for our image currently</li> </ul> </li> <li> <p>Instance details</p> <ul> <li>Image - Locate the Fortytwo Self Hosted Runner for Azure DevOps image and select whether you want an Ubuntu or Windows based runner:</li> </ul> <p></p> <ul> <li>Run with Azure Spot discount - Only select this if you know how to handle spot, and if your pipelines can tolerate evictions</li> <li>Size - Choose the virtual machine size you want to run the runners as</li> <li>Administrator account</li> <li>Configure an administrator account for you virtual machines</li> </ul> </li> </ul> <p> </p>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step1-manual/#spot","title":"Spot","text":"<p>Skip configuring Spot unless you chose to Run with Azure spot discount.</p>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step1-manual/#disks","title":"Disks","text":"<p>Leave Disks as default and go to the next page.</p>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step1-manual/#networking","title":"Networking","text":"<p>On the Networking page, you can choose between creating a new network or reuse an existing one. You can easily connect to a virtual network that is peered into a Azure Landing Zones solution and use private endpoints and stuff. Please be aware that the runners require internet connectivity in order to reach Azure DevOps.</p> <ul> <li>Load balancing options - Choose None, as Azure DevOps takes care of this</li> </ul> <p>The default settings will work just fine in most cases:</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step1-manual/#scaling","title":"Scaling","text":"<p>For scaling, Azure DevOps will take care of everything. However, you should configure Initial instance count to 0, as we need to configure the VMSS for Azure DevOps connectivity before creating our instances.</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step1-manual/#management-health-advanced-and-tags","title":"Management, Health, Advanced and Tags","text":"<p>No need to configure any of this. Just click next and complete the deployment of VMSS.</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step1-manual/#final-configuration","title":"Final configuration","text":"<p>After successfully creating the VMSS instance, click Go to resource</p> <p></p> <p>Under Upgrade policy, switch from manual to Automatic.</p> <p></p> <p>Continue to step 2 - Configuring the Azure DevOps Agent Pool</p>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step1-terraform/","title":"Step 1b - Configuring the Virtual Machine Scale Set using Terraform","text":"<p>Rename of organization</p> <p>Due to the renaming of Company, the Github organization has changed name from \"amestofortytwo\" to \"fortytwoservices\". Pre-existing Terraform code would need to change that in code.</p>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step1-terraform/#prereqs","title":"Prereqs","text":"<ul> <li>Terraform installed</li> <li>Azure CLI installed</li> </ul>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step1-terraform/#deployment","title":"Deployment","text":"<p>We have published this Terraform module for simplified deployment. If you are not familiar with using Terraform, consider using the manual method instead, but it should be fairly easy for most people. </p> <p>Start by creating an empty folder with a single file <code>main.tf</code>, with the below content, and running the <code>terraform.ps1</code> code line by line:</p> <code>main.tf</code> <code>terraform.ps1</code> <pre><code>provider \"azurerm\" {\n  features {}\n}\n\nmodule \"vmss\" {\n  source                         = \"fortytwoservices/selfhostedrunnervmss/azurerm\"\n  operating_system               = \"ubuntu\"       # windows or ubuntu\n  runner_platform                = \"azure_devops\" # azure_devops or github\n}\n</code></pre> <pre><code>az login\naz account set --subscription \"&lt;your subscription id&gt;\"\naz vm image terms accept --offer self_hosted_runner_ado --plan ubuntu-latest --publisher amestofortytwoas1653635920536\naz vm image terms accept --offer self_hosted_runner_ado --plan windows-latest --publisher amestofortytwoas1653635920536\nterraform init\nterraform apply\n</code></pre> <p>Continue to step 2 - Configuring the Azure DevOps Agent Pool</p>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step2/","title":"Step 2 - Configuring the Azure DevOps Agent Pool","text":"<p>Now the the VMSS is up and running, we are ready to configure the Azure DevOps side of things. </p> <p>On the organization level (not while in a project), go to Organization settings</p> <p>Find Agent pools and click Add pools</p> <p></p> <p>Select Azure virtual machine scale set</p> <p></p> <p>Find you VMSS and name your pool:</p> <p></p> <p>Configure your preferred Pool options. We recommend having at least 1 agent on standby, though if cost is an issue, you can set it to 0 (you will have longer wait times for your first run due to provisioning the instance)</p> <p></p> <p>Click Create.</p> <p>You should now be ready to use the VMSS as runners. After configuring the DevOps side of things, you should see the following extension added to your VMSS:</p> <p></p> <p>Continue to step 3 - Testing the self hosted runner</p>"},{"location":"marketplace-offerings/self-hosted-runners/ado/step3/","title":"Step 3 - Testing the self hosted runner","text":"<p>The following is an example pipeline using the pool we just created:</p> <pre><code>stages:\n  - stage: run\n    displayName: Run\n    jobs:\n      - job: run\n        displayName: Run\n        pool: SelfHostedRunnerUbuntu # Name of your VMSS pool\n        steps:\n          - task: PowerShell@2\n            name: Test\n            displayName: \"Test\"\n            inputs:\n              targetType: inline\n              pwsh: true\n              script: uname -a\n</code></pre> <p>After running the pipeline, you should see that an agent has come online:</p> <p></p> <p>And from the VMSS side of things, we can see that an instance has been created:</p> <p></p> <p>And of course, we can see that the pipeline is working just fine:</p> <p></p> <p>That's it, you now have an agent pool in Azure DevOps, that will automatically be updated whenever the Microsoft Hosted Runners are updated (through our image). Have fun!</p>"},{"location":"marketplace-offerings/self-hosted-runners/github/","title":"Configuring GitHub self hosted runners using VMSS","text":"<p>This documentation shows you how to configure an Azure Virtual Machine Scale Set (VMSS) that will always be running the latest Self Hosted Runner image, as well as configuring the VMSS instances to automatically register as self hosted runners in your GitHub organization or repository. Using a VMSS gives you the ability easily increase and decrease the number of active runners whenever you want, manually for now, but it is possible to automate. Additionally, the VMSS will always create instances based on the latest runner image published to the Azure Marketplace, so you will never need to worry about updating the operating system and toolkit - just like the hosted runners!</p> <p>To configure, you need to follow the three steps below:</p> <ol> <li>Configuring the Virtual Machine Scale Set</li> <li>Configuring the VMSS instances to automatically register to GitHub</li> <li>Testing the self hosted runner (Not really required)</li> </ol>"},{"location":"marketplace-offerings/self-hosted-runners/github/#select-your-deployment-option","title":"Select your deployment option:","text":"<ul> <li>Manual configuration in the Azure Portal</li> <li>Deploy using Terraform</li> </ul>"},{"location":"marketplace-offerings/self-hosted-runners/github/step1-manual/","title":"Step 1a - Configuring the Virtual Machine Scale Set manually","text":"<p>Note: If you do not want to handle the creation of the VMSS manually, you can use our other methods instead.</p> <p>Start by going to the Azure Portal and click +Create a resource. </p> <p></p> <p>Search for Virtual Machine Scale Set, click on the result and click Create</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step1-manual/#basics","title":"Basics","text":"<ul> <li>Project details<ul> <li>Subscription - A subscription you have contributor access to<ul> <li>Resource group - A new or existing resource group</li> </ul> </li> </ul> </li> <li>Scale set details<ul> <li>Virtual machine scale set name - The name of the scale set itself. Cannot be changed after deployment, but everything is stateless, so you can simply deploy a new scale set if needed.</li> <li>Region - The region where you want your runners to be located</li> <li>Availability zone - Configure to None in order to allow for a cluster with few running instances</li> </ul> </li> <li>Orchestration<ul> <li>Orchestration mode - Configure to Uniform, as we will be running only a single image and runner type</li> <li>Security type - Standard is the only supported for our image currently</li> </ul> </li> <li> <p>Instance details</p> <ul> <li>Image - Locate the Fortytwo Self Hosted Runner for Azure GitHub image and select whether you want an Ubuntu or Windows based runner:</li> </ul> <p></p> <ul> <li>Run with Azure Spot discount - Only select this if you know how to handle spot, and if your pipelines can tolerate evictions</li> <li>Size - Choose the virtual machine size you want to run the runners as</li> <li>Administrator account</li> <li>Configure an administrator account for you virtual machines</li> </ul> </li> </ul> <p> </p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step1-manual/#spot","title":"Spot","text":"<p>Skip configuring Spot unless you chose to Run with Azure spot discount.</p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step1-manual/#disks","title":"Disks","text":"<p>Leave Disks as default and go to the next page.</p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step1-manual/#networking","title":"Networking","text":"<p>On the Networking page, you can choose between creating a new network or reuse an existing one. You can easily connect to a virtual network that is peered into a Azure Landing Zones solution and use private endpoints and stuff. Please be aware that the runners require internet connectivity in order to reach GitHub.</p> <ul> <li>Load balancing options - Choose None, as GitHub takes care of this</li> </ul> <p>The default settings will work just fine in most cases:</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step1-manual/#scaling","title":"Scaling","text":"<p>For scaling, you should configure Initial instance count to 0, as we need to configure the VMSS for Github connectivity before creating our first instances.</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step1-manual/#management-health-advanced-and-tags","title":"Management, Health, Advanced and Tags","text":"<p>No need to configure any of this. Just click next and complete the deployment of VMSS.</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step1-manual/#final-configuration","title":"Final configuration","text":"<p>After successfully creating the VMSS instance, click Go to resource</p> <p></p> <p>Under Upgrade policy, switch from manual to Automatic.</p> <p></p> <p>Continue to step 2 - Configuring the virtual machine scale set for auto registration</p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step1-terraform/","title":"Step 1b - Configuring the Virtual Machine Scale Set using Terraform","text":"<p>Rename of organization</p> <p>Due to the renaming of Company, the Github organization has changed name from \"amestofortytwo\" to \"fortytwoservices\". Pre-existing Terraform code would need to change that in code.</p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step1-terraform/#prereqs","title":"Prereqs","text":"<ul> <li>Terraform installed</li> <li>Azure CLI installed</li> </ul>"},{"location":"marketplace-offerings/self-hosted-runners/github/step1-terraform/#deployment","title":"Deployment","text":"<p>We have published this Terraform module for simplified deployment. If you are not familiar with using Terraform, consider using the manual method instead, but it should be fairly easy for most people. </p> <p>Start by creating an empty folder with a single file <code>main.tf</code>, with the below content, and running ther <code>terraform.ps1</code> code line by line:</p> <code>main.tf</code> <code>terraform.ps1</code> <pre><code>provider \"azurerm\" {\n  features {}\n}\n\nmodule \"vmss\" {\n  source                         = \"fortytwoservices/selfhostedrunnervmss/azurerm\"\n  operating_system               = \"ubuntu\"       # windows or ubuntu\n  runner_platform                = \"github\"       # azure_devops or github\n}\n</code></pre> <pre><code>az login\naz account set --subscription \"&lt;your subscription id&gt;\"\naz vm image terms accept --offer self_hosted_runner_github --plan ubuntu-latest --publisher amestofortytwoas1653635920536\naz vm image terms accept --offer self_hosted_runner_github --plan windows-latest --publisher amestofortytwoas1653635920536\nterraform init\nterraform apply\n</code></pre> <p>Continue to step 2 - Configuring the virtual machine scale set for auto registration</p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step2/","title":"Step 2 - Configuring the virtual machine scale set for auto registration","text":"<p>Now the the VMSS is up and running, we are ready to configure the Github runner.</p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step2/#get-a-pat-from-github-for-either-repo-or-organization","title":"Get a PAT from Github for either repo or organization","text":"<p>If you are registering the runners for a private repo, the PAT needs to have access to \"repo\". If you are registering the runners for an organization, the PAT needs to have access to \"admin:org\". To register a PAT, go to \"Settings\" -&gt; \"Developer settings\" -&gt; \"Personal access tokens\" -&gt; \"Tokens (classic) and click \"Generate new token\".</p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step2/#organization-runners","title":"Organization runners","text":""},{"location":"marketplace-offerings/self-hosted-runners/github/step2/#organization-runners-on-private-repo","title":"Organization runners on private repo","text":""},{"location":"marketplace-offerings/self-hosted-runners/github/step2/#personal-repository-runners","title":"Personal repository runners","text":""},{"location":"marketplace-offerings/self-hosted-runners/github/step2/#for-ubuntu-self-hosted-runners","title":"For Ubuntu Self-hosted Runners","text":"<p>To configure the VMSS to auto-register, use the below new method. The legacy way is just mentioned for reference.</p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step2/#configure-the-vmss-to-auto-register-new","title":"Configure the VMSS to auto register (New)","text":"<p>Run the following with az-cli to configure an extension on the VMSS that will auto register the runner with Github. Replace the variables with your correct information.</p> <pre><code>VMSS=vmss-test-noeast   # Name of the VMSS.\nRG=rg-test-noeast       # Resource group for the VMSS.\nPAT=ghp_xxx             # The PAT generated in the previous steps.\nSCOPE=amesfortytwo      # -s: Can be spesified as either the organization, the owner/repository, or enterprises/enterprisename.\nUSER=runner             # -u: Username for the runner created on the VMSS.\nLABEL=label1,label2     # (Optional) -l: Comma separated list of labels for the runner.\nRGROUP=test             # (Optional) -r: Runner Group.\naz vmss extension set --vmss-name $VMSS --name customScript --resource-group $RG \\\n    --version 2.1 --publisher Microsoft.Azure.Extensions \\\n    --protected-settings \"{\\\"fileUris\\\": [\\\"https://raw.githubusercontent.com/fortytwoservices/terraform-azurerm-selfhostedrunnervmss/main/scripts/script.sh\\\"],\\\"commandToExecute\\\": \\\"RUNNER_CFG_PAT=$PAT bash script.sh -s $SCOPE -u $USER -l $LABEL -r $RGROUP -f\\\"}\"\n</code></pre> <p>Scale up the VMSS to at least 1 instance. This can be done in the Azure Portal or with az-cli. Currently you would need to manually scale the number of instances of the VMSS to the number you want.</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step2/#configure-the-vmss-to-auto-register-legacy-way","title":"Configure the VMSS to auto register (Legacy way)","text":"<p>Run the following with az-cli to configure an extension on the VMSS that will auto register the runner with Github. Replace the variables with your correct information.</p> <pre><code>VMSS=vmss-test-noeast   # Name of the VMSS.\nRG=rg-test-noeast       # Resource group for the VMSS.\nPAT=ghp_xxx             # The PAT generated in the previous steps.\nSCOPE=amesfortytwo      # Can be spesified as either the organization or the owner/repository.\nUSER=runner             # Username for the runner created on the VMSS.\nLABEL=label1,label2     # Comma separated list of labels for the runner.\nRGROUP=test             # Runner Group. Optional and can be left out/blank.\naz vmss extension set --vmss-name $VMSS --name customScript --resource-group $RG \\\n    --version 2.1 --publisher Microsoft.Azure.Extensions \\\n    --protected-settings \"{\\\"fileUris\\\": [\\\"https://raw.githubusercontent.com/fortytwoservices/terraform-azurerm-selfhostedrunnervmss/main/scripts/script.sh\\\"],\\\"commandToExecute\\\": \\\"bash script.sh $SCOPE $PAT $USER $LABEL $RGROUP\\\"}\"\n</code></pre> <p>Scale up the VMSS to at least 1 instance. This can be done in the Azure Portal or with az-cli. Currently you would need to manually scale the number of instances of the VMSS to the number you want.</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step2/#for-windows-self-hosted-runners","title":"For Windows Self-hosted Runners","text":"<p>To configure the VMSS to auto-register, use the below new method.</p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step2/#configure-the-vmss-to-auto-register-for-windows","title":"Configure the VMSS to auto register for Windows","text":"<p>Run the following with az-cli under a powershell terminal to configure an extension on the VMSS that will auto register the runner with Github. Replace the variables with your correct information.</p> <pre><code>$VMSS=vmss-test-noeast    # Name of the VMSS.\n$RG=rg-test-noeast        # Resource group for the VMSS.\n$PAT=ghp_xxx              # The PAT generated in the previous steps.\n$GHHOST=github.com        # The domain of the Github instance (default is github.com), use if running GHES.\n$SCOPE=amesfortytwo       # Can be spesified as either the organization, the owner/repository, or enterprises/enterprisename.\n$USER=runner              # Username for the runner created on the VMSS.\n$USERPASSWORD=12Passw0rd_ # Password for the runner user created on the VMSS.\n$LABEL=label1,label2      # (Optional) Comma separated list of labels for the runner.\naz vmss extension set --vmss-name $VMSS --name customScript --resource-group $RG \\\n    --version 2.1 --publisher Microsoft.Azure.Extensions \\\n    --protected-settings \"{\\\"fileUris\\\": [\\\"https://raw.githubusercontent.com/fortytwoservices/terraform-azurerm-selfhostedrunnervmss/main/scripts/invoke-ghrunner.ps1\\\"],\\\"commandToExecute\\\": \\\"powershell -ExecutionPolicy Unrestricted -Command .\\\\invoke-ghrunner.ps1 -runnerscope $SCOPE -githubpat $PAT -githubhostname $GHHOST -user $USER -userpassword $USERPASSWORD -label $LABEL\\\"}\"\n</code></pre> <p>Scale up the VMSS to at least 1 instance. This can be done in the Azure Portal or with az-cli. Currently you would need to manually scale the number of instances of the VMSS to the number you want.</p> <p></p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step2/#advanced-configuration-examples-for-the-vmss","title":"Advanced configuration examples for the VMSS","text":""},{"location":"marketplace-offerings/self-hosted-runners/github/step2/#offboard-github-runner-upon-termination-eventsscale-down-linux","title":"Offboard Github runner upon termination events/scale-down (Linux)","text":"<p>If you the Github runner instance to offboard itself from Github upon termination events/scale-down, you will need to enable termination notifications on the VMSS. This can be done with the following in the portal:</p> <p></p> <p>Also the Terraform module has a variable for this:</p> <pre><code>  enable_termination_notifications = true\n</code></pre>"},{"location":"marketplace-offerings/self-hosted-runners/github/step2/#verify-that-the-runner-is-registered","title":"Verify that the runner is registered","text":"<p>After the previous has been done, you should be able to verify within the organization or the repository that the runner is registered.</p> <p></p> <p>Continue to step 3 - Testing the self hosted runner</p>"},{"location":"marketplace-offerings/self-hosted-runners/github/step3/","title":"Step 3 - Testing the self hosted runner","text":"<p>The following is an example pipeline using the pool we just created:</p> <pre><code>---\nname: test \non:\n  workflow_dispatch:\n\npermissions:\n  contents: write\njobs:\n  deploy:\n    runs-on: self-hosted\n    steps:\n      - uses: actions/checkout@3df4ab11eba7bda6032a0b82a6bb43b11571feac # v4.0.0\n      - name: Run a command\n        shell: pwsh\n        run: Write-Host \"Hello World\"\n</code></pre> <p>We can see that the pipeline is working just fine:</p> <p></p> <p>That's it, you now have an agent pool in Github, that will automatically be updated whenever the Microsoft Hosted Runners are updated (through our image). Have fun!</p>"}]}